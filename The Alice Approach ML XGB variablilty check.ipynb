{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:purple; font-style:bold\"><br>Cuts Optimization using Extra Gradient Boosting\n",
    "<br></p><br>\n",
    "\n",
    "Over the last years, **Machine Learning** tools have been successfully applied to problems in high-energy physics. For example, for the classification of physics objects. Supervised machine learning algorithms allow for significant improvements in classification problems by taking into account observable correlations and by learning the optimal selection from examples, e.g. from Monte Carlo simulations.\n",
    "\n",
    "\n",
    "# Importing the Libraries\n",
    "\n",
    "**Numpy** is a powerful library that makes working with python more efficient, so we will import it and use it as np in the code. **Pandas** is another useful library that is built on numpy and has two great objects *series* and *dataframework*. Pandas works great for *data ingestion* and also has *data visualization* features. From **Hipe4ml** we import **TreeHandler** and with the help of this function we will import our *Analysis Tree* to our notebook.\n",
    "\n",
    "**Matplotlib** comes handy in plotting data while the machine learning is performed by **XGBOOST**. We will import data splitter from **Scikit-learn** as *train_test_split*. **Evaluation metrics** such as *confusion matrix*, *Receiver operating characteristic (ROC)*, and *Area Under the Receiver Operating Characteristic Curve (ROC AUC)*  will be used to asses our models.\n",
    "\n",
    "A **Confusion Matrix** $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$. Thus in binary classification, the count of true positives is $C_{00}$, false negatives $C_{01}$,false positives is $C_{10}$, and true neagtives is $C_{11}$.\n",
    "\n",
    "If $ y^{'}_{i} $ is the predicted value of the $ i$-th sample and $y_{i}$ is the corresponding true value, then the fraction of correct predictions over $ n_{samples}$ is defined as \n",
    "$$\n",
    "True \\: positives (y,y^{'}) =  \\sum_{i=1}^{n_{samples} } 1 (y^{'}_{i} = y_{i}=1)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/shahid/cbmsoft/anaconda-u/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import weakref \n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "#from root_pandas import read_root\n",
    "\n",
    "\n",
    "from data_cleaning import clean_df\n",
    "from KFPF_lambda_cuts import KFPF_lambda_cuts\n",
    "from plot_tools import AMS, preds_prob, plot_confusion_matrix\n",
    "from tree_importer import tree_importer\n",
    "import uproot\n",
    "\n",
    "\n",
    "#To save some memory we will delete unused variables\n",
    "class TestClass(object): \n",
    "    def check(self): \n",
    "        print (\"object is alive!\") \n",
    "    def __del__(self): \n",
    "        print (\"object deleted\") \n",
    "        \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "executor = ThreadPoolExecutor(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data\n",
    "CBM has a modified version of the cern's root software and it contains the simulated setup of CBM. Normally, a model generated input file, for example a URQMD 12 AGeV, is passed through different macros. These macros represent the CBM setup and it is like taking particles and passing them through a detector. These particles are registered as hits in the setup. Then particles' tracks are reconstructed from these hits using cellular automaton and Kalman Filter mathematics.\n",
    "\n",
    "\n",
    "CBM uses the **tree** format of cern root to store information. To reduce the size of these root files a modified tree file was created by the name of Analysis tree. This Analysis tree file contains most of the information that we need for physics analysis. \n",
    "\n",
    "In this example, we download three Analysis Trees. The first one contains mostly background candidates for lambda i.e. protons and pions which do not come from a lambda. The second file contains mostly signal candidates of lamba i.e. it contains protons and pions which come from a lambda decay. The third one contains 10k events generated using URQMD generator with 12 AGeV energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import three root files into our jupyter notebook\n",
    "signal = tree_importer('/home/shahid/cbmsoft/Data/PFSimplePlainTreeSignal.root','PlainTree')\n",
    "# We only select lambda candidates\n",
    "sgnal = signal[(signal['LambdaCandidates_is_signal']==1) & (signal['LambdaCandidates_mass']>1.108)\n",
    "               & (signal['LambdaCandidates_mass']<1.1227)]\n",
    "del signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly for the background\n",
    "background = tree_importer('/home/shahid/cbmsoft/Data/PFSimplePlainTreeBackground.root','PlainTree')\n",
    "bg = background[(background['LambdaCandidates_is_signal'] == 0)\n",
    "                & ((background['LambdaCandidates_mass'] > 1.07)\n",
    "                & (background['LambdaCandidates_mass'] < 1.108) | (background['LambdaCandidates_mass']>1.1227) \n",
    "                   & (background['LambdaCandidates_mass'] < 2.00))]\n",
    "\n",
    "\n",
    "del signal\n",
    "del background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29535"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = tree_importer('/home/shahid/cbmsoft/Data/10k_events_PFSimplePlainTree.root','PlainTree')\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = tree_importer('/home/shahid/Mount/gsi/u/flat_trees/apr20_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/PFSimplePlainTree.root','PlainTree')\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = df_original[(df_original['LambdaCandidates_is_signal'] == 0)\n",
    "                & ((df_original['LambdaCandidates_mass'] > 1.07)\n",
    "                & (df_original['LambdaCandidates_mass'] < 1.108) | (df_original['LambdaCandidates_mass']>1.1227) \n",
    "                   & (df_original['LambdaCandidates_mass'] < 2.00))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels=['chi2geo', 'chi2primneg','chi2primpos', 'chi2topo','cosineneg', 'cosinepos',\n",
    "       'cosinetopo', 'distance','eta', 'l', 'ldl','mass', 'masserr',\n",
    "       'p', 'pT', 'phi','px', 'pxerr', 'py','pyerr', 'pz','pzerr', 'rapidity',\n",
    "       'x', 'y', 'z','daughter1id','daughter2id','issignal', 'isfrompv','nhitsneg', 'nhitspos', 'pid']\n",
    "df_original.columns = new_labels\n",
    "bg.columns=new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The labels of the columns in the df data frame are having the prefix LambdaCandidates_ so we rename them\n",
    "new_labels= ['chi2geo', 'chi2primneg', 'chi2primpos', 'chi2topo', 'cosineneg',\n",
    "       'cosinepos', 'cosinetopo', 'distance', 'eta', 'l', 'ldl',\n",
    "       'mass', 'p', 'pT', 'phi', 'px', 'py', 'pz', 'rapidity',\n",
    "             'x', 'y', 'z', 'daughter1id', 'daughter2id', 'isfrompv', 'pid', 'issignal']\n",
    "\n",
    "sgnal.columns = new_labels\n",
    "bg.columns = new_labels\n",
    "\n",
    "#Let's see how the dataframe object df looks like\n",
    "df_original.columns=new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal = df_original[df_original['issignal']==1]\n",
    "df_bg = df_original[df_original['issignal']==0]\n",
    "del df_original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg['log-l']= np.log(df_bg['l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal['log-l']= np.log(df_signal['l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "df_bg['log-l'].hist(bins=np.arange(-20,80,0.5),alpha=0.3)\n",
    "df_signal['log-l'].hist(bins=np.arange(-20,80,0.5), alpha=0.3)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "#plt.ylabel('logarithmic scale')\n",
    "plt.title('URQMD 10k events, signal candidates, l')\n",
    "plt.savefig('hists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((13345-13314)/13345)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    with pd.option_context('mode.use_inf_as_na', True):\n",
    "        df = df.dropna()\n",
    "    is_good_mom = (df['pz'] > 0) & (df['p']<20)\n",
    "    is_good_coord = (abs(df['x']) < 50) & (abs(df['y']) < 50) & (df['z']>0) & (df['z']<80)\n",
    "    is_good_params = (df['distance'] > 0) & (df['distance'] < 100) & (df['chi2geo']>0) & (df['chi2geo'] < 1000) & (df['cosinepos'] > 0.5) & (df['chi2topo'] > 0) & (df['chi2topo'] < 100000) & (df['cosineneg']>0.1) & (df['eta']>1) & (df['eta']<6.5) & (df['l']<80) & (df['ldl']>0) & (df['ldl']<5000)\n",
    "    is_good_daughters = (df['chi2primneg']>0) & (df['chi2primneg'] < 3e7) & (df['chi2primpos']>0) & (df['chi2primpos']<1e6)\n",
    "    is_good_mass = (df['mass']>1.1) & (df['mass']<2)\n",
    "\n",
    "    is_good_df = (is_good_mom) & (is_good_coord) & (is_good_params) & (is_good_daughters) & (is_good_mass)\n",
    "\n",
    "    return df[is_good_df]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_signal=sgnal[((sgnal['eta']>1)) &  ((sgnal['eta']<4))]\n",
    "new_signal = sgnal[(abs(sgnal['x'])<50) & (abs(sgnal['y'])<50) & (sgnal['eta']>1) & (sgnal['eta']<4)]\n",
    "new_signal['eta'].hist(bins=100)\n",
    "plt.savefig('hists.png')\n",
    "new_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgnal['new_eta'].hist(bins=100)\n",
    "new_signal=sgnal[((sgnal['eta']>-1*np.log(np.tan((25*np.pi)/(2*180))))) &  ((sgnal['eta']<-1*np.log(np.tan((2.5*np.pi)/(2*180)))))]\n",
    "\n",
    "new_signal['eta'].hist(bins=100)\n",
    "plt.savefig('hists.png')\n",
    "#new_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal = df_original[df_original['issignal']==1]\n",
    "df_bg = df_original[df_original['issignal']==0]\n",
    "del df_original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('mode.use_inf_as_na', True):\n",
    "        sgnal = df_signal.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('mode.use_inf_as_na', True):\n",
    "        bg = df_bg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_signal\n",
    "del df_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgnal['log_chi2geo'] = np.log(sgnal['chi2geo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg['log_chi2geo'] = np.log(bg['chi2geo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('mode.use_inf_as_na', True):\n",
    "        bg = bg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize = (12,10))\n",
    "plt.hist(sgnal['chi2geo'], bins =300, facecolor = 'red', alpha = 0.35, range=(0,20))\n",
    "#plt.hist(sgnal['log_chi2geo'], bins=300, facecolor ='blue',alpha = 0.35)\n",
    "\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data frame object has some columns/features and for them at the very last column the true Monte Carlos information is available. This MC information tells us whether this reconstructed particle was originally produced as a decaying particle or not. So a value of 1 means that it is a true candidate and 0 means that it is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "Sometimes a data set contains entries which do not make sense. For example, infinite values or NaN entries. We clean the data by removing these entries. Ofcourse, we lose some data points but these outliers sometimes cause problems when we perform analysis. \n",
    "\n",
    "Since our experiment is a fixed target experiment so there are certain constraints which have to be applied on the data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new data frame and saving the results in it after cleaning of the original dfs\n",
    "#Also keeping the original one\n",
    "bcknd = clean_df(bg)\n",
    "signal = clean_df(sgnal)\n",
    "\n",
    "del bg\n",
    "del sgnal\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_df(df_original)\n",
    "#del df_original\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "h=plt.hist2d(signal['phi'],signal['eta'], bins=100, norm=mpl.colors.LogNorm())\n",
    "cbar=fig.colorbar(h[3], ax=axs)\n",
    "plt.title(\"Cleaned\", fontsize =18)\n",
    "plt.xlabel('$\\phi$', fontsize=18)\n",
    "plt.ylabel('$\\eta$', fontsize=18)\n",
    "cbar.ax.tick_params(labelsize=18)\n",
    "axs.tick_params(labelsize=18)\n",
    "plt.show()\n",
    "fig.savefig(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/pT_vs_rapidity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal['rapidity'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_signal.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Background and Signal\n",
    "Our sample contains a lot of background (2178718) and somewhat signal candidates (36203). For analysis we will use a signal set of 4000 candidates and a background set of 12000 candidates. The background and signal candidates will be selected by using MC information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal1 = signal[signal['rapidity']>1.5996]\n",
    "signal1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We randomly choose our signal set of 4000 candidates\n",
    "signal_selected= signal.sample(n=90000)\n",
    "\n",
    "#background = 3 times the signal is also done randomly\n",
    "background_selected = bcknd.sample(n=3*(signal_selected.shape[0]))\n",
    "\n",
    "del signal\n",
    "del bcknd\n",
    "gc.collect()\n",
    "\n",
    "#Let's combine signal and background\n",
    "dfs = [signal_selected, background_selected]\n",
    "df_scaled = pd.concat(dfs)\n",
    "\n",
    "# Let's shuffle the rows randomly\n",
    "df_scaled = df_scaled.sample(frac=1)\n",
    "del dfs, signal_selected, background_selected\n",
    "# Let's take a look at the top 10 entries of the df\n",
    "df_scaled.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = 0.5 * (np.log(E+P/E-P))\n",
    "\n",
    "\n",
    "https://cbm-wiki.gsi.de/foswiki/bin/view/PWG/CbmCollisionEnergies\n",
    "\n",
    "\n",
    "y = 0.5 * (np.log((12+10)/(12-10)))\n",
    "\n",
    "\n",
    "using this the rapidity is 3.1992 for Ebeam =12.04 and pbeam =12 and mid rapidity is y/2=  1.5996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pT_vs_rapidity(df, var_xaxis , var_yaxis , range_var_xaxis, range_var_yaxis):\n",
    "    import matplotlib as mpl\n",
    "    fig, axs = plt.subplots(figsize=(15, 10))\n",
    "    h=plt.hist2d(df[var_xaxis],df[var_yaxis],range=[range_var_xaxis,range_var_yaxis], bins=10, norm=mpl.colors.LogNorm())\n",
    "    cbar = fig.colorbar(h[3])\n",
    "    plt.vlines(x=.8,ymin=-1,ymax=4, color='r', linestyle='-')\n",
    "    plt.vlines(x=2.5,ymin=-1,ymax=4, color='r', linestyle='-')\n",
    "    plt.hlines(y=0.15, xmin=-0.1, xmax=3.5, colors='b', linestyles='solid', label='')\n",
    "    plt.hlines(y=1.45, xmin=-0.1, xmax=3.5, colors='b', linestyles='solid', label='')\n",
    "    plt.xlabel(''+var_xaxis, fontsize=15)\n",
    "    plt.ylabel(''+var_yaxis, fontsize=15)\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/pT_vs_rapidity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1=[-0.1, 3.5]\n",
    "range2=[-0.1, 3.5]\n",
    "\n",
    "pT_vs_rapidity(signal,'rapidity','pT', range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1 = (1.077, 1.18)\n",
    "fig, axs = plt.subplots(figsize=(10, 6))\n",
    "#df_scaled['mass'].plot.hist(bins = 300, range=range1,grid=True,sharey=True)\n",
    "(df_scaled[df_scaled['issignal']==0])['mass'].plot.hist(bins = 300, facecolor='yellow',grid=True,range=range1)\n",
    "(df_scaled[df_scaled['issignal']==1])['mass'].plot.hist(bins = 300, facecolor='magenta',grid=True, range=range1)\n",
    "plt.ylabel(\"Counts\", fontsize=15)\n",
    "plt.xlabel(\"Mass in $\\dfrac{GeV}{c^2}$\", fontsize= 15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.title('Test and Train Lambda Invariant Mass', fontsize = 15)\n",
    "plt.legend(('Background', 'Signal'), fontsize = 15)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"signal_bac_invmass_MC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train and Test sets\n",
    "To make machine learning algorithms more efficient on unseen data we divide our data into two sets. One set is for training the algorithm and the other is for testing the algorithm. If we don't do this then the algorithm can overfit and we will not capture the general trends in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following columns will be used to predict whether a reconstructed candidate is a lambda particle or not\n",
    "cuts = [ 'chi2primneg', 'chi2primpos', 'ldl', 'distance', 'chi2geo']\n",
    "\n",
    "\n",
    "x = df_scaled[cuts].copy()\n",
    "\n",
    "# The MC information is saved in this y variable\n",
    "y =pd.DataFrame(df_scaled['issignal'], dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following columns will be used to predict whether a reconstructed candidate is a lambda particle or not\n",
    "x_whole = df_clean[cuts].copy()\n",
    "# The MC information is saved in this y variable\n",
    "y_whole = pd.DataFrame(df_clean['issignal'], dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a new df \n",
    "new_check_set=KFPF_lambda_cuts(df_original)\n",
    "del df_original\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:purple; font-style:bold\"><br>XGB Boost \n",
    "<br></p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian\n",
    "In order to find the best parameters of XGB for our data we use Bayesian optimization. Grid search and and random search could also do the same job but bayesian is more time efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=324)\n",
    "dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "dtest = xgb.DMatrix(x_whole, label = y_whole)\n",
    "dtest1=xgb.DMatrix(x_test, label = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters\n",
    "\n",
    "*subsample* [default=1]\n",
    "Subsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting. Subsampling will occur once in every boosting iteration.\n",
    "range: (0,1]\n",
    "\n",
    "*eta* [default=0.3, alias: learning_rate]\n",
    "Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n",
    "range: [0,1]\n",
    "\n",
    "\n",
    "*gamma* [default=0, alias: min_split_loss]\n",
    "Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\n",
    "range: [0,∞]\n",
    "\n",
    "\n",
    "*alpha* [default=0, alias: reg_alpha]\n",
    "L1 regularization term on weights. Increasing this value will make model more conservative.\n",
    "\n",
    "*Lasso Regression* (Least Absolute Shrinkage and Selection Operator) adds “absolute value of magnitude” of coefficient as penalty term to the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Optimization function for xgboost\n",
    "#specify the parameters you want to tune as keyword arguments\n",
    "def bo_tune_xgb(max_depth, gamma, alpha, n_estimators ,learning_rate):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,\n",
    "              'alpha':alpha,\n",
    "              'n_estimators': n_estimators,\n",
    "              'learning_rate':learning_rate,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'eval_metric': 'auc', 'nthread' : 7}\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=70, nfold=5)\n",
    "    return  cv_result['test-auc-mean'].iloc[-1]\n",
    "\n",
    "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (4, 10),\n",
    "                                             'gamma': (0, 1),\n",
    "                                            'alpha': (2,20),\n",
    "                                             'learning_rate':(0,1),\n",
    "                                             'n_estimators':(100,500)\n",
    "                                            })\n",
    "\n",
    "#performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement\n",
    "xgb_bo.maximize(n_iter=15, init_points=8, acq='ei')\n",
    "#0.9951"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_param = xgb_bo.max['params']\n",
    "param= {'alpha': max_param['alpha'], 'gamma': max_param['gamma'], 'learning_rate': max_param['learning_rate'],\n",
    "        'max_depth': int(round(max_param['max_depth'],0)), 'n_estimators': int(round(max_param['n_estimators'],0))\n",
    "        , 'objective': 'binary:logistic'}\n",
    "\n",
    "#Fit/train on training data\n",
    "bst = xgb.train(param, dtrain)\n",
    "\n",
    "#predicitions on training set\n",
    "bst1= bst.predict(dtrain)\n",
    "\n",
    "#predictions on test set\n",
    "bst_test = pd.DataFrame(data=bst.predict(dtest1),  columns=[\"xgb_preds\"])\n",
    "y_test=y_test.set_index(np.arange(0,bst_test.shape[0]))\n",
    "bst_test['issignal']=y_test['issignal']\n",
    "\n",
    "#ROC cures for the predictions on train and test sets\n",
    "train_best, test_best = AMS(y_train, bst1,y_test, bst_test['xgb_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first argument should be a data frame, the second a column in it, in the form 'preds'\n",
    "preds_prob(bst_test,'xgb_preds', 'issignal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying XGB on the 10k events data-set\n",
    "df_clean['xgb_preds'] = bst.predict(dtest)\n",
    "preds_prob(df_clean,'xgb_preds', 'issignal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Already working model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = xgb.plot_importance(bst)\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.show()\n",
    "ax.figure.tight_layout() \n",
    "ax.figure.savefig(\"hits.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_visualization(cut, range1=(1.105, 1.19), bins1= 300 ):\n",
    "    mask1 = df_clean['xgb_preds']>cut\n",
    "    df3=df_clean[mask1]\n",
    "    \n",
    "    fig, ax2 = plt.subplots(figsize=(15, 10), dpi = 200)\n",
    "    color = 'tab:blue'\n",
    "    ax2.hist(df_clean['mass'],bins = bins1, range=range1, facecolor='blue',alpha = 0.35, label='before selection')\n",
    "    ax2.set_ylabel('Counts', fontsize = 15, color=color)\n",
    "    ax2.set_xlabel('Mass in GeV', fontsize = 15)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.legend( fontsize = 15, loc='upper left')\n",
    "    \n",
    "    color = 'tab:red'\n",
    "    ax1 = ax2.twinx()\n",
    "    ax1.hist(df3['mass'], bins = bins1, range=range1, facecolor='red',alpha = 0.35, label='Machine learning (XGB)')\n",
    "    ax1.set_xlabel('Mass in GeV', fontsize = 15)\n",
    "    ax1.set_ylabel('Counts ', fontsize = 15, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.legend( fontsize = 15,loc='upper right' )\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.title(\"The sample's Invariant Mass with XGB (with a cut > \"+str(cut)+')', fontsize = 15)\n",
    "    fig.tight_layout()\n",
    "    #fig.savefig(\"whole_sample_invmass_with_ML.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_visualization(test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut3 = test_best\n",
    "mask1 = df_clean['xgb_preds']>train_best\n",
    "df3=df_clean[mask1]\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "range1= (1.105, 1.14)\n",
    "bins1 = 150\n",
    "\n",
    "#xgb\n",
    "\n",
    "df3_new = df3[df3['issignal']==1]\n",
    "df3_new1 = df3[df3['issignal']==0]\n",
    "df3['mass'].plot.hist(bins = bins1, range=range1, facecolor='red',alpha = 0.3,grid=True,sharey=True)\n",
    "#df3_new['mass'].plot.hist(bins = 300, range=range1,facecolor='blue',alpha = 0.3,grid=True,sharey=True)\n",
    "df3_new1['mass'].plot.hist(bins = bins1, range=range1,facecolor='green',alpha = 0.3,grid=True,sharey=True)\n",
    "plt.legend(('XGB selected lambdas','\\n False positives = \\n (MC =0)\\n background in \\n the distribution' ), fontsize = 18, loc='upper right')\n",
    "#plt.rcParams[\"legend.loc\"] = 'upper right'\n",
    "plt.title(\"KFPF variables + cos$\\Theta_{between \\ \\overrightarrow{P_\\Lambda} \\  & \\ \\overrightarrow{P_{\\Pi^-}}}$ + $P_T$  with a cut of %.4f \"%cut3 +\"on the XGB probability distribution\", fontsize = 18)\n",
    "plt.xlabel(\"Mass in $\\dfrac{GeV}{c^2}$\", fontsize = 18)\n",
    "plt.ylabel(\"Counts\", fontsize = 18)\n",
    "axs.tick_params(labelsize=18)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"whole_sample_invmass_with_ML.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "By definition a confusion matrix $C$ is such that $C_{i, j}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$.\n",
    "\n",
    "Thus in binary classification, the count of true positives is $C_{0,0}$, false positives is $C_{1,0}$, true negatives is $C_{1,1}$ and false negatives is $C_{0,1}$.\n",
    "\n",
    "The following function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut1 = train_best\n",
    "df_clean['xgb_preds1'] = ((df_clean['xgb_preds']>cut1)*1)\n",
    "cnf_matrix = confusion_matrix(y_whole, df_clean['xgb_preds1'], labels=[1,0])\n",
    "#cnf_matrix = confusion_matrix(new_check_set['issignal'], new_check_set['new_signal'], labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "fig, axs = plt.subplots(figsize=(10, 8))\n",
    "axs.yaxis.set_label_coords(-0.04,.5)\n",
    "axs.xaxis.set_label_coords(0.5,-.005)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['signal','background'], title='Confusion Matrix for XGB for cut > '+str(cut1))\n",
    "plt.savefig('confusion_matrix_extreme_gradient_boosting_whole_data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:purple; font-style:bold\"><br>Tree visualization\n",
    "<br></p><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax1 = plt.subplots(figsize=(15, 10), dpi = 200)\n",
    "xgb.plot_tree(bst,num_trees=10)\n",
    "plt.rcParams['figure.figsize'] = [20, 40]\n",
    "plt.rcParams['figure.dpi']=200\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.to_graphviz(xg_reg, fmap='', num_trees=0, rankdir=None, yes_color=None, no_color=None, condition_node_params=None, leaf_node_params=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut3 = test_best\n",
    "mask1 = df_clean['xgb_preds']>cut3\n",
    "df3_base=df_clean[mask1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "range1= (1.0999, 1.17)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1,figsize=(15,10), sharex=True,  gridspec_kw={'width_ratios': [10],\n",
    "                           'height_ratios': [8,4]})\n",
    "\n",
    "ns, bins, patches=axs[0].hist((df3_base['mass']),bins = 300, range=range1,Fill=True, color='red', facecolor='red',alpha = 0.3)\n",
    "ns1, bins1, patches1=axs[0].hist((new_check_set['mass']),bins = 300, Fill=True, range=range1,facecolor='blue',alpha = 0.3)\n",
    "#plt.xlabel(\"Mass in GeV\", fontsize = 15)\n",
    "axs[0].set_ylabel(\"counts\", fontsize = 15)\n",
    "#axs[0].grid()\n",
    "axs[0].legend(('XGBoost Selected $\\Lambda$s','KFPF selected $\\Lambda$s'), fontsize = 15, loc='upper right')\n",
    "\n",
    "#plt.rcParams[\"legend.loc\"] = 'upper right'\n",
    "axs[0].set_title(\"The lambda's Invariant Mass histogram with KFPF and XGB selection criteria on KFPF variables\", fontsize = 15)\n",
    "axs[0].grid()\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "#fig.savefig(\"whole_sample_invmass_with_ML.png\")\n",
    "\n",
    "\n",
    "hist1, bin_edges1 = np.histogram(df3_base['mass'],range=(1.09, 1.17), bins=300)\n",
    "hist2, bin_edges2 = np.histogram(new_check_set['mass'],range=(1.09, 1.17), bins=300)\n",
    "\n",
    "#makes sense to have only positive values \n",
    "diff = (hist1 - hist2)\n",
    "axs[1].bar(bins[:-1],     # this is what makes it comparable\n",
    "        ns / ns1, # maybe check for div-by-zero!\n",
    "        width=0.001)\n",
    "plt.xlabel(\"Mass in $\\dfrac{GeV}{c^2}$\", fontsize = 15)\n",
    "axs[1].set_ylabel(\"XGB / KFPF\", fontsize = 15)\n",
    "axs[1].grid()\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"whole_sample_invmass_with_ML.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define fit function.\n",
    "def fit_function(x, amplitude, mean, stddev,c,d,e):\n",
    "    return (amplitude) * (np.exp(-(0.5)*((x - mean) / stddev)**2))+c+d*x+e*(x**2)\n",
    "def background_function(x,c,d,e):\n",
    "    return c+d*x+e*(x**2)\n",
    "\n",
    "def signal_function( x, amplitude, mean, stddev):\n",
    "    return (amplitude) * (np.exp(-(0.5)*((x - mean) / stddev)**2))\n",
    "#def signal_function( x, x0, a, gam):\n",
    "#    return a * (gam**2) / ( gam**2 + ( x - x0 )**2)\n",
    "\n",
    "#def fit_function( x, x0, a, gam, c,d,e):\n",
    "#    return a * (gam**2) / ( gam**2 + ( x - x0 )**2)+(c+d*x+e*(x**2))\n",
    "\n",
    "# 3.) Generate exponential and gaussian data and histograms.\n",
    "data = df3['mass']\n",
    "bins = np.linspace(1.108, 1.126, 70)\n",
    "data_entries_1, bins_1 = np.histogram(data, bins=bins)\n",
    "\n",
    "# 4.) Add histograms of exponential and gaussian data.\n",
    "data_entries = data_entries_1 \n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "\n",
    "# 5.) Fit the function to the histogram data.\n",
    "popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, p0=[600,1.115,0.001,0,0,0])\n",
    "#popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, p0=[1.1156,800,0.0013,107000,-100000,800000])\n",
    "print(popt)\n",
    "\n",
    "# 6.)\n",
    "# Generate enough x values to make the curves look smooth.\n",
    "xspace = np.linspace(1.108, 1.126, 1000000)\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "# Plot the histogram and the fitted function.\n",
    "plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function')\n",
    "\n",
    "\n",
    "plt.plot(xspace,background_function(xspace,popt[3],popt[4],popt[5]),color='red')\n",
    "plt.plot(xspace,signal_function(xspace,popt[0],popt[1],popt[2]),color='green')\n",
    "\n",
    "# Make the plot nicer.\n",
    "#plt.xlim(1.108,1.124)\n",
    "plt.xlabel(r'Mass in $\\frac{GeV}{c^2}$', fontsize=15)\n",
    "plt.ylabel(r'Number of entries')\n",
    "plt.title(r'Lamda baryon')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "fig.savefig('hists.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "def integrand( x, x0, a, gam):\n",
    "    return a * (gam**2) / ( gam**2 + ( x - x0 )**2)\n",
    "\n",
    "x0 = popt[0]\n",
    "a = popt[1]\n",
    "gam = popt[2]\n",
    "I_sig = quad(integrand, popt[0]-5*popt[2], popt[0]+5*popt[2] , args=(x0, a, gam))\n",
    "I_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand(x,c,d,e):\n",
    "    return c+d*x+e*(x**2)\n",
    "\n",
    "\n",
    "c = popt[3]\n",
    "d = popt[4]\n",
    "e = popt[5]\n",
    "I = quad(integrand, popt[0]-5*popt[2], popt[0]+5*popt[2] , args=(c,d,e))\n",
    "I_sig[0]/abs(I[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand(x, amplitude, mean, stddev,c,d,e):\n",
    "    return (amplitude) * (np.exp(-(0.5)*((x - mean) / stddev)**2))+c+d*x+e*(x**2)\n",
    "\n",
    "amplitude = popt[0]\n",
    "mean = popt[1]\n",
    "stddev = popt[2]\n",
    "c = popt[3]\n",
    "d = popt[4]\n",
    "e = popt[5]\n",
    "I = quad(integrand, popt[1]-5*popt[2], popt[1]+5*popt[2] , args=(amplitude,mean,stddev,c,d,e))\n",
    "I_sig[0]/(np.sqrt(I[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['mass'].hist(bins=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Differential Fitting\n",
    "\n",
    "This will be carried out in 3 steps. Step1/prefit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut3 = test_best\n",
    "mask1 = df_clean['xgb_preds']>cut3\n",
    "df3_base=df_clean[mask1]\n",
    "df1 = df3_base[(df3_base['mass']<1.108)]\n",
    "df2 = df3_base[df3_base['mass']>1.13]\n",
    "df3 = pd.concat([df1, df2])\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def fit_function( x, c,d,e):\n",
    "    return c+d*x+e*(x**2)\n",
    "\n",
    "data = df3['mass']\n",
    "bins = np.linspace(1.1, 1.2, 300)\n",
    "data_entries_1, bins_1 = np.histogram(data, bins=bins)\n",
    "bin_means = (np.histogram(data, bins, weights=data)[0] /\n",
    "             np.histogram(data, bins)[0])\n",
    "\n",
    "data_entries = data_entries_1 \n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "\n",
    "digitized = np.digitize(data, bins)\n",
    "bin_means = [data[digitized == i].mean() for i in range(1, len(bins))]\n",
    "\n",
    "\n",
    "\n",
    "bin_heights, bin_borders, _ = plt.hist(data, bins=bins, label='histogram')\n",
    "bin_centers = bin_borders[:-1] + np.diff(bin_borders) / 2\n",
    "popt, pcov = curve_fit(fit_function, bin_centers, bin_heights, p0=[1., 1.115, 0.001])\n",
    "\n",
    "x_interval_for_fit = np.linspace(bin_borders[0], bin_borders[-1], 10000)\n",
    "\n",
    "plt.plot(x_interval_for_fit, fit_function(x_interval_for_fit, *popt), label='fit')\n",
    "\n",
    "\n",
    "\n",
    "#popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, p0=[600,1.115,0.001,0,0,0])\n",
    "#popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, p0=[0,0,0],\n",
    "#                       method='lm')\n",
    "#bounds=[(-4320,6000, -4000),\n",
    "#                               (-3000,7570, -3100) ]\n",
    "\n",
    "c0, d0, e0 = popt\n",
    "print(popt)\n",
    "dc0, dd0, de0 = \\\n",
    "          [np.sqrt(pcov[j,j]) for j in range(popt.size)]\n",
    "\n",
    "resids = bin_heights - fit_function(bin_centers, c0, d0, e0)\n",
    "redchisqr = ((resids)**2).sum()/float(bins_1.size-3)\n",
    "print(redchisqr)\n",
    "\n",
    "# 6.)\n",
    "# Generate enough x values to make the curves look smooth.\n",
    "#xspace = np.linspace(1.08, 1.2, 1000000)\n",
    "\n",
    "# Plot the histogram and the fitted function.\n",
    "#plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "#plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function')\n",
    "\n",
    "\n",
    "#plt.plot(xspace,background_function(xspace,popt[0],popt[1],popt[2]),color='red')\n",
    "\n",
    "# Make the plot nicer.\n",
    "#plt.xlim(1.108,1.2)\n",
    "plt.xlabel(r'Mass in $\\frac{GeV}{c^2}$', fontsize=15)\n",
    "plt.ylabel(r'Number of entries')\n",
    "plt.title(r'Lamda baryon')\n",
    "plt.legend(loc='best')\n",
    "axs.text(0.7, 0.95, 'c = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(c0, dc0), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.90, 'd = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(d0, dd0), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.85, 'e = {0:0.1e}$\\pm${1:0.1e}'\n",
    "         .format(d0, de0), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.80, ' $\\chi^{2}_{reduced} $ = '+str(redchisqr), transform = axs.transAxes)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "fig.savefig('hists.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model\n",
    "x=binscenters, \n",
    "y=data_entries\n",
    "\n",
    "#def gaussian(x, amp, cen, wid, c,d,e):\n",
    "#    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "#    return ((amp / (np.sqrt(2*np.pi) * wid)) * np.exp(-(x-cen)**2 / (2*wid**2)))+c+d*x+e*(x**2)\n",
    "\n",
    "\n",
    "gmodel = Model(fit_function)\n",
    "#result = gmodel.fit(y, x=x, amp=3, mean=1.115, std=0.0009, c=20, d=10, e=-10,  method='bfgs')\n",
    "result = gmodel.fit(y, x=x, c=c0, d=d0, e=e0, method='cg')\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "#plt.plot(x, result.init_fit, 'k--', label='initial fit')\n",
    "#plt.plot(x, result.best_fit, 'r-', label='best fit')\n",
    "plt.plot(x_interval_for_fit, fit_function(x_interval_for_fit, result.values['c'],result.values['d'],result.values['e']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Fixing some signal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut3 = test_best\n",
    "mask1 = df_clean['xgb_preds']>cut3\n",
    "df3_base=df_clean[mask1]\n",
    "std_of_gaus = 0.0014\n",
    "# Define fit function.\n",
    "def fit_function(x, amp,c,d,e):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std_of_gaus)) * (np.exp(-(0.5)*((x - 1.1157) / std_of_gaus)**2))+c+d*x+e*(x**2)\n",
    "def background_function(x,c,d,e):\n",
    "    return c+d*x+e*(x**2)\n",
    "\n",
    "def signal_function( x, amp):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std_of_gaus)) * (np.exp(-(0.5)*((x - 1.1157) / std_of_gaus)**2))\n",
    "#def signal_function( x, a):\n",
    "#    return a * (0.0016/2) / ((0.5)* 0.0016**2 + ( x - 1.115683 )**2)\n",
    "\n",
    "#def fit_function( x, a, c,d,e):\n",
    "#    return a * (0.0016/2) / ((0.5)* (0.0016**2) + ( x - 1.115683 )**2)+(c+d*x)++e*(x**2)\n",
    "\n",
    "# 3.) Generate exponential and gaussian data and histograms.\n",
    "data = df3_base['mass']\n",
    "bins = np.linspace(1.1, 1.13, 300)\n",
    "data_entries_1, bins_1 = np.histogram(data, bins=bins)\n",
    "\n",
    "# 4.) Add histograms of exponential and gaussian data.\n",
    "data_entries = data_entries_1 \n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "\n",
    "# 5.) Fit the function to the histogram data.\n",
    "popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, p0=[0,c0,d0,e0])\n",
    "\n",
    "amp1, c1, d1, e1 = popt\n",
    "print(popt)\n",
    "damp1, dc1, dd1, de1 = \\\n",
    "          [np.sqrt(pcov[j,j]) for j in range(popt.size)]\n",
    "\n",
    "resids = data_entries - fit_function(binscenters, amp1, c1, d1, e1)\n",
    "redchisqr = ((resids)**2).sum()/float(bins_1.size-3)\n",
    "print(redchisqr)\n",
    "\n",
    "\n",
    "#popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, p0=[1,-5578.7,10271.68,-4489.33],\n",
    "#                      bounds=[(-1000,-6000,8000,-5000),(1000,-4000,11000,-4050)])\n",
    "\n",
    "# 6.)\n",
    "# Generate enough x values to make the curves look smooth.\n",
    "xspace = np.linspace(1.10, 1.13, 1000000)\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "# Plot the histogram and the fitted function.\n",
    "plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function')\n",
    "\n",
    "\n",
    "plt.plot(xspace,background_function(xspace,popt[1],popt[2],popt[3]),color='red')\n",
    "plt.plot(xspace,signal_function(xspace,popt[0]),color='green')\n",
    "\n",
    "# Make the plot nicer.\n",
    "#plt.xlim(1.108,1.124)\n",
    "plt.xlabel(r'Mass in $\\frac{GeV}{c^2}$', fontsize=15)\n",
    "plt.ylabel(r'Number of entries')\n",
    "plt.title(r'Lamda baryon')\n",
    "plt.legend(loc='best')\n",
    "axs.text(0.7, 0.95, 'amp = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(amp1, damp1), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.90, 'c = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(c1, dc1), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.85, 'd = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(d1, dd1), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.80, 'e = {0:0.1e}$\\pm${1:0.1e}'\n",
    "         .format(d1, de1), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.75, ' $\\chi^{2}_{reduced} $ = '+str(redchisqr), transform = axs.transAxes)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "fig.savefig('hists.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model\n",
    "x=binscenters, \n",
    "y=data_entries\n",
    "\n",
    "gmodel = Model(fit_function)\n",
    "\n",
    "result = gmodel.fit(y, x=x, amp=amp1, c=c1, d=c1, e=e1,  method='lsq')\n",
    "#result = gmodel.fit(y, x=x, a=900, mean=1.1157, gam=0.0009, c=-100, d=100, e=10, method='lsq')\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "#plt.plot(x, result.init_fit, 'k--', label='initial fit')\n",
    "#plt.plot(x, result.best_fit, 'r-', label='best fit')\n",
    "plt.plot(xspace, fit_function(xspace, result.values['amp'],result.values['c'],result.values['d'],\n",
    "                             result.values['e']))\n",
    "\n",
    "plt.plot(xspace,background_function(xspace,result.values['c'],result.values['d'],result.values['e']),color='red')\n",
    "plt.plot(xspace,signal_function(xspace,result.values['amp'])\n",
    "         ,color='green')\n",
    "#plt.legend(loc='best')\n",
    "#plt.show()\n",
    "# <end examp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_function(x, amp, mean,c,d,e):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std_of_gaus)) * (np.exp(-(0.5)*((x - mean) / std_of_gaus)**2))+c+d*x+e*(x**2)\n",
    "def background_function(x,c,d,e):\n",
    "    return c+d*x+e*(x**2)\n",
    "\n",
    "def signal_function( x, amp, mean):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std_of_gaus)) * (np.exp(-(0.5)*((x - mean) / std_of_gaus)**2))\n",
    "#def signal_function( x, a,mean, gam):\n",
    "#    return a * (gam/2) / ((0.5)* gam**2 + ( x - mean )**2)\n",
    "\n",
    "#def fit_function( x, a, mean, gam, c,d,e):\n",
    "#    return a * (gam/2) / ((0.5)* (gam**2) + ( x - mean )**2)+(c+d*x)++e*(x**2)\n",
    "\n",
    "# 3.) Generate exponential and gaussian data and histograms.\n",
    "data = df3_base['mass']\n",
    "bins = np.linspace(1.1, 1.13, 300)\n",
    "data_entries_1, bins_1 = np.histogram(data, bins=bins)\n",
    "\n",
    "# 4.) Add histograms of exponential and gaussian data.\n",
    "data_entries = data_entries_1 \n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "\n",
    "# 5.) Fit the function to the histogram data.\n",
    "popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, \n",
    "                       p0=[amp1,1.11568,c1,d1,e1])\n",
    "\n",
    "#popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, \n",
    "#                       p0=[1.61,1.1156,0.0018,-4.81e+03,8.82e+03,-4.05e+03])\n",
    "amp2, mean2, c2, d2, e2 = popt\n",
    "print(popt)\n",
    "damp2,dmean2, dc2, dd2, de2 = \\\n",
    "          [np.sqrt(pcov[j,j]) for j in range(popt.size)]\n",
    "\n",
    "resids = data_entries - fit_function(binscenters, amp2,mean2, c2, d2, e2)\n",
    "redchisqr = ((resids)**2).sum()/float(bins_1.size-3)\n",
    "print(redchisqr)\n",
    "\n",
    "# 6.)\n",
    "# Generate enough x values to make the curves look smooth.\n",
    "xspace = np.linspace(1.1, 1.13, 1000000)\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "# Plot the histogram and the fitted function.\n",
    "plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function')\n",
    "\n",
    "\n",
    "plt.plot(xspace,background_function(xspace,c2,d2,e2),color='red')\n",
    "plt.plot(xspace,signal_function(xspace,amp2,mean2),color='green')\n",
    "\n",
    "# Make the plot nicer.\n",
    "#plt.xlim(1.108,1.124)\n",
    "plt.xlabel(r'Mass in $\\frac{GeV}{c^2}$', fontsize=15)\n",
    "plt.ylabel(r'Number of entries')\n",
    "plt.title(r'Lamda baryon')\n",
    "plt.legend(loc='best')\n",
    "axs.text(0.7, 0.95, 'amp = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(amp2, damp2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.85, 'mean = {0:e}$\\pm${1:0.1f}'\n",
    "         .format(mean2, dmean2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.80, 'c = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(c2, dc2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.75, 'd = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(d2, dd2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.70, 'e = {0:0.1e}$\\pm${1:0.1e}'\n",
    "         .format(e2, de2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.65, ' $\\chi^{2}_{reduced} $ = '+str(redchisqr), transform = axs.transAxes)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "fig.savefig('hists.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_function(x, amp, std,c,d,e):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std)) * (np.exp(-(0.5)*((x - 1.115693) / std)**2))+c+d*x+e*(x**2)\n",
    "def background_function(x,c,d,e):\n",
    "    return c+d*x+e*(x**2)\n",
    "\n",
    "def signal_function( x, amp, std):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std)) * (np.exp(-(0.5)*((x - 1.115693) / std)**2))\n",
    "#def signal_function( x, a,mean, gam):\n",
    "#    return a * (gam/2) / ((0.5)* gam**2 + ( x - mean )**2)\n",
    "\n",
    "#def fit_function( x, a, mean, gam, c,d,e):\n",
    "#    return a * (gam/2) / ((0.5)* (gam**2) + ( x - mean )**2)+(c+d*x)++e*(x**2)\n",
    "\n",
    "# 3.) Generate exponential and gaussian data and histograms.\n",
    "data = df3_base['mass']\n",
    "bins = np.linspace(1.1, 1.13, 300)\n",
    "data_entries_1, bins_1 = np.histogram(data, bins=bins)\n",
    "\n",
    "# 4.) Add histograms of exponential and gaussian data.\n",
    "data_entries = data_entries_1 \n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "\n",
    "# 5.) Fit the function to the histogram data.\n",
    "popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, \n",
    "                       p0=[amp1,0.0015,c1,d1,e1])\n",
    "\n",
    "#popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, \n",
    "#                       p0=[1.61,1.1156,0.0018,-4.81e+03,8.82e+03,-4.05e+03])\n",
    "amp2, std2, c2, d2, e2 = popt\n",
    "print(popt)\n",
    "damp2,dstd2, dc2, dd2, de2 = \\\n",
    "          [np.sqrt(pcov[j,j]) for j in range(popt.size)]\n",
    "\n",
    "resids = data_entries - fit_function(binscenters, amp2,std2, c2, d2, e2)\n",
    "redchisqr = ((resids)**2).sum()/float(bins_1.size-3)\n",
    "print(redchisqr)\n",
    "\n",
    "# 6.)\n",
    "# Generate enough x values to make the curves look smooth.\n",
    "xspace = np.linspace(1.1, 1.13, 1000000)\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "# Plot the histogram and the fitted function.\n",
    "plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function')\n",
    "\n",
    "\n",
    "plt.plot(xspace,background_function(xspace,c2,d2,e2),color='red')\n",
    "plt.plot(xspace,signal_function(xspace,amp2,std2),color='green')\n",
    "\n",
    "# Make the plot nicer.\n",
    "#plt.xlim(1.108,1.124)\n",
    "plt.xlabel(r'Mass in $\\frac{GeV}{c^2}$', fontsize=15)\n",
    "plt.ylabel(r'Number of entries')\n",
    "plt.title(r'Lamda baryon')\n",
    "plt.legend(loc='best')\n",
    "axs.text(0.7, 0.95, 'amp = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(amp2, damp2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.90, 'std = {0:e}$\\pm${1:0.1f}'\n",
    "         .format(std2, dstd2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.85, 'c = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(c2, dc2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.80, 'd = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(d2, dd2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.75, 'e = {0:0.1e}$\\pm${1:0.1e}'\n",
    "         .format(e2, de2), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.70, ' $\\chi^{2}_{reduced} $ = '+str(redchisqr), transform = axs.transAxes)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "fig.savefig('hists.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "fig, axs = plt.subplots(2, 1,figsize=(15,10), sharex=True,  gridspec_kw={'width_ratios': [10],\n",
    "                           'height_ratios': [8,4]})\n",
    "\n",
    "# Define fit function.\n",
    "def fit_function(x, amp, mean, std,c,d,e):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std)) * (np.exp(-(0.5)*((x - mean) / std)**2))+c+d*x+e*(x**2)\n",
    "def background_function(x,c,d,e):\n",
    "    return c+d*x+e*(x**2)\n",
    "\n",
    "def signal_function( x, amp, mean, std):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std)) * (np.exp(-(0.5)*((x - mean) / std)**2))\n",
    "#def signal_function( x, amp,mean, gam):\n",
    "#    return amp * (gam/2) / ((0.5)* gam**2 + ( x - mean )**2)\n",
    "\n",
    "#def fit_function( x, amp, mean, gam, c,d,e):\n",
    "#    return amp * (gam/2) / ((0.5)* (gam**2) + ( x - mean )**2)+(c+d*x)++e*(x**2)\n",
    "\n",
    "\n",
    "data = df3_base['mass']\n",
    "bins = np.linspace(1.08, 1.2, 300)\n",
    "data_entries_1, bins_1 = np.histogram(data, bins=bins)\n",
    "\n",
    "\n",
    "\n",
    "data_entries = data_entries_1 \n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "\n",
    "# 5.) Fit the function to the histogram data.\n",
    "popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, \n",
    "                       p0=[par2[0],par2[1],par2[2],par2[3],par2[4],par2[5]], method='dogbox')\n",
    "\n",
    "#popt, pcov = curve_fit(fit_function, xdata=binscenters, ydata=data_entries, \n",
    "#                       p0=[1.61,1.1156,0.0018,-4.81e+03,8.82e+03,-4.05e+03])\n",
    "amp2, mean2, std2, c2, d2, e2 = popt\n",
    "print(popt)\n",
    "damp2, dmean2,dstd2, dc2, dd2, de2 = \\\n",
    "          [np.sqrt(pcov[j,j]) for j in range(popt.size)]\n",
    "\n",
    "resids = data_entries - fit_function(binscenters, amp2,mean2,std2, c2, d2, e2)\n",
    "redchisqr = ((resids)**2).sum()/float(bins_1.size-3)\n",
    "print(redchisqr)\n",
    "\n",
    "# 6.)\n",
    "# Generate enough x values to make the curves look smooth.\n",
    "xspace = np.linspace(1.08, 1.2, 1000000)\n",
    "\n",
    "# Plot the histogram and the fitted function.\n",
    "#axs[0].plot(binscenters, data_entries, color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "axs[0].errorbar(x=binscenters, y=data_entries, yerr=(np.sqrt(data_entries)), linestyle='none', marker='.',mfc='red', ms=10, label='Bin data with $\\sqrt{bin\\ count}$')\n",
    "#axs[0].plot(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "axs[0].plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, \n",
    "         label='Fitted function = $\\dfrac{A}{\\sigma\\sqrt{2\\pi}}\\ e^{\\dfrac{1}{2}\\ \\dfrac{(x-\\mu)^2}{\\sigma^2}} +c+dx+ex^2$')\n",
    "\n",
    "#(amp/(np.sqrt(2*np.pi) * std)) * (np.exp(-(0.5)*((x - mean) / std)**2))+c+d*x+e*(x**2)\n",
    "\n",
    "\n",
    "axs[0].plot(xspace,background_function(xspace,c2,d2,e2),color='red',label='Background = $c+dx+ex^2$')\n",
    "axs[0].plot(xspace,signal_function(xspace,amp2,mean2,std2),color='green',label='Signal= $\\dfrac{A}{\\sigma\\sqrt{2\\pi}}\\ e^{\\dfrac{1}{2}\\ \\dfrac{(x-\\mu)^2}{\\sigma^2}}$')\n",
    "\n",
    "# Make the plot nicer.\n",
    "#plt.xlim(1.108,1.124)\n",
    "plt.xlabel(r'Mass in $\\frac{GeV}{c^2}$', fontsize=15)\n",
    "plt.ylabel(r'Number of entries')\n",
    "axs[0].set_title(r'Lamda baryon')\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[0].text(0.7, 0.95, 'amp = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(amp2, damp2), transform = axs[0].transAxes)\n",
    "axs[0].text(0.7, 0.90, 'mean = {0:e}$\\pm${1:0.1f}'\n",
    "         .format(mean2, dmean2), transform = axs[0].transAxes)\n",
    "axs[0].text(0.7, 0.85, 'std = {0:e}$\\pm${1:0.1f}'\n",
    "         .format(std2, dstd2), transform = axs[0].transAxes)\n",
    "axs[0].text(0.7, 0.80, 'c = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(c2, dc2), transform = axs[0].transAxes)\n",
    "axs[0].text(0.7, 0.75, 'd = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(d2, dd2), transform = axs[0].transAxes)\n",
    "axs[0].text(0.7, 0.70, 'e = {0:0.1e}$\\pm${1:0.1e}'\n",
    "         .format(e2, de2), transform = axs[0].transAxes)\n",
    "axs[0].text(0.7, 0.65, ' $\\chi^{2}_{reduced} $ = '+str(redchisqr), transform = axs[0].transAxes)\n",
    "\n",
    "axs[1].plot(binscenters,(data_entries - fit_function(binscenters,*popt))/np.sqrt(data_entries))\n",
    "axs[1].hlines(y = 0,xmin=1,xmax=1.3, color='r', linestyle='-')\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel('$\\dfrac{y-f(x)}{\\sqrt{bin\\ count}}$')\n",
    "\n",
    "axs[0].set_xlim([1.107,1.125])\n",
    "axs[1].set_xlim([1.107,1.125])\n",
    "plt.show()\n",
    "plt.clf()\n",
    "fig.tight_layout()\n",
    "fig.savefig('hists.png')\n",
    "#pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entries_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mids = 0.5*(bins[1:] + bins[:-1])\n",
    "mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Model\n",
    "x=binscenters, \n",
    "y=data_entries\n",
    "\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig, axs = plt.subplots(2, 1,figsize=(15,10), sharex=True,  gridspec_kw={'width_ratios': [10],\n",
    "                           'height_ratios': [8,4]})\n",
    "\n",
    "#def gaussian(x, amp, cen, wid, c,d,e):\n",
    "#    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "#    return ((amp / (np.sqrt(2*np.pi) * wid)) * np.exp(-(x-cen)**2 / (2*wid**2)))+c+d*x+e*(x**2)\n",
    "\n",
    "gmodel = Model(fit_function)\n",
    "\n",
    "result = gmodel.fit(y, x=x, amp=par2[0], mean=par2[1], std=par2[2], c=par2[3], d=par2[4], e=par2[5], method='powel')\n",
    "#result = gmodel.fit(y, x=x, a=900, mean=1.1157, gam=0.0009, c=-100, d=100, e=10, method='lsq')\n",
    "\n",
    "print(result.fit_report())\n",
    "\n",
    "\n",
    "axs[0].errorbar(x=binscenters, y=data_entries, yerr=(np.sqrt(data_entries)), linestyle='none', marker='.',mfc='red', ms=10, label='Bin data with $\\sqrt{bin\\ count}$')\n",
    "#plt.plot(x, result.init_fit, 'k--', label='initial fit')\n",
    "#plt.plot(x, result.best_fit, 'r-', label='best fit')\n",
    "\n",
    "axs[0].plot(xspace, fit_function(xspace, result.values['amp'],result.values['mean'],result.values['std']\n",
    "                          ,result.values['c'],result.values['d'],result.values['e']),color='darkorange', linewidth=2.5, \n",
    "         label='Fitted function = $\\dfrac{A}{\\sigma\\sqrt{2\\pi}}\\ e^{\\dfrac{1}{2}\\ \\dfrac{(x-\\mu)^2}{\\sigma^2}} +c+dx+ex^2$')\n",
    "\n",
    "axs[0].plot(xspace,background_function(xspace,result.values['c'],result.values['d'],result.values['e']),color='red',label='Background = $c+dx+ex^2$')\n",
    "axs[0].plot(xspace,signal_function(xspace,result.values['amp'],result.values['mean'],result.values['std'])\n",
    "         ,color='green',label='Signal= $\\dfrac{A}{\\sigma\\sqrt{2\\pi}}\\ e^{\\dfrac{1}{2}\\ \\dfrac{(x-\\mu)^2}{\\sigma^2}}$')\n",
    "#axs[0].plot(binscenters, result.init_fit[0], 'k--', label='initial fit')\n",
    "\n",
    "\n",
    "fitted_func = fit_function(binscenters, result.values['amp'],result.values['mean'],result.values['std']\n",
    "                          ,result.values['c'],result.values['d'],result.values['e'])\n",
    "axs[1].plot(binscenters,(data_entries - fitted_func)/np.sqrt(data_entries))\n",
    "axs[1].hlines(y = 0,xmin=1,xmax=1.3, color='r', linestyle='-')\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel('$\\dfrac{y-f(x)}{\\sqrt{bin\\ count}}$')\n",
    "\n",
    "axs[0].legend(loc='upper left')\n",
    "axs[0].set_xlim([1.107,1.125])\n",
    "axs[1].set_xlim([1.107,1.125])\n",
    "axs[1].set_ylim([-4,7])\n",
    "plt.show()\n",
    "#plt.show()\n",
    "# <end examp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def signal_function( x, a,mean, gam):\n",
    "#    return a * (gam/2) / ((0.5)* (gam**2) + ( x - mean)**2)\n",
    "\n",
    "def signal_function( x, amp, mean, std):\n",
    "    return (amp/(np.sqrt(2*np.pi) * std)) * (np.exp(-(0.5)*((x - mean) / std)**2))\n",
    "\n",
    "# 3.) Generate exponential and gaussian data and histograms.\n",
    "data = df_scaled[df_scaled['issignal']==1]['mass']\n",
    "bins = np.linspace(1.105, 1.126, 300)\n",
    "\n",
    "bins0 = np.linspace(1.105, 1.112, 10).reshape((10,1))\n",
    "bins1 = np.linspace(1.112, 1.12, 60).reshape((60,1))\n",
    "bins2 = np.linspace(1.12, 1.126,10).reshape((10,1))\n",
    "bins3 = np.concatenate((bins0,bins1,bins2)).reshape((80,1))\n",
    "#bins =bins3.flatten()\n",
    "#bins3 = np.concatenate(bins0,bins1,bins2)\n",
    "#bins = np.array(bins3).reshape(80,1)\n",
    "data_entries_1, bins_1 = np.histogram(data, bins=bins)\n",
    "\n",
    "# 4.) Add histograms of exponential and gaussian data.\n",
    "data_entries = data_entries_1 \n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "\n",
    "#popt, pcov = curve_fit(signal_function, xdata=binscenters, ydata=data_entries, p0=[10,1.115,0.0001],\n",
    "#                      method='trf')\n",
    "\n",
    "popt, pcov = curve_fit(signal_function, xdata=binscenters, ydata=data_entries, p0=[0,1.1156,0.1],\n",
    "                      method='trf')\n",
    "\n",
    "amp, mean, std = popt\n",
    "print(popt)\n",
    "damp, dmean, dstd = \\\n",
    "          [np.sqrt(pcov[j,j]) for j in range(popt.size)]\n",
    "\n",
    "resids = data_entries - signal_function(binscenters, amp, mean, std)\n",
    "redchisqr = ((resids)**2).sum()/float(bins_1.size-3)\n",
    "print(redchisqr)\n",
    "# 6.)\n",
    "# Generate enough x values to make the curves look smooth.\n",
    "xspace = np.linspace(1.105, 1.126, 1000000)\n",
    "fig, axs = plt.subplots(figsize=(15, 10))\n",
    "# Plot the histogram and the fitted function.\n",
    "plt.bar(binscenters, data_entries, width=bins[1] - bins[0], color='navy',alpha = 0.5, label=r'Histogram entries')\n",
    "\n",
    "plt.plot(xspace,signal_function(xspace,amp,mean,std),color='green', label='Fit')\n",
    "\n",
    "# Make the plot nicer.\n",
    "#plt.xlim(1.108,1.124)\n",
    "plt.xlabel(r'Mass in $\\frac{GeV}{c^2}$', fontsize=15)\n",
    "plt.ylabel(r'Number of entries')\n",
    "plt.title(r'Lamda baryon')\n",
    "plt.legend(loc='best')\n",
    "axs.text(0.7, 0.95, 'amp = {0:0.1f}$\\pm${1:0.1f}'\n",
    "         .format(amp, damp), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.90, 'mean = {0:e}$\\pm${1:0.1f}'\n",
    "         .format(mean, dmean), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.85, 'std = {0:e}$\\pm${1:0.1e}'\n",
    "         .format(std, dstd), transform = axs.transAxes)\n",
    "axs.text(0.7, 0.80, ' $\\chi^{2}_{reduced} $ = '+str(redchisqr), transform = axs.transAxes)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "fig.savefig('hists.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TF1, TCanvas,TMath, TColor\n",
    "%jsroot on\n",
    "h = ROOT.TH1F(\"gauss\",\"Example histogram\",300,1.08,1.2)\n",
    "for i in range(0,df3_base['mass'].shape[0]):\n",
    "    h.Fill(df3_base['mass'].iloc[i])\n",
    "\n",
    "f = TF1(\"total\",\"[0]*exp(-0.5*((x-[1])/[2])^2)+[3]+[4]*x+[5]*x*x\",1.08,1.2);\n",
    "f.SetNpx(1000);\n",
    "f.SetParameters(13852.2,1.11806,0.00446980,-0.0271897,-0.0266959,-0.0260058);\n",
    "c = ROOT.TCanvas(\"myCanvasName\",\"The Canvas Title\",800,600)\n",
    "h.Fit(f,\"RNI\");\n",
    "print(\"chi2\",f.GetChisquare())\n",
    "par = f.GetParameters()\n",
    "\n",
    "c.Draw()\n",
    "\n",
    "\n",
    "h.Draw()\n",
    "f.Draw(\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_base=df_clean[df_clean['xgb_preds']>test_best]\n",
    "low_pt_below_mid_rapidity_cut = df3_base[(df3_base['rapidity']<1.5996) & (df3_base['pT']<0.52)]\n",
    "df1 = low_pt_below_mid_rapidity_cut[(low_pt_below_mid_rapidity_cut['mass']<1.108)]\n",
    "df2 = low_pt_below_mid_rapidity_cut[low_pt_below_mid_rapidity_cut['mass']>1.13]\n",
    "df3 = pd.concat([df1, df2])\n",
    "\n",
    "data = df3['mass']\n",
    "h = ROOT.TH1F(\"Background\",\"Background without peak\",300,1.08,1.2)\n",
    "for i in range(0,data.shape[0]):\n",
    "    h.Fill(data.iloc[i])\n",
    "\n",
    "f = TF1(\"total\",\"[0]+[1]*x+[2]*x*x\",1.08,1.2);\n",
    "f.SetNpx(1000);\n",
    "f.SetParameters(13852.2,1.11806,0.00446980,-0.0271897,-0.0266959,-0.0260058);\n",
    "c = ROOT.TCanvas(\"myCanvasName\",\"The Canvas Title\",800,600)\n",
    "h.Fit(f,\"RNIFCWW\");\n",
    "print(\"chi2\",f.GetChisquare()/f.GetNDF())\n",
    "par = f.GetParameters()\n",
    "\n",
    "c.Draw()\n",
    "\n",
    "\n",
    "h.Draw()\n",
    "f.Draw(\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = low_pt_below_mid_rapidity_cut['mass']\n",
    "h = ROOT.TH1F(\"B_and_S\",\"Background with signal some free parameters\",300,1.08,1.2)\n",
    "for i in range(0,data.shape[0]):\n",
    "    h.Fill(data.iloc[i])\n",
    "\n",
    "\n",
    "f1 = TF1(\"total\",\"[0]*exp(-0.5*((x-1.115683)/0.0014)^2)+[1]+[2]*x+[3]*x*x\",1.08,1.2);\n",
    "f.SetNpx(1000);\n",
    "f1.SetParameters(1,par[0],par[1],par[2]);\n",
    "c = ROOT.TCanvas(\"myCanvasName\",\"The Canvas Title\",800,600)\n",
    "h.Fit(f1,\"RNI\");\n",
    "print(\"chi2\",f.GetChisquare()/f2.GetNDF())\n",
    "par1 = f1.GetParameters()\n",
    "\n",
    "c.Draw()\n",
    "\n",
    "\n",
    "h.Draw(\"E1\")\n",
    "f1.Draw(\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "data = low_pt_below_mid_rapidity_cut['mass']\n",
    "#ROOT.gStyle.SetOptStat(0);\n",
    "h1 = ROOT.TH1F(\"B_&_S\",\"rapidity<1.5996 & pT<0.4\",100,1.10,1.2)\n",
    "h2 = ROOT.TH1F(\"h2\", \"\", 100, 1.10, 1.2);\n",
    "h3 = ROOT.TH1F(\"h2\", \"\", 100, 1.10, 1.2);\n",
    "for i in range(0,data.shape[0]):\n",
    "    h1.Fill(data.iloc[i])\n",
    "\n",
    "pi=TMath.Pi()\n",
    "f2 = TF1(\"full\",\"[0]*exp(-0.5*((x-[1])/[2])^2)+[3]+[4]*x+[5]*x*x\",1.08,1.2);\n",
    "f2.SetNpx(1000);\n",
    "f2.SetParameters(par1[0],1.116,0.001,par1[1],par1[2],par1[3]);\n",
    "f2.SetLineColor(ROOT.kRed)\n",
    "c = ROOT.TCanvas(\"myCanvasName\",\"The Canvas Title\",1000,1000)\n",
    "h1.Fit(f2,\"MNIR\");\n",
    "#TVirtualFitter::SetDefaultFitter(\"Minuit\");\n",
    "#h1.SetFillColor(kGreen);\n",
    "h1.SetFillStyle(3003);\n",
    "h1.SetLineWidth(2)\n",
    "h1.SetStats (0)\n",
    "h1.SetYTitle(\"Entries\")\n",
    "h1.SetLabelSize(0.04)\n",
    "h1.SetLineColor(ROOT.kBlack)\n",
    "h1.GetXaxis().SetTitle(\"Mass #frac{[GeV]}{c^2}\")\n",
    "#h2.SetMarkerColor(2)\n",
    "#h1.SetTitle(\"Entries with Gaussian plus 2nd order polynom bac\")\n",
    "c.Clear()\n",
    "hs.Add(h1);\n",
    "c.Divide (1,2)\n",
    "c.Draw()\n",
    "c.cd(1);\n",
    "h1.Draw(\"pe\")\n",
    "fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[1])/[2])^2)\",1.08,1.2);\n",
    "fs.SetNpx(1000);\n",
    "fs.SetLineColor(ROOT.kGreen)\n",
    "fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",1.08,1.2)\n",
    "fb.SetLineStyle(2)\n",
    "fb.SetLineColor(ROOT.kBlue)\n",
    "fb.SetNpx(1000);\n",
    "fs.SetParameters(f2.GetParameter(0),f2.GetParameter(1),f2.GetParameter(2));\n",
    "fb.SetParameters(f2.GetParameter(3),f2.GetParameter(4),f2.GetParameter(5));\n",
    "fs.Draw(\"SAME\")\n",
    "fb.Draw(\"SAME\")\n",
    "f2.Draw(\"SAME\")\n",
    "#h1.Sumw2();\n",
    "\n",
    "bin1 = h1.FindBin(1.1);\n",
    "bin2 = h1.FindBin(1.2);\n",
    "print(\"red chi2\",f2.GetChisquare()/((bin2-bin1+1)-6))\n",
    "par2 = f2.GetParameters()\n",
    "for i in range(bin1,bin2):\n",
    "    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "    t_value = h1.GetBinContent(i)\n",
    "    h2.SetBinContent(i,f_value)\n",
    "    h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "#h1.Draw(\"SAME\")\n",
    "#h1.SetLineColor(kRed);\n",
    "h2.Sumw2()\n",
    "\n",
    "hs.Add(h2);\n",
    "#h2.Draw(\"SAME\")\n",
    "#hs.Draw(\"nostack\")\n",
    "#h2.Draw(\"SAME\")\n",
    "\n",
    "integral_min = f2.GetParameter(1) - (TMath.Abs(3*f2.GetParameter(2)));\n",
    "integral_max = f2.GetParameter(1) + (TMath.Abs( 3*f2.GetParameter(2)));\n",
    "\n",
    "\n",
    "\n",
    "#To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "#(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "\n",
    "integral_min = f2.GetParameter(1) - (TMath.Abs(3*f2.GetParameter(2)));\n",
    "integral_max = f2.GetParameter(1) + (TMath.Abs( 3*f2.GetParameter(2)));\n",
    "\n",
    "\n",
    "#To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "print(tot)\n",
    "\n",
    "#To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "signal_under_peak = fs.Integral(integral_min,integral_max)/binwidth;\n",
    "print(signal_under_peak)\n",
    "\n",
    "#Background\n",
    "backgnd_under_peak = tot-signal_under_peak;\n",
    "print(backgnd_under_peak)\n",
    "\n",
    "#Significance = signal/(signal+background)^0.5\n",
    "Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "print(Significance)\n",
    "\n",
    "legend = ROOT.TLegend(0.9,0.9,0.6,0.5);\n",
    "legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "legend.AddEntry(f2,\"Ae^{-#frac{1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}+b+cx+dx^{2}\",\"l\");\n",
    "legend.AddEntry(fs,\"Ae^{-#frac{1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}\",\"l\");\n",
    "legend.AddEntry(fb,\"b+cx+dx^{2}\",\"l\");\n",
    "#legend.AddEntry((ROOT.TObject), ROOT.Form(\"Total : %f\"%tot));\n",
    "#legend.AddEntry((TObject), ROOT.Form(\"Signal : %f\"%signal_under_peak));\n",
    "#legend.AddEntry((TObject), ROOT.Form(\"Background : %f \"%backgnd_under_peak));\n",
    "#legend.AddEntry((TObject), ROOT.Form(\"Significance in sigma: %f\"%Significance));\n",
    "\n",
    "legend.Draw()\n",
    "#rp = ROOT.TRatioPlot(h1, h2);\n",
    "#rp.Draw(\"E1\");\n",
    "#h1.Sumw2();\n",
    "c.cd(2)\n",
    "#h3=(h1-h2)\n",
    "h3.SetLineColor(TColor.GetColor(5))\n",
    "h3.SetYTitle(\"D-f/dl\")\n",
    "h3.Draw()\n",
    "f0 = TF1(\"f0\",\"[0]\",1.08,1.2)\n",
    "f0.SetParameters(0)\n",
    "f0.Draw(\"SAME\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c.Update()\n",
    "#c.SaveAs(\"picture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "data = low_pt_below_mid_rapidity_cut['mass']\n",
    "\n",
    "canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "canvas .Clear ()\n",
    "canvas.Draw()\n",
    "pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "pad1 . Draw ()\n",
    "pad1 . cd ()\n",
    "pad1. Clear()\n",
    "\n",
    "\n",
    "#ROOT.gStyle.SetOptStat(0);\n",
    "h1 = ROOT.TH1F(\"B_&_S\",\"rapidity<1.5996 & pT<0.5\",100,1.10,1.2)\n",
    "h1.SetTitleOffset(-1)\n",
    "h1.SetFillStyle(3003);\n",
    "h1.SetLineWidth(2)\n",
    "h1.SetStats (0)\n",
    "h1.SetYTitle(\"Entries\")\n",
    "#h1.SetLabelSize(0.0)\n",
    "h1.SetLineColor(ROOT.kBlack)\n",
    "#h1.GetXaxis().SetTitle(\"Mass #frac{[GeV]}{c^2}\")\n",
    "h2 = ROOT.TH1F(\"h2\", \"\", 100, 1.10, 1.2);\n",
    "h3 = ROOT.TH1F(\"h2\", \"\", 100, 1.10, 1.2);\n",
    "h3.SetLineWidth(2)\n",
    "h3.SetStats (0)\n",
    "#h3.SetLabelSize(0.11)\n",
    "h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "for i in range(0,data.shape[0]):\n",
    "    h1.Fill(data.iloc[i])\n",
    "\n",
    "pi=TMath.Pi()\n",
    "f2 = TF1(\"full\",\"[0]*exp(-0.5*((x-[1])/[2])^2)+[3]+[4]*x+[5]*x*x\",1.08,1.2);\n",
    "f2.SetNpx(100000);\n",
    "f2.SetParameters(par1[0],1.115,0.001,par1[1],par1[2],par1[3]);\n",
    "f2.SetLineColor(ROOT.kRed)\n",
    "h1.Fit(f2,\"MNIR\");\n",
    "\n",
    "\n",
    "h1.Draw(\"pe\")\n",
    "fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[1])/[2])^2)\",1.08,1.2);\n",
    "fs.SetNpx(100000);\n",
    "fs.SetLineColor(ROOT.kGreen)\n",
    "fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",1.08,1.2)\n",
    "fb.SetLineStyle(4)\n",
    "fb.SetLineColor(ROOT.kBlue)\n",
    "fb.SetNpx(100000);\n",
    "fs.SetParameters(f2.GetParameter(0),f2.GetParameter(1),f2.GetParameter(2));\n",
    "fb.SetParameters(f2.GetParameter(3),f2.GetParameter(4),f2.GetParameter(5));\n",
    "fs.Draw(\"SAME\")\n",
    "fb.Draw(\"SAME\")\n",
    "f2.Draw(\"SAME\")\n",
    "\n",
    "#h1.Sumw2();\n",
    "\n",
    "bin1 = h1.FindBin(1.1);\n",
    "bin2 = h1.FindBin(1.2);\n",
    "\n",
    "print(\"red chi2\",f2.GetChisquare()/((bin2-bin1+1)-6))\n",
    "chi2 = f2 . GetChisquare ()\n",
    "ndf = f2 . GetNDF ()\n",
    "par2 = f2.GetParameters()\n",
    "for i in range(bin1,bin2):\n",
    "    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "    t_value = h1.GetBinContent(i)\n",
    "    h2.SetBinContent(i,f_value)\n",
    "    h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "#h1.Draw(\"SAME\")\n",
    "#h1.SetLineColor(kRed);\n",
    "h2.Sumw2()\n",
    "\n",
    "hs.Add(h2);\n",
    "#h2.Draw(\"SAME\")\n",
    "#hs.Draw(\"nostack\")\n",
    "#h2.Draw(\"SAME\")\n",
    "\n",
    "integral_min = f2.GetParameter(1) - (TMath.Abs(3*f2.GetParameter(2)));\n",
    "integral_max = f2.GetParameter(1) + (TMath.Abs( 3*f2.GetParameter(2)));\n",
    "\n",
    "\n",
    "\n",
    "#To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "#(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "\n",
    "integral_min = f2.GetParameter(1) - (TMath.Abs(3*f2.GetParameter(2)));\n",
    "integral_max = f2.GetParameter(1) + (TMath.Abs( 3*f2.GetParameter(2)));\n",
    "\n",
    "\n",
    "#To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "print(tot)\n",
    "\n",
    "#To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "signal_under_peak = fs.Integral(integral_min,integral_max)/binwidth;\n",
    "print(signal_under_peak)\n",
    "\n",
    "#Background\n",
    "backgnd_under_peak = tot-signal_under_peak;\n",
    "print(backgnd_under_peak)\n",
    "\n",
    "#Significance = signal/(signal+background)^0.5\n",
    "Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "print(Significance)\n",
    "\n",
    "std = f2 . GetParameter (2)\n",
    "latex = ROOT . TLatex ()\n",
    "latex . SetNDC ()\n",
    "latex . SetTextSize (0.02)\n",
    "latex . DrawText (0.4 ,0.45, \" Significance = %.1f /sqrt(%.1f+%.1f)= %.1f\"%(signal_under_peak,signal_under_peak,backgnd_under_peak,Significance ))\n",
    "latex . DrawText (0.4 ,0.35, \" Std = %.4f GeV\"%( std ))\n",
    "latex . DrawText (0.4 ,0.25,\" chi2 / ndof = %.1f/%d = %.1f\"%(\n",
    "chi2 , ndf , chi2 / ndf ))\n",
    "\n",
    "legend = ROOT.TLegend(0.9,0.8,0.6,0.5);\n",
    "legend.AddEntry(h1,\"Invariant mass of lambda\",\"lep\");\n",
    "legend.AddEntry(f2,\"Ae^{#frac{-1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}+b+cx+dx^{2}\",\"l\");\n",
    "legend.AddEntry(fs,\"Ae^{#frac{-1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}\",\"l\");\n",
    "legend.AddEntry(fb,\"b+cx+dx^{2}\",\"l\");\n",
    "legend . SetLineWidth (0)\n",
    "#legend.AddEntry((ROOT.TObject), ROOT.Form(\"Total : %f\"%tot));\n",
    "#legend.AddEntry((TObject), ROOT.Form(\"Signal : %f\"%signal_under_peak));\n",
    "#legend.AddEntry((TObject), ROOT.Form(\"Background : %f \"%backgnd_under_peak));\n",
    "#legend.AddEntry((TObject), ROOT.Form(\"Significance in sigma: %f\"%Significance));\n",
    "\n",
    "legend.Draw()\n",
    "#rp = ROOT.TRatioPlot(h1, h2);\n",
    "#rp.Draw(\"E1\");\n",
    "#h1.Sumw2();\n",
    "\n",
    "\n",
    "canvas . cd ()\n",
    "pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "pad2 . Draw ()\n",
    "pad2 . cd ()\n",
    "pad2.Clear()\n",
    "\n",
    "#h3=(h1-h2)\n",
    "h3.SetLineColor(TColor.GetColor(5))\n",
    "h3.SetYTitle(\"d-f/#Deltad\")\n",
    "h3.Draw()\n",
    "line = ROOT . TLine (1.1,0 ,1.2 ,0)\n",
    "line . SetLineColor ( ROOT . kRed )\n",
    "line . SetLineWidth (2)\n",
    "line . Draw (\" same \")\n",
    "\n",
    "\n",
    "pad1 . SetBottomMargin (0)\n",
    "pad2 . SetTopMargin (0)\n",
    "pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "h1 . GetXaxis (). SetLabelSize (0)\n",
    "h1 . GetXaxis (). SetTitleSize (0)\n",
    "h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "\n",
    "h3 . SetTitle (\"\")\n",
    "h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "#ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "#207,512 divisions\n",
    "h3 . GetYaxis (). SetNdivisions (207)\n",
    "h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "\n",
    "\n",
    "canvas.Update()\n",
    "canvas.Print(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/picture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenztian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on\n",
    "from ROOT import TMath\n",
    "data = low_pt_below_mid_rapidity_cut['mass']\n",
    "ROOT.gStyle.SetOptStat(0);\n",
    "h1 = ROOT.TH1F(\"B_&_S\",\"\",50,1.10,1.14)\n",
    "h2 = ROOT.TH1F(\"h2\", \"h2\", 50, 1.10, 1.14);\n",
    "h3 = ROOT.TH1F(\"h2\", \"h2\", 50, 1.10, 1.14);\n",
    "for i in range(0,data.shape[0]):\n",
    "    h1.Fill(data.iloc[i])\n",
    "\n",
    "hs =ROOT.THStack(\"hs\",\"\");\n",
    "\n",
    "\n",
    "pi=TMath.Pi()\n",
    "f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x\",1.08,1.2);\n",
    "f2.SetNpx(1000);\n",
    "f2.SetLineColor(TColor.GetColor(5))\n",
    "f2.SetParameters(1,0.0001,1.1156,par1[1],par1[2],par1[3]);\n",
    "c = ROOT.TCanvas(\"myCanvasName\",\"The Canvas Title\",1000,1000)\n",
    "h1.Fit(f2,\"MIRN\");\n",
    "#TVirtualFitter::SetDefaultFitter(\"Minuit\");\n",
    "#h1.SetFillColor(kGreen);\n",
    "h1.SetFillStyle(3003);\n",
    "h1.SetLineWidth(2)\n",
    "Red = ROOT.TColor.GetColor(1)\n",
    "#h1.SetFillColor(Red);\n",
    "#h1.SetLineColor(Red)\n",
    "h1.SetYTitle(\"Entries\")\n",
    "h1.SetLabelSize(0.04)\n",
    "h2.SetMarkerColor(2)\n",
    "#h1.SetTitle(\"Entries with Gaussian plus 2nd order polynom bac\")\n",
    "print(\"red chi2\",f2.GetChisquare()/((bin2-bin1+1)-6))\n",
    "\n",
    "par2 = f2.GetParameters()\n",
    "hs.Add(h1);\n",
    "c.Divide (1,2)\n",
    "c.Draw()\n",
    "c.cd(1);\n",
    "h1.Draw(\"E\")\n",
    "fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",1.08,1.2);\n",
    "fs.SetNpx(1000);\n",
    "fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",1.08,1.2)\n",
    "fb.SetLineStyle(2)\n",
    "fb.SetNpx(1000);\n",
    " \n",
    "fs.SetParameters(f2.GetParameter(0),f2.GetParameter(1),f2.GetParameter(2));\n",
    "fb.SetParameters(f2.GetParameter(3),f2.GetParameter(4),f2.GetParameter(5));\n",
    "fs.Draw(\"SAME\")\n",
    "fb.Draw(\"SAME\")\n",
    "f2.Draw(\"SAME\")\n",
    "#h1.Sumw2();\n",
    "\n",
    "\n",
    "bin1 = h1.FindBin(1.11);\n",
    "bin2 = h1.FindBin(1.124);\n",
    "for i in range(bin1,bin2):\n",
    "    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "    t_value = h1.GetBinContent(i)\n",
    "    h2.SetBinContent(i,f_value)\n",
    "    h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "#h1.Draw(\"SAME\")\n",
    "#h1.SetLineColor(kRed);\n",
    "h2.Sumw2()\n",
    "\n",
    "hs.Add(h2);\n",
    "#h2.Draw(\"SAME\")\n",
    "#hs.Draw(\"nostack\")\n",
    "#h2.Draw(\"SAME\")\n",
    "legend = ROOT.TLegend(0.9,0.9,0.6,0.5);\n",
    "legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+b+cx+dx^{2}\",\"l\");\n",
    "legend.AddEntry(fs,\"Ae^{-#frac{1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}\",\"l\");\n",
    "legend.AddEntry(fb,\"b+cx+dx^{2}\",\"l\");\n",
    "legend.Draw()\n",
    "#rp = ROOT.TRatioPlot(h1, h2);\n",
    "#rp.Draw(\"E1\");\n",
    "#h1.Sumw2();\n",
    "c.cd(2)\n",
    "#h3=(h1-h2)\n",
    "h3.SetLineColor(TColor.GetColor(5))\n",
    "h3.SetYTitle(\"D-f/dl\")\n",
    "h3.Draw()\n",
    "f0 = TF1(\"f0\",\"[0]\",1.08,1.2)\n",
    "f0.SetParameters(0)\n",
    "f0.Draw(\"SAME\")\n",
    "\n",
    "\n",
    "c.Update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pT_vs_rapidity(df, var_xaxis , var_yaxis , range_var_xaxis, range_var_yaxis):\n",
    "    import matplotlib as mpl\n",
    "    fig, axs = plt.subplots(figsize=(15, 10))\n",
    "    h=plt.hist2d(df[var_xaxis],df[var_yaxis],range=[range_var_xaxis,range_var_yaxis], bins=100, norm=mpl.colors.LogNorm())\n",
    "    cbar = fig.colorbar(h[3])\n",
    "    plt.vlines(x=1.59,ymin=-1,ymax=4, color='r', linestyle='-')\n",
    "    #plt.vlines(x=2.0,ymin=-1,ymax=4, color='r', linestyle='-')\n",
    "    plt.hlines(y=0.4, xmin=-0.1, xmax=3.5, colors='b', linestyles='solid', label='')\n",
    "    #plt.hlines(y=0.9, xmin=-0.1, xmax=3.5, colors='b', linestyles='solid', label='')\n",
    "    plt.xlabel(''+var_xaxis, fontsize=15)\n",
    "    plt.ylabel(''+var_yaxis, fontsize=15)\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/pT_vs_rapidity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1=[-0.1, 3.5]\n",
    "range2=[-0.5, 3.5]\n",
    "\n",
    "pT_vs_rapidity(df3_base,'rapidity','pT', range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_rapidity_cut = df3_base[(df3_base['rapidity']<2) & (df3_base['rapidity']>0.8) &(df3_base['pT']>0.15)\n",
    "                           &(df3_base['pT']<0.9)]\n",
    "pT_vs_rapidity(pt_rapidity_cut,'rapidity','pT', range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pt_above_mid_rapidity_cut = df3_base[(df3_base['rapidity']>1.5996) & (df3_base['pT']>0.9)]\n",
    "pT_vs_rapidity(high_pt_above_mid_rapidity_cut,'rapidity','pT', range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pT_vs_rapidity(low_pt_below_mid_rapidity_cut,'rapidity','pT', range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
