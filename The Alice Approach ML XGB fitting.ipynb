{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:purple; font-style:bold\"><br>Cuts Optimization using Extra Gradient Boosting\n",
    "<br></p><br>\n",
    "\n",
    "Over the last years, **Machine Learning** tools have been successfully applied to problems in high-energy physics. For example, for the classification of physics objects. Supervised machine learning algorithms allow for significant improvements in classification problems by taking into account observable correlations and by learning the optimal selection from examples, e.g. from Monte Carlo simulations.\n",
    "\n",
    "\n",
    "# Importing the Libraries\n",
    "\n",
    "**Numpy** is a powerful library that makes working with python more efficient, so we will import it and use it as np in the code. **Pandas** is another useful library that is built on numpy and has two great objects *series* and *dataframework*. Pandas works great for *data ingestion* and also has *data visualization* features. From **Hipe4ml** we import **TreeHandler** and with the help of this function we will import our *Analysis Tree* to our notebook.\n",
    "\n",
    "**Matplotlib** comes handy in plotting data while the machine learning is performed by **XGBOOST**. We will import data splitter from **Scikit-learn** as *train_test_split*. **Evaluation metrics** such as *confusion matrix*, *Receiver operating characteristic (ROC)*, and *Area Under the Receiver Operating Characteristic Curve (ROC AUC)*  will be used to asses our models.\n",
    "\n",
    "A **Confusion Matrix** $C$ is such that $C_{ij}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$. Thus in binary classification, the count of true positives is $C_{00}$, false negatives $C_{01}$,false positives is $C_{10}$, and true neagtives is $C_{11}$.\n",
    "\n",
    "If $ y^{'}_{i} $ is the predicted value of the $ i$-th sample and $y_{i}$ is the corresponding true value, then the fraction of correct predictions over $ n_{samples}$ is defined as \n",
    "$$\n",
    "True \\: positives (y,y^{'}) =  \\sum_{i=1}^{n_{samples} } 1 (y^{'}_{i} = y_{i}=1)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import weakref \n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "#from root_pandas import read_root\n",
    "\n",
    "\n",
    "from data_cleaning import clean_df\n",
    "from KFPF_lambda_cuts import KFPF_lambda_cuts\n",
    "from plot_tools import AMS, preds_prob, plot_confusion_matrix\n",
    "from tree_importer import tree_importer\n",
    "import uproot\n",
    "\n",
    "\n",
    "#To save some memory we will delete unused variables\n",
    "class TestClass(object): \n",
    "    def check(self): \n",
    "        print (\"object is alive!\") \n",
    "    def __del__(self): \n",
    "        print (\"object deleted\") \n",
    "        \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "executor = ThreadPoolExecutor(8)\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data\n",
    "CBM has a modified version of the cern's root software and it contains the simulated setup of CBM. Normally, a model generated input file, for example a URQMD 12 AGeV, is passed through different macros. These macros represent the CBM setup and it is like taking particles and passing them through a detector. These particles are registered as hits in the setup. Then particles' tracks are reconstructed from these hits using cellular automaton and Kalman Filter mathematics.\n",
    "\n",
    "\n",
    "CBM uses the **tree** format of cern root to store information. To reduce the size of these root files a modified tree file was created by the name of Analysis tree. This Analysis tree file contains most of the information that we need for physics analysis. \n",
    "\n",
    "In this example, we download three Analysis Trees. The first one contains mostly background candidates for lambda i.e. protons and pions which do not come from a lambda. The second file contains mostly signal candidates of lamba i.e. it contains protons and pions which come from a lambda decay. The third one contains 10k events generated using URQMD generator with 12 AGeV energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import three root files into our jupyter notebook\n",
    "signal = tree_importer('/home/shahid/cbmsoft/Data/PFSimplePlainTreeSignal.root','PlainTree')\n",
    "# We only select lambda candidates\n",
    "sgnal = signal[(signal['LambdaCandidates_is_signal']==1) & (signal['LambdaCandidates_mass']>1.108)\n",
    "               & (signal['LambdaCandidates_mass']<1.1227)]\n",
    "del signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_signal = uproot.open('dcm_100k_signal.root:t1').arrays(library='pd')\n",
    "gc.collect()\n",
    "#df_clean_signal['issignal']=((df_clean_signal['issignal']>0)*1)\n",
    "signal = df_clean_signal[(df_clean_signal['issignal']==1) & (df_clean_signal['mass']>1.108)\n",
    "               & (df_clean_signal['mass']<1.1227)]\n",
    "#del df_clean_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal['mass'].hist[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_urqmd = tree_importer('/home/shahid/Mount/gsi/u/flat_trees/PFSimplePlainTree_urqmd.root','PlainTree')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_clean_urqmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "file = uproot.open('/home/shahid/Mount/gsi/u/flat_trees/PFSimplePlainTree_urqmd_5k.root:PlainTree',library='pd').arrays(labels,library='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"LambdaCandidates_chi2geo\", \"LambdaCandidates_chi2primneg\", \"LambdaCandidates_chi2primpos\",\n",
    "         \"LambdaCandidates_distance\", \"LambdaCandidates_ldl\",\"LambdaCandidates_mass\", \"LambdaCandidates_pT\", \"LambdaCandidates_rapidity\", \"LambdaCandidates_is_signal\"]\n",
    "\n",
    "new_labels=['chi2geo', 'chi2primneg','chi2primpos', 'distance', 'ldl','mass', 'pT', 'rapidity','issignal']\n",
    "\n",
    "df_urqmd_5k= pd.DataFrame(data=file)\n",
    "del file\n",
    "df_urqmd_5k.columns = new_labels\n",
    "df_urqmd_5k['issignal']=((df_urqmd_5k['issignal']>0)*1)\n",
    "with pd.option_context('mode.use_inf_as_na', True):\n",
    "    df_urqmd_5k = df_urqmd_5k.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels=['$\\chi^{2}_{geometrical}$', '$\\chi^{2}_{primary\\ \\pi^-}$','$\\chi^{2}_{primary\\ proton}$', 'DCA (cm)', 'L/$\\Delta$L','mass', '$p_{T}$', '$y_{LAB}$','issignal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "bin1 = 300 \n",
    "plt.hist(df3_base[df3_base['issignal']==0]['distance'],bins = bin1, color = 'red',alpha = 0.3,label='Background')\n",
    "plt.hist(df3_base[df3_base['issignal']==1]['distance'],bins = bin1, color = 'blue',label='Signal', alpha =0.3)\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.ylabel('counts (log scale)', fontsize = 18)\n",
    "#plt.xlabel('$\\chi^{2}_{geometrical}$', fontsize = 18)\n",
    "plt.legend(fontsize=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "#ax.text(0, 1500, r'CBM Performance', fontsize=15)\n",
    "#ax.text(0, 500, r'URQMD, Au+Au @ 12 $A$GeV/$c$', fontsize=15)\n",
    "plt.xlabel('DCA (cm)', fontsize = 18)\n",
    "plt.xlim([0,0.2])\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig('hists.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "bin1 = 300 \n",
    "range1=[0,4000]\n",
    "plt.hist(df_urqmd_5k[df_urqmd_5k['issignal']==0]['ldl'],bins = bin1,range=range1, color = 'red',alpha = 0.3,label='Background')\n",
    "plt.hist(df_urqmd_5k[df_urqmd_5k['issignal']==1]['ldl'],bins = bin1, range=range1, color = 'blue',label='Signal', alpha =0.3)\n",
    "#plt.vlines(x=4,ymin=-1,ymax=10000, color='r', linestyle='-')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.ylabel('counts (log scale)', fontsize = 18)\n",
    "plt.xlabel(plot_labels[4], fontsize = 18)\n",
    "plt.legend(loc='upper right',fontsize=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "ax.text(0.3, 15000, r'CBM Performance', fontsize=15)\n",
    "ax.text(0.3, 5000, r'URQMD, Au+Au @ 12 $A$GeV/$c$', fontsize=15)\n",
    "#plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "#ax.text(4, 10000, r'$PFSimple$', fontsize=20, color ='r')\n",
    "#plt.xlim([0,20])\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig('hists.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = tree_importer('/home/shahid/Mount/gsi/u/flat_trees/apr20_fr_18.2.1_fs_jun19p1/dcmqgsm_smm_pluto/auau/12agev/mbias/sis100_electron_target_25_mkm/PFSimplePlainTree_dcm.root','PlainTree')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = df_original[(df_original['LambdaCandidates_is_signal'] == 0)\n",
    "                & ((df_original['LambdaCandidates_mass'] > 1.07)\n",
    "                & (df_original['LambdaCandidates_mass'] < 1.108) | (df_original['LambdaCandidates_mass']>1.1227) \n",
    "                   & (df_original['LambdaCandidates_mass'] < 2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The labels of the columns in the df data frame are having the prefix LambdaCandidates_ so we rename them\n",
    "new_labels= ['chi2geo', 'chi2primneg', 'chi2primpos', 'chi2topo', 'cosineneg',\n",
    "       'cosinepos', 'cosinetopo', 'distance', 'eta', 'l', 'ldl',\n",
    "       'mass', 'p', 'pT', 'phi', 'px', 'py', 'pz', 'rapidity',\n",
    "             'x', 'y', 'z', 'daughter1id', 'daughter2id', 'isfrompv', 'pid', 'issignal']\n",
    "\n",
    "\n",
    "\n",
    "sgnal.columns = new_labels\n",
    "#bg.columns = new_labels\n",
    "\n",
    "#Let's see how the dataframe object df looks like\n",
    "#df_original.columns=new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data frame object has some columns/features and for them at the very last column the true Monte Carlos information is available. This MC information tells us whether this reconstructed particle was originally produced as a decaying particle or not. So a value of 1 means that it is a true candidate and 0 means that it is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "Sometimes a data set contains entries which do not make sense. For example, infinite values or NaN entries. We clean the data by removing these entries. Ofcourse, we lose some data points but these outliers sometimes cause problems when we perform analysis. \n",
    "\n",
    "Since our experiment is a fixed target experiment so there are certain constraints which have to be applied on the data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    with pd.option_context('mode.use_inf_as_na', True):\n",
    "        df = df.dropna()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new data frame and saving the results in it after cleaning of the original dfs\n",
    "#Also keeping the original one\n",
    "#bcknd = clean_df(bg)\n",
    "signal = clean_df(sgnal)\n",
    "\n",
    "#del bg\n",
    "del sgnal\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = df_clean[(df_clean['issignal']==1) & (df_clean['mass']>1.108)\n",
    "               & (df_clean['mass']<1.1227)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_selected= signal\n",
    "background_selected = df_clean_urqmd[(df_clean_urqmd['issignal'] == 0)\n",
    "                & ((df_clean_urqmd['mass'] > 1.07)\n",
    "                & (df_clean_urqmd['mass'] < 1.108) | (df_clean_urqmd['mass']>1.1227) \n",
    "                   & (df_clean_urqmd['mass'] < 1.3))].sample(n=3*(signal_selected.shape[0]))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Background and Signal\n",
    "Our sample contains a lot of background (2178718) and somewhat signal candidates (36203). For analysis we will use a signal set of 4000 candidates and a background set of 12000 candidates. The background and signal candidates will be selected by using MC information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We randomly choose our signal set of 4000 candidates\n",
    "#signal_selected= signal\n",
    "\n",
    "#background = 3 times the signal is also done randomly\n",
    "#background_selected = bcknd.sample(n=3*(signal_selected.shape[0]))\n",
    "\n",
    "\n",
    "#del signal\n",
    "#del bcknd\n",
    "#gc.collect()\n",
    "\n",
    "#Let's combine signal and background\n",
    "dfs = [signal_selected, background_selected]\n",
    "df_scaled = pd.concat(dfs)\n",
    "\n",
    "# Let's shuffle the rows randomly\n",
    "df_scaled = df_scaled.sample(frac=1)\n",
    "del dfs, signal_selected, background_selected\n",
    "# Let's take a look at the top 10 entries of the df\n",
    "df_scaled.iloc[0:10,:]\n",
    "#del signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_scaled.shape)\n",
    "df_scaled[df_scaled['issignal']==1].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = 0.5 * (np.log(E+P/E-P))\n",
    "\n",
    "\n",
    "https://cbm-wiki.gsi.de/foswiki/bin/view/PWG/CbmCollisionEnergies\n",
    "\n",
    "\n",
    "y = 0.5 * (np.log((12+10)/(12-10)))\n",
    "\n",
    "\n",
    "using this the rapidity is 3.1992 for Ebeam =12.04 and pbeam =12 and mid rapidity is y/2=  1.5996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1 = (1.077, 1.18)\n",
    "fig, axs = plt.subplots(figsize=(10, 6))\n",
    "#df_scaled['mass'].plot.hist(bins = 300, range=range1,grid=True,sharey=True)\n",
    "(df_scaled[df_scaled['issignal']==0])['mass'].plot.hist(bins = 300, facecolor='yellow',grid=True,range=range1, label='Background')\n",
    "(df_scaled[df_scaled['issignal']==1])['mass'].plot.hist(bins = 300, facecolor='magenta',grid=True, range=range1, label ='Signal')\n",
    "#plt.vlines(x=1.108,ymin=-1,ymax=48000, color='black', linestyle='-')\n",
    "#plt.vlines(x=1.1227,ymin=-1,ymax=48000, color='black', linestyle='-')\n",
    "plt.ylabel(\"Counts (log scale)\", fontsize=15)\n",
    "plt.xlabel(\"Mass in GeV/$c^2$\", fontsize= 15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "#plt.title('Test and Train Lambda Invariant Mass', fontsize = 15)\n",
    "plt.legend( fontsize = 15)\n",
    "axs.tick_params(axis='both', which='major', labelsize=18)\n",
    "axs.text(1.13, 9500, r'CBM Performance', fontsize=15)\n",
    "axs.text(1.13, 6000, r'DCM-QGSM-SMM, Au+Au @ 12 $A$GeV/$c$', color = 'magenta',  fontsize=15)\n",
    "axs.text(1.13, 4000, r'URQMD, Au+Au @ 12 $A$GeV/$c$', fontsize=15)\n",
    "plt.yscale(\"log\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"hists.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train and Test sets\n",
    "To make machine learning algorithms more efficient on unseen data we divide our data into two sets. One set is for training the algorithm and the other is for testing the algorithm. If we don't do this then the algorithm can overfit and we will not capture the general trends in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following columns will be used to predict whether a reconstructed candidate is a lambda particle or not\n",
    "cuts = [ 'chi2primneg', 'chi2primpos', 'ldl', 'distance', 'chi2geo']\n",
    "\n",
    "\n",
    "x = df_scaled[cuts].copy()\n",
    "\n",
    "# The MC information is saved in this y variable\n",
    "y =pd.DataFrame(df_scaled['issignal'], dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following columns will be used to predict whether a reconstructed candidate is a lambda particle or not\n",
    "x_whole = df_clean[cuts].copy()\n",
    "# The MC information is saved in this y variable\n",
    "y_whole = pd.DataFrame(df_clean['issignal'], dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a new df \n",
    "\n",
    "#new_check_set=KFPF_lambda_cuts(df_original)\n",
    "new_check_set=KFPF_lambda_cuts(df_clean)\n",
    "del df_original\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:purple; font-style:bold\"><br>XGB Boost \n",
    "<br></p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian\n",
    "In order to find the best parameters of XGB for our data we use Bayesian optimization. Grid search and and random search could also do the same job but bayesian is more time efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=324)\n",
    "dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "dtest = xgb.DMatrix(x_whole, label = y_whole)\n",
    "dtest1=xgb.DMatrix(x_test, label = y_test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_whole_1 = df_clean_urqmd[cuts].copy()\n",
    "# The MC information is saved in this y variable\n",
    "y_whole_1 = pd.DataFrame(df_clean_urqmd['issignal'], dtype='int')\n",
    "dtest2 = xgb.DMatrix(x_whole_1, label = y_whole_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters\n",
    "\n",
    "*subsample* [default=1]\n",
    "Subsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting. Subsampling will occur once in every boosting iteration.\n",
    "range: (0,1]\n",
    "\n",
    "*eta* [default=0.3, alias: learning_rate]\n",
    "Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n",
    "range: [0,1]\n",
    "\n",
    "\n",
    "*gamma* [default=0, alias: min_split_loss]\n",
    "Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\n",
    "range: [0,∞]\n",
    "\n",
    "\n",
    "*alpha* [default=0, alias: reg_alpha]\n",
    "L1 regularization term on weights. Increasing this value will make model more conservative.\n",
    "\n",
    "*Lasso Regression* (Least Absolute Shrinkage and Selection Operator) adds “absolute value of magnitude” of coefficient as penalty term to the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bayesian Optimization function for xgboost\n",
    "#specify the parameters you want to tune as keyword arguments\n",
    "def bo_tune_xgb(max_depth, gamma, alpha, n_estimators ,learning_rate):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,\n",
    "              'alpha':alpha,\n",
    "              'n_estimators': n_estimators,\n",
    "              'learning_rate':learning_rate,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.3,\n",
    "              'eval_metric': 'auc', 'objective':'binary:logistic', 'nthread' : 6}\n",
    "    cv_result = xgb.cv(params=params, dtrain=dtrain, num_boost_round=10, nfold=5)\n",
    "    return  cv_result['test-auc-mean'].iloc[-1]\n",
    "\n",
    "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (4, 10),\n",
    "                                             'gamma': (0, 1),\n",
    "                                            'alpha': (2,20),\n",
    "                                             'learning_rate':(0,1),\n",
    "                                             'n_estimators':(100,500)\n",
    "                                            })\n",
    "\n",
    "#performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement\n",
    "xgb_bo.maximize(n_iter=15, init_points=8, acq='ei')\n",
    "#0.9951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import sqrt, log, argmax\n",
    "import itertools\n",
    "\n",
    "\"\"\"\n",
    "A receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its\n",
    "discrimination threshold is varied. This function requires the true binary value and the target scores, which can either be probability estimates of\n",
    "the positive class, confidence values, or binary decisions.\n",
    "The function roc_auc_score computes Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "\n",
    "To find the best threshold which results more signal to background ratio for lambda candidates we use the parameter S0 called the approximate median significance\n",
    "by the higgs boson  ML challenge (http://higgsml.lal.in2p3.fr/documentation,9.)\n",
    "\"\"\"\n",
    "def AMS(y_true, y_predict, y_true1, y_predict1):\n",
    "    roc_auc=roc_auc_score(y_true, y_predict)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_predict,drop_intermediate=False ,pos_label=1)\n",
    "    S0 = sqrt(2 * ((tpr + fpr) * log((1 + tpr/fpr)) - tpr))\n",
    "    S0 = S0[~np.isnan(S0)]\n",
    "    xi = argmax(S0)\n",
    "    S0_best_threshold = (thresholds[xi])\n",
    "\n",
    "    roc_auc1=roc_auc_score(y_true1, y_predict1)\n",
    "    fpr1, tpr1, thresholds1 = roc_curve(y_true1, y_predict1,drop_intermediate=False ,pos_label=1)\n",
    "    S01 = sqrt(2 * ((tpr1 + fpr1) * log((1 + tpr1/fpr1)) - tpr1))\n",
    "    S01 = S01[~np.isnan(S01)]\n",
    "    xi1 = argmax(S01)\n",
    "    S0_best_threshold1 = (thresholds[xi1])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi = 100)\n",
    "    plt.plot(fpr, tpr, linewidth=3 ,linestyle=':',color='darkorange',label='ROC curve train (area = %0.4f)' % roc_auc)\n",
    "    plt.plot(fpr1, tpr1, color='green',label='ROC curve test (area = %0.4f)' % roc_auc1)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Random guess')\n",
    "    #plt.scatter(fpr[xi], tpr[xi], marker='o', color='black', label= 'Best Threshold train set = '+\"%.4f\" % S0_best_threshold +'\\n AMS = '+ \"%.2f\" % S0[xi])\n",
    "    plt.scatter(fpr1[xi1], tpr1[xi1], marker='o', s=80, color='blue', label= 'Best Threshold test set = '+\"%.4f\" % S0_best_threshold1 +'\\n AMS = '+ \"%.2f\" % S01[xi1])\n",
    "    plt.xlabel('False Positive Rate', fontsize = 18)\n",
    "    plt.ylabel('True Positive Rate', fontsize = 18)\n",
    "    plt.legend(loc=\"lower right\", fontsize = 18)\n",
    "    plt.title('Receiver operating characteristic', fontsize = 18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0, 1.02])\n",
    "    #axs.axis([-0.01, 1, 0.9, 1])\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('hists.png')\n",
    "    plt.show()\n",
    "    return S0_best_threshold, S0_best_threshold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_param = xgb_bo.max['params']\n",
    "param= {'alpha': max_param['alpha'], 'gamma': max_param['gamma'], 'learning_rate': max_param['learning_rate'],\n",
    "        'max_depth': int(round(max_param['max_depth'],0)), 'n_estimators': int(round(max_param['n_estimators'],0))\n",
    "        , 'objective': 'binary:logistic'}\n",
    "\n",
    "#Fit/train on training data\n",
    "bst = xgb.train(param, dtrain)\n",
    "\n",
    "#predicitions on training set\n",
    "bst_train= pd.DataFrame(data=bst.predict(dtrain, output_margin=False),  columns=[\"xgb_preds\"])\n",
    "y_train=y_train.set_index(np.arange(0,bst_train.shape[0]))\n",
    "bst_train['issignal']=y_train['issignal']\n",
    "\n",
    "#predictions on test set\n",
    "bst_test = pd.DataFrame(data=bst.predict(dtest1, output_margin=False),  columns=[\"xgb_preds\"])\n",
    "y_test=y_test.set_index(np.arange(0,bst_test.shape[0]))\n",
    "bst_test['issignal']=y_test['issignal']\n",
    "\n",
    "#ROC cures for the predictions on train and test sets\n",
    "train_best, test_best = AMS(y_train, bst_train['xgb_preds'],y_test, bst_test['xgb_preds'])\n",
    "\n",
    "#The first argument should be a data frame, the second a column in it, in the form 'preds'\n",
    "preds_prob(bst_test,'xgb_preds', 'issignal','test')\n",
    "\n",
    "#Applying XGB on the 10k events data-set\n",
    "df_clean['xgb_preds'] = bst.predict(dtest, output_margin=False)\n",
    "#preds_prob(df_clean,'xgb_preds', 'issignal','test')\n",
    "\n",
    "df_clean_urqmd['xgb_preds'] = bst.predict(dtest2, output_margin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_prob(df, preds, true, dataset):\n",
    "    if dataset =='train':\n",
    "        label1 = 'XGB Predictions on the training data set'\n",
    "    else:\n",
    "        label1 = 'XGB Predictions on the test data set'\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    bins1=100\n",
    "    plt.hist(df[preds], bins=bins1,facecolor='green',alpha = 0.3, label=label1)\n",
    "    TP = df[(df[true]==1)]\n",
    "    TN = df[(df[true]==0)]\n",
    "    #TP[preds].plot.hist(ax=ax, bins=bins1,facecolor='blue', histtype='stepfilled',alpha = 0.3, label='True Positives/signal in predictions')\n",
    "    hist, bins = np.histogram(TP[preds], bins=bins1)\n",
    "    err = np.sqrt(hist)\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    \n",
    "    hist1, bins1 = np.histogram(TN[preds], bins=bins1)\n",
    "    err1 = np.sqrt(hist1)\n",
    "    plt.errorbar(center, hist1, yerr=err1, fmt='o',\n",
    "                 c='Red', label='Background in predictions')\n",
    "    \n",
    "    plt.errorbar(center, hist, yerr=err, fmt='o',\n",
    "                 c='blue', label='Signal in predictions')\n",
    "    \n",
    "    \n",
    "    ax.annotate('Cut on probability', xy=(0, 10),  xycoords='data',\n",
    "            xytext=(0.13, 0.65), textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.08),\n",
    "            horizontalalignment='right', verticalalignment='top',fontsize=15\n",
    "            )\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    plt.xlabel('Probability',fontsize=18)\n",
    "    plt.ylabel('Counts', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=18)\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_prob(bst_test,'xgb_preds', 'issignal', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function will display the inavriant mass histogram of the original 10k event set along with the mass histoigram after we apply a cut\n",
    "# on the probability prediction of xgb\n",
    "def cut_visualization(df, variable,cut, range1=(1.09, 1.19), bins1= 300 ):\n",
    "    mask1 = df[variable]>cut\n",
    "    df3=df[mask1]\n",
    "    \n",
    "    fig, ax2 = plt.subplots(figsize=(12, 8), dpi = 300)\n",
    "    color = 'tab:blue'\n",
    "    ax2.hist(df['mass'],bins = bins1, range=range1, facecolor='blue' ,alpha = 0.35, label='before selection')\n",
    "    ax2.set_ylabel('Counts', fontsize = 15, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.legend( fontsize = 15, loc='upper left')\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax2.grid()\n",
    "    ax2.set_xlabel(\"Mass (GeV/${c^2}$)\", fontsize = 18)\n",
    "    \n",
    "    \n",
    "    \n",
    "    color = 'tab:red'\n",
    "    ax1 = ax2.twinx()\n",
    "    ax1.hist(df3['mass'], bins = bins1, range=range1, facecolor='red',alpha = 0.35, label=\"XGB (with a cut > %.2f\"%cut+')')\n",
    "    ax1.set_xlabel('Mass in GeV', fontsize = 15)\n",
    "    ax1.set_ylabel('Counts ', fontsize = 15, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax1.legend( fontsize = 18,loc='upper right' )\n",
    "\n",
    "    plt.title(\"The original sample's Invariant Mass along with mass after selection of XGB\", fontsize = 15)\n",
    "    plt.text(1.14, 8000, 'CBM Performance', fontsize=18)\n",
    "    plt.text(1.14, 7000, 'URQMD, Au+Au @ 12A GeV/$c$', fontsize=18)\n",
    "    #plt.text(0.02, 0.1, r'cut > %.4f'%cut, fontsize=15)\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"test_best.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_visualization(df_clean_urqmd,'xgb_preds',0.954)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut3 = 0.95\n",
    "mask1 = df_clean_urqmd['xgb_preds']>cut3\n",
    "df3_base=df_clean_urqmd[mask1]\n",
    "fig, axs = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "range1= (1.105, 1.14)\n",
    "bins1 = 150\n",
    "\n",
    "#xgb\n",
    "\n",
    "#issignal has 0,1,2 . So we convert all signals above zero to 1\n",
    "\n",
    "\n",
    "\n",
    "df3_base['mass'].plot.hist(bins = bins1, range=range1, facecolor='red',alpha = 0.3,grid=True,sharey=True, label='XGB selected $\\Lambda$s')\n",
    "#df3_base[df3_base['issignal']==1]['mass'].plot.hist(bins = 300, range=range1,facecolor='blue',alpha = 0.3,grid=True,sharey=True, '\\n True positives = \\n (MC =1)\\n signal in \\n the distribution')\n",
    "#df3_base[df3_base['issignal']==1]['mass'].plot.hist(bins = bins1, range=range1,facecolor='magenta',alpha = 0.3,grid=True,sharey=True )\n",
    "df3_base[df3_base['issignal']==0]['mass'].plot.hist(bins = bins1, range=range1,facecolor='green',alpha = 0.3,grid=True,sharey=True, label ='\\n False positives = \\n (MC =0)\\n background in \\n the distribution')\n",
    "\n",
    "plt.legend( fontsize = 18, loc='upper right')\n",
    "#plt.rcParams[\"legend.loc\"] = 'upper right'\n",
    "plt.title(\"XGB selected $\\Lambda$ candidates with a cut of %.3f \"%cut3 +\"on the XGB probability distribution\", fontsize = 18)\n",
    "plt.xlabel(\"Mass (GeV/${c^2}$)\", fontsize = 18)\n",
    "plt.ylabel(\"Counts\", fontsize = 18)\n",
    "axs.text(1.123, 4000, 'CBM Performance', fontsize=18)\n",
    "axs.text(1.123, 3500, 'URQMD, Au+Au @ 12A GeV/$c$', fontsize=18)\n",
    "axs.tick_params(labelsize=18)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"whole_sample_invmass_with_ML.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "By definition a confusion matrix $C$ is such that $C_{i, j}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$.\n",
    "\n",
    "Thus in binary classification, the count of true positives is $C_{0,0}$, false positives is $C_{1,0}$, true negatives is $C_{1,1}$ and false negatives is $C_{0,1}$.\n",
    "\n",
    "The following function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['xgb_preds1'] = ((df_clean['xgb_preds']>cut3)*1)\n",
    "cnf_matrix = confusion_matrix(y_whole, df_clean['xgb_preds1'], labels=[1,0])\n",
    "#cnf_matrix = confusion_matrix(new_check_set['issignal'], new_check_set['new_signal'], labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "fig, axs = plt.subplots(figsize=(10, 8))\n",
    "axs.yaxis.set_label_coords(-0.04,.5)\n",
    "axs.xaxis.set_label_coords(0.5,-.005)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['signal','background'], title='Confusion Matrix for XGB for cut > '+str(cut3))\n",
    "plt.savefig('confusion_matrix_extreme_gradient_boosting_whole_data.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30269/ (50269+120980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = xgb.plot_importance(bst)\n",
    "plt.rcParams['figure.figsize'] = [5, 3]\n",
    "plt.show()\n",
    "ax.figure.tight_layout() \n",
    "ax.figure.savefig(\"hits.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(bst,num_trees=2)\n",
    "plt.rcParams['figure.figsize'] = [80, 160]\n",
    "plt.rcParams['figure.dpi']=300\n",
    "#plt.show()\n",
    "plt.savefig(\"hists.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.to_graphviz(xg_reg, fmap='', num_trees=0, rankdir=None, yes_color=None, no_color=None, condition_node_params=None, leaf_node_params=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "range1= (1.08, 1.22)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1,figsize=(15,10), sharex=True,  gridspec_kw={'width_ratios': [10],\n",
    "                           'height_ratios': [8,4]})\n",
    "\n",
    "ns, bins, patches=axs[0].hist((df3_base['mass']),bins = 300, range=range1,Fill=True, color='red', facecolor='red',alpha = 0.3)\n",
    "ns1, bins1, patches1=axs[0].hist((new_check_set['mass']),bins = 300, Fill=True, range=range1,facecolor='blue',alpha = 0.3)\n",
    "#plt.xlabel(\"Mass in GeV\", fontsize = 15)\n",
    "axs[0].set_ylabel(\"counts\", fontsize = 15)\n",
    "#axs[0].grid()\n",
    "axs[0].legend(('XGBoost Selected $\\Lambda$s','KFPF selected $\\Lambda$s'), fontsize = 15, loc='upper right')\n",
    "\n",
    "#plt.rcParams[\"legend.loc\"] = 'upper right'\n",
    "axs[0].set_title(\"The lambda's Invariant Mass histogram with KFPF and XGB selection criteria on KFPF variables\", fontsize = 15)\n",
    "axs[0].grid()\n",
    "axs[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "#fig.savefig(\"whole_sample_invmass_with_ML.png\")\n",
    "\n",
    "\n",
    "hist1, bin_edges1 = np.histogram(df3_base['mass'],range=(1.09, 1.17), bins=300)\n",
    "hist2, bin_edges2 = np.histogram(new_check_set['mass'],range=(1.09, 1.17), bins=300)\n",
    "\n",
    "#makes sense to have only positive values \n",
    "diff = (hist1 - hist2)\n",
    "axs[1].bar(bins[:-1],     # this is what makes it comparable\n",
    "        ns / ns1, # maybe check for div-by-zero!\n",
    "        width=0.001)\n",
    "plt.xlabel(\"Mass in $\\dfrac{GeV}{c^2}$\", fontsize = 15)\n",
    "axs[1].set_ylabel(\"XGB / KFPF\", fontsize = 15)\n",
    "axs[1].grid()\n",
    "axs[1].tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"whole_sample_invmass_with_ML.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dtest, dtrain, dtest1, df_scaled, x, y, x_whole, y_whole, x_train, x_test, y_train, y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_100k = df_clean.copy()\n",
    "del df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdt cut 0.7\n",
    "df0 = df3_base\n",
    "df0 = df0[(df0['mass']>1.07)&(df0['mass']<1.3)]\n",
    "df0 = df0[['rapidity', 'mass', 'pT', 'issignal']]\n",
    "del df3_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdt cut 0.8\n",
    "df1 = df3_base\n",
    "df1 = df1[(df1['mass']>1.07)&(df1['mass']<1.3)]\n",
    "df1 = df1[['rapidity', 'mass', 'pT', 'issignal']]\n",
    "del df3_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bdt cut 0.9\n",
    "df2 = df3_base\n",
    "df2 = df2[(df2['mass']>1.07)&(df2['mass']<1.3)]\n",
    "df2 = df2[['rapidity', 'mass', 'pT', 'issignal']]\n",
    "del df3_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.92\n",
    "df3 = df3_base\n",
    "df3 = df3[(df3['mass']>1.07)&(df3['mass']<1.3)]\n",
    "df3 = df3[['rapidity', 'mass', 'pT', 'issignal']]\n",
    "del df3_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_best\n",
    "df4 = df3_base\n",
    "df4 = df4[(df4['mass']>1.07)&(df4['mass']<1.3)]\n",
    "df4 = df4[['rapidity', 'mass', 'pT', 'issignal']]\n",
    "del df3_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_best\n",
    "df4_urqmd = df3_base\n",
    "df4_urqmd = df4_urqmd[(df4_urqmd['mass']>1.07)&(df4_urqmd['mass']<1.3)]\n",
    "df4_urqmd = df4_urqmd[['rapidity', 'mass', 'pT', 'issignal']]\n",
    "del df3_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df4[df4['issignal']==1]\n",
    "#df4 = df4[['rapidity', 'mass', 'pT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyRoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, ROOT\n",
    "from ROOT import TF1, TCanvas,TMath, TColor\n",
    "\n",
    "class Linear:\n",
    "    def __call__( self, x, par ):\n",
    "        return par[0] + x[0]*par[1]\n",
    "\n",
    "class lorenztian:\n",
    "    def _call_(self, x, p):\n",
    "        return 0.5*p[0]*p[1] /( ((x[0]-p[2])**2) + ((0.5 * (p[1])**2))) \n",
    "\n",
    "class gaus:\n",
    "    def _call_(self, x ,p):\n",
    "        return p[0]*np.exp(-0.5*((x[0]-p[2])/p[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def truncate(number, decimals=2):\n",
    "    \"\"\"\n",
    "    Returns a value truncated to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer.\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more.\")\n",
    "    elif decimals == 0:\n",
    "        return math.trunc(number)\n",
    "\n",
    "    factor = 10.0 ** decimals\n",
    "    return math.trunc(number * factor) / factor\n",
    "\n",
    "\n",
    "def background_selector(df):\n",
    "    df1 = df[(df['mass']<1.108)]\n",
    "    df2 = df[df['mass']>1.13]\n",
    "    df3 = pd.concat([df1, df2])\n",
    "    return df3['mass'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate(0.39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentile binning\n",
    "#df0 = df3_base\n",
    "#df = df0[(df0['mass']>1.07)&(df0['mass']<1.3)]\n",
    "df = df4\n",
    "out0, bins0 =pd.qcut(df['rapidity'], q=4, retbins=1)\n",
    "lowest_rapidity = df[df['rapidity']<bins0[1]]\n",
    "low_rapidity = df[(df['rapidity']>bins0[1])&(df['rapidity']<bins0[2])]\n",
    "mid_rapidity = df[(df['rapidity']>bins0[2])&(df['rapidity']<bins0[3])]\n",
    "high_rapidity = df[(df['rapidity']>bins0[3])]\n",
    "    \n",
    "out1, bins1 =pd.qcut(lowest_rapidity['pT'], q=3, retbins=1)\n",
    "low_pT_lowest_rapidity = lowest_rapidity[lowest_rapidity['pT']<bins1[1]]\n",
    "mid_pT_lowest_rapidity = lowest_rapidity[(lowest_rapidity['pT']>bins1[1]) & (lowest_rapidity['pT']<bins1[2])]\n",
    "high_pT_lowest_rapidity =lowest_rapidity[(lowest_rapidity['pT']>bins1[2])]\n",
    "\n",
    "out2, bins2 =pd.qcut(low_rapidity['pT'], q=3, retbins=1)\n",
    "low_pT_low_rapidity = low_rapidity[low_rapidity['pT']<bins2[1]]\n",
    "mid_pT_low_rapidity = low_rapidity[(low_rapidity['pT']>bins2[1]) & (low_rapidity['pT']<bins2[2])]\n",
    "high_pT_low_rapidity= low_rapidity[(low_rapidity['pT']>bins2[2])]\n",
    "    \n",
    "out3, bins3 =pd.qcut(mid_rapidity['pT'], q=3, retbins=1)\n",
    "low_pT_mid_rapidity = mid_rapidity[mid_rapidity['pT']<bins3[1]]\n",
    "mid_pT_mid_rapidity = mid_rapidity[(mid_rapidity['pT']>bins3[1]) & (mid_rapidity['pT']<bins3[2])]\n",
    "high_pT_mid_rapidity=mid_rapidity[(mid_rapidity['pT']>bins3[2])]\n",
    "    \n",
    "out4, bins4 =pd.qcut(high_rapidity['pT'], q=3, retbins=1)\n",
    "low_pT_high_rapidity = high_rapidity[high_rapidity['pT']<bins4[1]]\n",
    "mid_pT_high_rapidity = high_rapidity[(high_rapidity['pT']>bins4[1]) & (high_rapidity['pT']<bins4[2])]\n",
    "high_pT_high_rapidity=high_rapidity[(high_rapidity['pT']>bins4[2])]\n",
    "\n",
    "#del out0, lowest_rapidity, mid_rapidity, high_rapidity, out1, out2, out3, out4, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_selector(df):\n",
    "    df1 = df[(df['mass']<1.108)]\n",
    "    df2 = df[df['mass']>1.13]\n",
    "    df3 = pd.concat([df1, df2])\n",
    "    return df3['mass'] \n",
    "\n",
    "list1 = [low_pT_lowest_rapidity, mid_pT_lowest_rapidity, high_pT_lowest_rapidity, low_pT_low_rapidity,\n",
    "         mid_pT_low_rapidity, high_pT_low_rapidity, low_pT_mid_rapidity, mid_pT_mid_rapidity,\n",
    "        high_pT_mid_rapidity, low_pT_high_rapidity, mid_pT_high_rapidity, high_pT_high_rapidity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4['mass'].describe()[1]-1.2*(df4['mass'].describe()[2])+0.2* (df4['mass'].describe()[2])\n",
    "df4['mass'].describe()[1]+1.2*(df4['mass'].describe()[2])+0.2* (df4['mass'].describe()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorentzian\n",
    "Lorenztian with second chebyshev 2nd order polynom\n",
    "\n",
    "The describe of BDT score > 70 shows that the sigma of the data mean is at 1.178052 with an std of 0.059818. So 1.55sigma below the mean is 1.0883250000000002 and 1.55 sigma above the mean is 1.267779. So let's choose 1.55, 1.5 and 1.45 below the mean and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol2 = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "pol3 = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x+[3]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "one_var_pol2=TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "one_var_pol3=TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x+[4]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lorentzian + second order pol\n",
    "lorentzian_pol2 = []\n",
    "pt_min=[]\n",
    "y_min = []\n",
    "#lorentzian_3rd_order_pol = []\n",
    "\n",
    "\n",
    "df = df4_urqmd\n",
    "\n",
    "\n",
    "mass_range_min = [df['mass'].describe()[1]-1.2*(df['mass'].describe()[2])]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2]),\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "\n",
    "y_bin_low = -0.2\n",
    "y_bin_up =0.0\n",
    "for i in range(0,15,1):\n",
    "    y_bin_low = truncate(y_bin_low + 0.2)\n",
    "    y_bin_up = truncate(y_bin_up+0.2)\n",
    "    df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "    \n",
    "    pt_bin_low =-0.2\n",
    "    pt_bin_up =0\n",
    "    for i in range(0,15,1):\n",
    "        pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "        pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "        df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "        mc_counts = df_pt[df_pt['issignal']>0].shape[0]\n",
    "        \n",
    "        for mm in mass_range_min:\n",
    "            for mmm in range(0,3,1):\n",
    "                \n",
    "                #canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "                #canvas.Draw()\n",
    "                #canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "                binning = [40,70,100,130]\n",
    "                for b in binning:\n",
    "                    tot_sig_3_sigma = 0\n",
    "                    tot_bac_3_sigma = 0\n",
    "                    tot_sig_3_point_5_sigma = 0\n",
    "                    tot_bac_3_point_5_sigma = 0\n",
    "                    tot_sig_2_point_5_sigma = 0\n",
    "                    tot_bac_2_point_5_sigma = 0\n",
    "                    tot_sig_2_sigma = 0\n",
    "\n",
    "\n",
    "                    #step 0\n",
    "                    if df_pt.shape[0]>500:\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        fb.SetParameters(0,0,0);\n",
    "                        #fb =TF1(\"fb\",\"[0]+[1]*x+[2]*x*x+[3]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #fb.SetParameters(0,0,0,0);\n",
    "                        h0.Fit(fb,\"RIEMQN\");\n",
    "                        par = fb.GetParameters()\n",
    "                        #Step 1\n",
    "                        data = df_pt['mass']\n",
    "                        \n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        f1.SetParameters(1,par[0], par[1], par[2]);\n",
    "                        #f1=TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x+[4]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f1.SetParameters(1,par[0], par[1], par[2],par[3]);\n",
    "                        h1.Fit(f1,\"RNIQ\");\n",
    "                        par1 = f1.GetParameters()\n",
    "\n",
    "                        #canvas .Clear ()\n",
    "                        #pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                        #pad1 . Draw ()\n",
    "                        #pad1 . cd ()\n",
    "                        #pad1. Clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #step 2\n",
    "                        f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3]);\n",
    "                        #f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x+[6]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2.SetNpx(100000);\n",
    "                        #f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3],par1[4]);\n",
    "                        #f2.SetLineColor(ROOT.kRed)\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNIRQ\"))\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fs.SetNpx(100000);\n",
    "                        #fs.SetLineColor(ROOT.kGreen)\n",
    "                        #fb.SetLineStyle(4)\n",
    "                        #fb.SetLineColor(ROOT.kBlue)\n",
    "                        #fb.SetNpx(100000);\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                        fb.SetParameters(par2[3],par2[4],par2[5]);\n",
    "                        #fb.SetParameters(par2[3],par2[4],par2[5],par2[6]);\n",
    "\n",
    "\n",
    "                        #h1.SetTitleOffset(-1)\n",
    "                        #h1.SetFillStyle(3003);\n",
    "                        #h1.SetLineWidth(2)\n",
    "                        #h1.SetStats (0)\n",
    "                        #h1.SetYTitle(\"Entries\")\n",
    "                        #h1.SetLineColor(ROOT.kBlack)\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        #h3.SetLineWidth(2)\n",
    "                        #h3.SetStats (0)\n",
    "                        #h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                        #h1.Draw(\"pe\")\n",
    "                        #fs.Draw(\"SAME\")\n",
    "                        #fb.Draw(\"SAME\")\n",
    "                        #f2.Draw(\"SAME\")\n",
    "\n",
    "                        bin1 = h1.FindBin(fit_limit_low[mmm]+mm);\n",
    "                        bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                        #h2.Sumw2()\n",
    "\n",
    "                        integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                        integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "                        binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                        #tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                        #sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "\n",
    "                        signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                        if signal_under_peak>0:\n",
    "                            tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak                \n",
    "                        #sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                        #man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                        if sigma_signal_under_peak!=0:\n",
    "                            print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                        \n",
    "                        backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                        #if backgnd_under_peak<0:\n",
    "                            #print('Negative background')\n",
    "\n",
    "                        Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                        signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        #bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        if signal_under_peak_3_point_5_sigma>0:\n",
    "                            tot_sig_3_point_5_sigma= tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma                \n",
    "                        #tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                        #sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                        #man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        #bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        if signal_under_peak_2_point_5_sigma>0:\n",
    "                            tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                        #tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                        #sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                        #man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_sigm = (fs.Integral(par2[2] - (TMath.Abs(2*par2[1])),par2[2] + (TMath.Abs(2.*par2[1])))/binwidth);\n",
    "                        #bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        if signal_under_peak_2_sigm>0:\n",
    "                            tot_sig_2_sigma = tot_sig_2_sigma+signal_under_peak_2_sigm\n",
    "\n",
    "                        #std = par2 [1]\n",
    "                        #estd = f2.GetParError(1)\n",
    "                        del h0, h1, h2, h3, f1, f2, fb, fs\n",
    "                        #latex = ROOT . TLatex ()\n",
    "                        #latex . SetNDC ()\n",
    "                        #latex . SetTextSize (0.02)\n",
    "                        #latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                        #latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                        #latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                        #latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                        #latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "                        #latex . DrawLatex (0.4 ,0.55,\" True signal (MC=1) = %.f\"%(mc_counts))\n",
    "\n",
    "                        #legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                        #legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                        #legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx+Dx^{2}\",\"l\");\n",
    "                        #legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "                        #legend.AddEntry(fb,\"B+Cx+Dx^{2}\",\"l\");\n",
    "                        #legend . SetLineWidth (0)\n",
    "                        #legend.Draw()\n",
    "\n",
    "                        #canvas . cd ()\n",
    "                        #pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                        #pad2 . Draw ()\n",
    "                        #pad2 . cd ()\n",
    "                        #pad2.Clear()\n",
    "\n",
    "\n",
    "                        #h3.SetLineColor(TColor.GetColor(5))\n",
    "                        #h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                        #h3.Draw()\n",
    "                        #line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                        #line . SetLineColor ( ROOT . kRed )\n",
    "                        #line . SetLineWidth (2)\n",
    "                        #line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                        #pad1 . SetBottomMargin (0)\n",
    "                        #pad2 . SetTopMargin (0)\n",
    "                        #pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                        #h1 . GetXaxis (). SetLabelSize (0)\n",
    "                        #h1 . GetXaxis (). SetTitleSize (0)\n",
    "                        #h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                        #h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                        #h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                        #h3 . SetTitle (\"\")\n",
    "                        #h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                        #h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                        #h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                        #h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "                    #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                        #h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "                    #207,512 divisions\n",
    "                        #h3 . GetYaxis (). SetNdivisions (207)\n",
    "                        #h1 . GetYaxis (). SetRangeUser (0.5 ,3000)\n",
    "                        #h1 .GetYaxis().SetNdivisions(107)\n",
    "                        #h3 . GetXaxis (). SetNdivisions (207)\n",
    "                        gc.collect()\n",
    "                        #canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "                    else:\n",
    "                        tot_sig_2_point_5_sigma=tot_sig_2_point_5_sigma+0\n",
    "                        tot_sig_3_sigma=tot_sig_3_sigma+0\n",
    "                        tot_sig_3_point_5_sigma=tot_sig_3_point_5_sigma+0\n",
    "                        #tot_sig_2_sigma = tot_sig_2_sigma+0\n",
    "            #lorentzian_pol2.append(tot_sig_2_sigma)\n",
    "                    lorentzian_pol2.append(tot_sig_2_point_5_sigma)\n",
    "                    lorentzian_pol2.append(tot_sig_3_sigma)\n",
    "                    lorentzian_pol2.append(tot_sig_3_point_5_sigma)\n",
    "                    pt_min.append(pt_bin_low+0.2)\n",
    "                    pt_min.append(pt_bin_low+0.2)\n",
    "                    pt_min.append(pt_bin_low+0.2)\n",
    "                    y_min.append(y_bin_low+0.2)\n",
    "                    y_min.append(y_bin_low+0.2)\n",
    "                    y_min.append(y_bin_low+0.2)\n",
    "                    \n",
    "            gc.collect()\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")       \n",
    "print(y_bin_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total yield\n",
    "#lorentzian + second order pol\n",
    "lorentzian_pol2 = []\n",
    "#lorentzian_3rd_order_pol = []\n",
    "\n",
    "\n",
    "df = df4_urqmd\n",
    "\n",
    "\n",
    "mass_range_min = [df['mass'].describe()[1]-1.2*(df['mass'].describe()[2])]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2]),\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,3,1):\n",
    "        #canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "        #canvas.Draw()\n",
    "        #canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "\n",
    "        binning = [70,100,130]\n",
    "        for b in binning:\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            tot_sig_2_sigma = 0\n",
    "            y_bin_low=-0.2\n",
    "            y_bin_up =0\n",
    "            for i in range(0,15,1):\n",
    "                y_bin_low = truncate(y_bin_low+0.2)\n",
    "                y_bin_up = truncate(y_bin_up+0.2)\n",
    "                df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "                pt_bin_low =-0.2\n",
    "                pt_bin_up =0\n",
    "                for i in range(0,15,1):\n",
    "                    pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                    pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                    df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                    mc_counts = df_pt[df_pt['issignal']>0].shape[0]\n",
    "                    #step 0\n",
    "                    if df_pt.shape[0]>500:\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        fb.SetParameters(0,0,0);\n",
    "                        #fb =TF1(\"fb\",\"[0]+[1]*x+[2]*x*x+[3]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #fb.SetParameters(0,0,0,0);\n",
    "                        h0.Fit(fb,\"RIEMQ\");\n",
    "                        par = fb.GetParameters()\n",
    "                        #Step 1\n",
    "                        data = df_pt['mass']\n",
    "                        \n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        f1.SetParameters(1,par[0], par[1], par[2]);\n",
    "                        #f1=TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x+[4]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f1.SetParameters(1,par[0], par[1], par[2],par[3]);\n",
    "                        h1.Fit(f1,\"RNIQ\");\n",
    "                        par1 = f1.GetParameters()\n",
    "\n",
    "                        #canvas .Clear ()\n",
    "                        #pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                        #pad1 . Draw ()\n",
    "                        #pad1 . cd ()\n",
    "                        #pad1. Clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #step 2\n",
    "                        f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3]);\n",
    "                        #f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x+[6]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2.SetNpx(100000);\n",
    "                        #f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3],par1[4]);\n",
    "                        #f2.SetLineColor(ROOT.kRed)\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNIRQ\"))\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fs.SetNpx(100000);\n",
    "                        #fs.SetLineColor(ROOT.kGreen)\n",
    "                        #fb.SetLineStyle(4)\n",
    "                        #fb.SetLineColor(ROOT.kBlue)\n",
    "                        #fb.SetNpx(100000);\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                        fb.SetParameters(par2[3],par2[4],par2[5]);\n",
    "                        #fb.SetParameters(par2[3],par2[4],par2[5],par2[6]);\n",
    "\n",
    "\n",
    "                        #h1.SetTitleOffset(-1)\n",
    "                        #h1.SetFillStyle(3003);\n",
    "                        #h1.SetLineWidth(2)\n",
    "                        #h1.SetStats (0)\n",
    "                        #h1.SetYTitle(\"Entries\")\n",
    "                        #h1.SetLineColor(ROOT.kBlack)\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        #h3.SetLineWidth(2)\n",
    "                        #h3.SetStats (0)\n",
    "                        #h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                        #h1.Draw(\"pe\")\n",
    "                        #fs.Draw(\"SAME\")\n",
    "                        #fb.Draw(\"SAME\")\n",
    "                        #f2.Draw(\"SAME\")\n",
    "\n",
    "                        bin1 = h1.FindBin(fit_limit_low[mmm]+mm);\n",
    "                        bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                        #h2.Sumw2()\n",
    "\n",
    "                        integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                        integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "                        binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                        #tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                        #sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "\n",
    "                        signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                        if signal_under_peak>0:\n",
    "                            tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak                \n",
    "                        #sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                        #man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                        if sigma_signal_under_peak!=0:\n",
    "                            print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                        \n",
    "                        backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                        #if backgnd_under_peak<0:\n",
    "                            #print('Negative background')\n",
    "\n",
    "                        Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                        signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        #bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        if signal_under_peak_3_point_5_sigma>0:\n",
    "                            tot_sig_3_point_5_sigma= tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma                \n",
    "                        #tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                        #sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                        #man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        #bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        if signal_under_peak_2_point_5_sigma>0:\n",
    "                            tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                        #tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                        #sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                        #man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_sigm = (fs.Integral(par2[2] - (TMath.Abs(2*par2[1])),par2[2] + (TMath.Abs(2.*par2[1])))/binwidth);\n",
    "                        #bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        if signal_under_peak_2_sigm>0:\n",
    "                            tot_sig_2_sigma = tot_sig_2_sigma+signal_under_peak_2_sigm\n",
    "\n",
    "                        #std = par2 [1]\n",
    "                        #estd = f2.GetParError(1)\n",
    "                        del h0, h1, h2, h3, f1, f2, fb, fs\n",
    "                        #latex = ROOT . TLatex ()\n",
    "                        #latex . SetNDC ()\n",
    "                        #latex . SetTextSize (0.02)\n",
    "                        #latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                        #latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                        #latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                        #latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                        #latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "                        #latex . DrawLatex (0.4 ,0.55,\" True signal (MC=1) = %.f\"%(mc_counts))\n",
    "\n",
    "                        #legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                        #legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                        #legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx+Dx^{2}\",\"l\");\n",
    "                        #legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "                        #legend.AddEntry(fb,\"B+Cx+Dx^{2}\",\"l\");\n",
    "                        #legend . SetLineWidth (0)\n",
    "                        #legend.Draw()\n",
    "\n",
    "                        #canvas . cd ()\n",
    "                        #pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                        #pad2 . Draw ()\n",
    "                        #pad2 . cd ()\n",
    "                        #pad2.Clear()\n",
    "\n",
    "\n",
    "                        #h3.SetLineColor(TColor.GetColor(5))\n",
    "                        #h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                        #h3.Draw()\n",
    "                        #line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                        #line . SetLineColor ( ROOT . kRed )\n",
    "                        #line . SetLineWidth (2)\n",
    "                        #line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                        #pad1 . SetBottomMargin (0)\n",
    "                        #pad2 . SetTopMargin (0)\n",
    "                        #pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                        #h1 . GetXaxis (). SetLabelSize (0)\n",
    "                        #h1 . GetXaxis (). SetTitleSize (0)\n",
    "                        #h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                        #h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                        #h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                        #h3 . SetTitle (\"\")\n",
    "                        #h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                        #h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                        #h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                        #h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "                    #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                        #h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "                    #207,512 divisions\n",
    "                        #h3 . GetYaxis (). SetNdivisions (207)\n",
    "                        #h1 . GetYaxis (). SetRangeUser (0.5 ,3000)\n",
    "                        #h1 .GetYaxis().SetNdivisions(107)\n",
    "                        #h3 . GetXaxis (). SetNdivisions (207)\n",
    "                        gc.collect()\n",
    "                        #canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "                    else:\n",
    "                        tot_sig_2_point_5_sigma=tot_sig_2_point_5_sigma+0\n",
    "                        tot_sig_3_sigma=tot_sig_3_sigma+0\n",
    "                        #tot_sig_3_point_5_sigma=tot_sig_3_point_5_sigma+0\n",
    "                        #tot_sig_2_sigma = tot_sig_2_sigma+0\n",
    "            #lorentzian_pol2.append(tot_sig_2_sigma)\n",
    "            lorentzian_pol2.append(tot_sig_2_point_5_sigma)\n",
    "            lorentzian_pol2.append(tot_sig_3_sigma)\n",
    "            #lorentzian_pol2.append(tot_sig_3_point_5_sigma)\n",
    "            gc.collect()\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lorentzian_pol2)\n",
    "#lorentzian_pol2\n",
    "#lorentzian_3rd_order_pol\n",
    "#lorentzian_pol2.mean()\n",
    "#15*15*3*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = 15*15\n",
    "binning = 4\n",
    "size = configurations*3*3*binning\n",
    "#yields = {'yields':np.zeros(size)}\n",
    "#df_yields = pd.DataFrame(yields, columns = ['yields'])\n",
    "#df_yields['yields']= lorentzian_pol2\n",
    "#df_yields['pt_min']= pt_min\n",
    "#df_yields['y_min']= y_min\n",
    "new_yy = df_yields[(df_yields['pt_min']>0.4) & (df_yields['pt_min']<0.8)]\n",
    "new_yy[(new_yy['y_min']>1) & (new_yy['y_min']<1.4) & (new_yy['yields']>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,27,1):\n",
    "    df_yields['yields'].iloc[i+2*27] = lorentzian_pol2[i]\n",
    "    df_yields['yields'].iloc[i+3*27] = lorentzian_3rd_order_pol[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new = df_yields[(df_yields['yields']<119844+3000)&(df_yields['yields']>119844-3000)]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yields[df_yields['yields']>0]['yields'].hist(bins=20)\n",
    "#df_yields[df_yields['yields']>100000]['yields'].mean()\n",
    "plt.hist(lorentzian_pol2, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = 3\n",
    "size = configurations*3*3*3*2\n",
    "yields = {'yields':np.zeros(size)}\n",
    "df_yields = pd.DataFrame(yields, columns = ['yields'])\n",
    "df_yields['sigma']=np.zeros(size)\n",
    "df_yields['fit_lim']=np.zeros(size)\n",
    "df_yields['bins'] = np.zeros(size)\n",
    "df_yields['numbering'] = np.arange(0,size,1)\n",
    "df_yields['function'] = np.zeros(size)\n",
    "df_yields['BDT_cut'] = np.zeros(size)\n",
    "for i in range(0,27,1):\n",
    "    df_yields['function'].iloc[i] = 'lorentzian_pol2'\n",
    "    df_yields['function'].iloc[i+27] = 'lorentzian_pol3'\n",
    "    df_yields['yields'].iloc[i] = lorentzian_pol2[i]\n",
    "    df_yields['yields'].iloc[i+27] = lorentzian_3rd_order_pol[i]\n",
    "    df_yields['function'].iloc[i+2*27] = 'lorentzian_pol2'\n",
    "    df_yields['function'].iloc[i+3*27] = 'lorentzian_pol3'\n",
    "        \n",
    "for i in range(0,size,3):\n",
    "    df_yields['sigma'].iloc[i]  ='2.5 sigma'\n",
    "    df_yields['sigma'].iloc[i+1]='3 sigma'\n",
    "    df_yields['sigma'].iloc[i+2]='3.5 sigma'\n",
    "#for i in range(0,162,1):\n",
    "#    df_yields['yields'].iloc[162+i] = third_order_pol[i]\n",
    "\n",
    "for k in range(0,3,1):\n",
    "    for l in range (0,12,1):\n",
    "        df_yields['bins'] .iloc[k+l*9] = 70\n",
    "        df_yields['bins'] .iloc[k+3+l*9] = 100\n",
    "        df_yields['bins'] .iloc[k+6+l*9] = 130\n",
    "\n",
    "        \n",
    "for i in range(0,4,1):\n",
    "    for j in range(0,9,1):\n",
    "            df_yields['fit_lim'].iloc[i*27+j]=mass_range_min[0]+fit_limit_low[0]\n",
    "            df_yields['fit_lim'].iloc[i*27+9+j]=mass_range_min[0]+fit_limit_low[1]\n",
    "            df_yields['fit_lim'].iloc[i*27+18+j]=mass_range_min[0]+fit_limit_low[2]\n",
    "\n",
    "for i in range(0,2*27,1):\n",
    "    df_yields['BDT_cut'].iloc[i] = 'test_best'\n",
    "    df_yields['BDT_cut'].iloc[i+2*27] = '0.9'\n",
    "    df_yields['BDT_cut'].iloc[i+4*27] = '0.8'\n",
    "#for aj in range(0,int(size/2),1):\n",
    "#    df_yields['function'].iloc[aj]='Lorentzian plus 2nd order chebyshev'\n",
    "#    df_yields['function'].iloc[aj+int(size/2)]='Lorentzian plus 3rd order chebyshev'\n",
    "\n",
    "    \n",
    "    \n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "def yield_plot(variable1, variable2):\n",
    "    fig, axs = plt.subplots(figsize=(12,10))\n",
    "    bins1 = 19\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(variable1)))\n",
    "    axs.plot(variable1, variable2,label='', alpha =0.3)\n",
    "        #axs.set_ylabel('Starting Mass')   \n",
    "\n",
    "    #axs.legend(loc=(1.04,0.7), fontsize=13)\n",
    "\n",
    "    \n",
    "    \n",
    "yield_plot(df_yields['numbering'],df_yields['yields'])\n",
    "\n",
    "\n",
    "#df_yields[(df_yields['yields']>(df_yields['yields'].mean()-10)) & (df_yields['yields']<(df_yields['yields'].mean()+10))]\n",
    "df_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lorentzian 3rd order pol\n",
    "lorentzian_3rd_order_pol = []\n",
    "\n",
    "df = df4\n",
    "\n",
    "\n",
    "mass_range_min = [df['mass'].describe()[1]-1.2*(df['mass'].describe()[2])]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2]),\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,3,1):\n",
    "        canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "        canvas.Draw()\n",
    "        canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "\n",
    "        binning = [70,100,130]\n",
    "        for b in binning:\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            y_bin_low=-0.2\n",
    "            y_bin_up =0\n",
    "            for i in range(0,18,1):\n",
    "                y_bin_low = truncate(y_bin_low+0.2)\n",
    "                y_bin_up = truncate(y_bin_up+0.2)\n",
    "                df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "                pt_bin_low =-0.2\n",
    "                pt_bin_up =0\n",
    "                for i in range(0,18,1):\n",
    "                    pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                    pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                    df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                    #step 0\n",
    "                    if df_pt.shape[0]>1000:\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x+[3]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        fb.SetParameters(0,0,0,0);\n",
    "                        h0.Fit(fb,\"EM\");\n",
    "                        par = fb.GetParameters()\n",
    "                        #Step 1\n",
    "                        data = df_pt['mass']\n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x+[4]*x*x*x\",low_limit,upper_limit);\n",
    "                        #f1 = TF1(\"step1\",\"[0]*exp(-0.5*((x-1.115683)/0.0014)^2)+[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        f1.SetParameters(1,par[0], par[1], par[2], par[3]);\n",
    "                        h1.Fit(f1,\"RNI\");\n",
    "                        par1 = f1.GetParameters()\n",
    "\n",
    "                        canvas .Clear ()\n",
    "                        pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                        pad1 . Draw ()\n",
    "                        pad1 . cd ()\n",
    "                        pad1. Clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #step 2\n",
    "                        f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x+[6]*x*x*x\",low_limit,upper_limit)\n",
    "                        #f2 = TF1(\"full\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]+[4]*x+[5]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        f2.SetNpx(100000);\n",
    "                        f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3], par1[4]);\n",
    "                        f2.SetLineColor(ROOT.kRed)\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNIR\"))\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",low_limit,upper_limit);\n",
    "                        #fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        fs.SetNpx(100000);\n",
    "                        fs.SetLineColor(ROOT.kGreen)\n",
    "                        fb.SetLineStyle(4)\n",
    "                        fb.SetLineColor(ROOT.kBlue)\n",
    "                        fb.SetNpx(100000);\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                        fb.SetParameters(par2[3],par2[4],par2[5],par2[6]);\n",
    "\n",
    "\n",
    "                        h1.SetTitleOffset(-1)\n",
    "                        h1.SetFillStyle(3003);\n",
    "                        h1.SetLineWidth(2)\n",
    "                        h1.SetStats (0)\n",
    "                        h1.SetYTitle(\"Entries\")\n",
    "                        h1.SetLineColor(ROOT.kBlack)\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3.SetLineWidth(2)\n",
    "                        h3.SetStats (0)\n",
    "                        h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                        h1.Draw(\"pe\")\n",
    "                        fs.Draw(\"SAME\")\n",
    "                        fb.Draw(\"SAME\")\n",
    "                        f2.Draw(\"SAME\")\n",
    "\n",
    "                        bin1 = h1.FindBin(low_limit);\n",
    "                        bin2 = h1.FindBin(upper_limit);\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                        h2.Sumw2()\n",
    "\n",
    "                                #To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "                    #(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "                        integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                        integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "                    #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                        binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                        tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                        sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "                    #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                        signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                        if signal_under_peak<0:\n",
    "                            print('Negative signal')                \n",
    "                        sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                        man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                        if sigma_signal_under_peak!=0:\n",
    "                            print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                        tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "                    #Background\n",
    "                        backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                        if backgnd_under_peak<0:\n",
    "                            print('Negative background')\n",
    "                        sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                        tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "                    #Significance = signal/(signal+background)^0.5\n",
    "                        Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                        #3.5 sigma\n",
    "                        signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                        tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                        tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "                        std = par2 [1]\n",
    "                        estd = f2.GetParError(1)\n",
    "\n",
    "                        latex = ROOT . TLatex ()\n",
    "                        latex . SetNDC ()\n",
    "                        latex . SetTextSize (0.02)\n",
    "                        latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                        latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                        latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                        latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                        latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "\n",
    "\n",
    "                        legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                        legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                        legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx+Dx^{2}+Ex^{3}\",\"l\");\n",
    "                        legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "                        legend.AddEntry(fb,\"B+Cx+Dx^{2}+Ex^{3}\",\"l\");\n",
    "                        legend . SetLineWidth (0)\n",
    "                        legend.Draw()\n",
    "\n",
    "                        canvas . cd ()\n",
    "                        pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                        pad2 . Draw ()\n",
    "                        pad2 . cd ()\n",
    "                        pad2.Clear()\n",
    "\n",
    "\n",
    "                        h3.SetLineColor(TColor.GetColor(5))\n",
    "                        h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                        h3.Draw()\n",
    "                        line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                        line . SetLineColor ( ROOT . kRed )\n",
    "                        line . SetLineWidth (2)\n",
    "                        line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                        pad1 . SetBottomMargin (0)\n",
    "                        pad2 . SetTopMargin (0)\n",
    "                        pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                        h1 . GetXaxis (). SetLabelSize (0)\n",
    "                        h1 . GetXaxis (). SetTitleSize (0)\n",
    "                        h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                        h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                        h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                        h3 . SetTitle (\"\")\n",
    "                        h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                        h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                        h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                        h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "                    #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                        h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "                    #207,512 divisions\n",
    "                        h3 . GetYaxis (). SetNdivisions (207)\n",
    "                        h1 . GetYaxis (). SetRangeUser (0.5 ,3000)\n",
    "                        h1 .GetYaxis().SetNdivisions(107)\n",
    "                        h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "                        canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "            lorentzian_3rd_order_pol.append(tot_sig_2_point_5_sigma)\n",
    "            lorentzian_3rd_order_pol.append(tot_sig_3_sigma)\n",
    "            lorentzian_3rd_order_pol.append(tot_sig_3_point_5_sigma)\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian + second order pol\n",
    "gaussian_2nd = []\n",
    "\n",
    "df = df4\n",
    "\n",
    "\n",
    "mass_range_min = [df['mass'].describe()[1]-1.2*(df['mass'].describe()[2])]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2]),\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,3,1):\n",
    "        canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "        canvas.Draw()\n",
    "        canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "\n",
    "        binning = [70,100,130]\n",
    "        for b in binning:\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            y_bin_low=-0.2\n",
    "            y_bin_up =0\n",
    "            for i in range(0,18,1):\n",
    "                y_bin_low = truncate(y_bin_low+0.2)\n",
    "                y_bin_up = truncate(y_bin_up+0.2)\n",
    "                df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "                pt_bin_low =-0.2\n",
    "                pt_bin_up =0\n",
    "                for i in range(0,18,1):\n",
    "                    pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                    pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                    df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                    #step 0\n",
    "                    if df_pt.shape[0]>1000:\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        fb.SetParameters(0,0,0);\n",
    "                        h0.Fit(fb,\"EM\");\n",
    "                        par = fb.GetParameters()\n",
    "                        #Step 1\n",
    "                        data = df_pt['mass']\n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x\",low_limit,upper_limit);\n",
    "                        #f1 = TF1(\"step1\",\"[0]*exp(-0.5*((x-1.115683)/0.0014)^2)+[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        f1.SetParameters(1,par[0], par[1], par[2]);\n",
    "                        h1.Fit(f1,\"RNI\");\n",
    "                        par1 = f1.GetParameters()\n",
    "\n",
    "                        canvas .Clear ()\n",
    "                        pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                        pad1 . Draw ()\n",
    "                        pad1 . cd ()\n",
    "                        pad1. Clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #step 2\n",
    "                        f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x\",low_limit,upper_limit)\n",
    "                        #f2 = TF1(\"full\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]+[4]*x+[5]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        f2.SetNpx(100000);\n",
    "                        f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3]);\n",
    "                        f2.SetLineColor(ROOT.kRed)\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNIR\"))\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",low_limit,upper_limit);\n",
    "                        #fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        fs.SetNpx(100000);\n",
    "                        fs.SetLineColor(ROOT.kGreen)\n",
    "                        fb.SetLineStyle(4)\n",
    "                        fb.SetLineColor(ROOT.kBlue)\n",
    "                        fb.SetNpx(100000);\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                        fb.SetParameters(par2[3],par2[4],par2[5]);\n",
    "\n",
    "\n",
    "                        h1.SetTitleOffset(-1)\n",
    "                        h1.SetFillStyle(3003);\n",
    "                        h1.SetLineWidth(2)\n",
    "                        h1.SetStats (0)\n",
    "                        h1.SetYTitle(\"Entries\")\n",
    "                        h1.SetLineColor(ROOT.kBlack)\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3.SetLineWidth(2)\n",
    "                        h3.SetStats (0)\n",
    "                        h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                        h1.Draw(\"pe\")\n",
    "                        fs.Draw(\"SAME\")\n",
    "                        fb.Draw(\"SAME\")\n",
    "                        f2.Draw(\"SAME\")\n",
    "\n",
    "                        bin1 = h1.FindBin(low_limit);\n",
    "                        bin2 = h1.FindBin(upper_limit);\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                        h2.Sumw2()\n",
    "\n",
    "                                #To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "                    #(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "                        integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                        integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "                    #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                        binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                        tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                        sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "                    #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                        signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                        if signal_under_peak<0:\n",
    "                            print('Negative signal')                \n",
    "                        sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                        man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                        if sigma_signal_under_peak!=0:\n",
    "                            print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                        tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "                    #Background\n",
    "                        backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                        if backgnd_under_peak<0:\n",
    "                            print('Negative background')\n",
    "                        sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                        tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "                    #Significance = signal/(signal+background)^0.5\n",
    "                        Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                        #3.5 sigma\n",
    "                        signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                        tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                        tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "                        std = par2 [1]\n",
    "                        estd = f2.GetParError(1)\n",
    "\n",
    "                        latex = ROOT . TLatex ()\n",
    "                        latex . SetNDC ()\n",
    "                        latex . SetTextSize (0.02)\n",
    "                        latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                        latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                        latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                        latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                        latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "\n",
    "\n",
    "                        legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                        legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                        legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx+Dx^{2}\",\"l\");\n",
    "                        legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "                        legend.AddEntry(fb,\"B+Cx+Dx^{2}\",\"l\");\n",
    "                        legend . SetLineWidth (0)\n",
    "                        legend.Draw()\n",
    "\n",
    "                        canvas . cd ()\n",
    "                        pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                        pad2 . Draw ()\n",
    "                        pad2 . cd ()\n",
    "                        pad2.Clear()\n",
    "\n",
    "\n",
    "                        h3.SetLineColor(TColor.GetColor(5))\n",
    "                        h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                        h3.Draw()\n",
    "                        line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                        line . SetLineColor ( ROOT . kRed )\n",
    "                        line . SetLineWidth (2)\n",
    "                        line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                        pad1 . SetBottomMargin (0)\n",
    "                        pad2 . SetTopMargin (0)\n",
    "                        pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                        h1 . GetXaxis (). SetLabelSize (0)\n",
    "                        h1 . GetXaxis (). SetTitleSize (0)\n",
    "                        h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                        h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                        h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                        h3 . SetTitle (\"\")\n",
    "                        h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                        h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                        h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                        h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "                    #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                        h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "                    #207,512 divisions\n",
    "                        h3 . GetYaxis (). SetNdivisions (207)\n",
    "                        h1 . GetYaxis (). SetRangeUser (0.5 ,3000)\n",
    "                        h1 .GetYaxis().SetNdivisions(107)\n",
    "                        h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "                        canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "            gaussian_2nd.append(tot_sig_2_point_5_sigma)\n",
    "            gaussian_2nd.append(tot_sig_3_sigma)\n",
    "            gaussian_2nd.append(tot_sig_3_point_5_sigma)\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd order chebyshev back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_order_pol = []\n",
    "\n",
    "mass_range_min = [1.0853341]\n",
    "fit_limit_low=[0,0.05*0.059818,0.1*0.059818,1.2707699000000001,1.2707699000000001+(0.05*0.059818),1.2707699000000001 +(0.1*0.059818)]\n",
    "for mm in mass_range_min:\n",
    "    canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "    canvas.Draw()\n",
    "    canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "    \n",
    "\n",
    "    binning = [70,100,130]\n",
    "    for b in binning:\n",
    "\n",
    "        bins=b\n",
    "        for mmm in range(0,3,1):\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            for entry in list1:\n",
    "                distribution = entry\n",
    "            #Step 1\n",
    "                data0 = background_selector(entry)\n",
    "                h0 = ROOT.TH1F(\"Background\",\"Background without peak\",bins,mm,1.23)\n",
    "                for i in range(0,data0.shape[0]):\n",
    "                    h0.Fill(data0.iloc[i])\n",
    "                fb = TF1(\"fb\",\"[0]*x*x*x-[1]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fb.SetParameters(0,0);\n",
    "                h0.Fit(fb,\"RNIFCWW\");\n",
    "                par = fb.GetParameters()\n",
    "\n",
    "            #Step 1\n",
    "                data = distribution['mass']\n",
    "        #the minimum x (lower edge of the first bin)=mm        \n",
    "                h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(distribution['rapidity'].min(),distribution['rapidity'].max(),distribution['pT'].min(),distribution['pT'].max(), mm, bins),bins,mm,1.23)\n",
    "                for i in range(0,data.shape[0]):\n",
    "                    h1.Fill(data.iloc[i])\n",
    "                f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]*x*x*x-[2]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                f1.SetParameters(1,par[0],par[1]);\n",
    "                h1.Fit(f1,\"RNI\");\n",
    "                par1 = f1.GetParameters()\n",
    "\n",
    "\n",
    "            #Step2\n",
    "                canvas .Clear ()\n",
    "                pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                pad1 . Draw ()\n",
    "                pad1 . cd ()\n",
    "                pad1. Clear()\n",
    "\n",
    "\n",
    "                h1.SetTitleOffset(-1)\n",
    "                h1.SetFillStyle(3003);\n",
    "                h1.SetLineWidth(2)\n",
    "                h1.SetStats (0)\n",
    "                h1.SetYTitle(\"Entries\")\n",
    "                h1.SetLineColor(ROOT.kBlack)\n",
    "                h2 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3.SetLineWidth(2)\n",
    "                h3.SetStats (0)\n",
    "                h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ 0.25*[1]*[1]) +[3]*x*x*x-[4]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                f2.SetNpx(100000);\n",
    "                f2.SetParameters(par1[0],0.0001,1.115,par1[1], par1[2]);\n",
    "                f2.SetLineColor(ROOT.kRed)\n",
    "                h1.Fit(f2,\"MNIR\");\n",
    "                par2 = f2.GetParameters()\n",
    "\n",
    "\n",
    "                h1.Draw(\"pe\")\n",
    "                fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fs.SetNpx(100000);\n",
    "                fs.SetLineColor(ROOT.kGreen)\n",
    "                fb.SetLineStyle(4)\n",
    "                fb.SetLineColor(ROOT.kBlue)\n",
    "                fb.SetNpx(100000);\n",
    "                fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                fb.SetParameters(par2[3],par2[4]);\n",
    "                fs.Draw(\"SAME\")\n",
    "                fb.Draw(\"SAME\")\n",
    "                f2.Draw(\"SAME\")\n",
    "\n",
    "                bin1 = h1.FindBin(mm+fit_limit_low[mmm]);\n",
    "                bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                for i in range(bin1,bin2):\n",
    "                    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                    t_value = h1.GetBinContent(i)\n",
    "                    h2.SetBinContent(i,f_value)\n",
    "                    if (h1.GetBinError(i) > 0):\n",
    "                        h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                h2.Sumw2()\n",
    "\n",
    "            #To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "            #(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "                integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "            #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "            #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                if signal_under_peak<0:\n",
    "                    print('Negative signal')                \n",
    "\n",
    "                sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                if sigma_signal_under_peak!=0:\n",
    "                    print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "            #Background\n",
    "                backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                if backgnd_under_peak<0:\n",
    "                    print('negative background')                \n",
    "                sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "            #Significance = signal/(signal+background)^0.5\n",
    "                Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                #3.5 sigma\n",
    "                signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                std = par2 [1]\n",
    "                estd = f2.GetParError(1)\n",
    "\n",
    "                latex = ROOT . TLatex ()\n",
    "                latex . SetNDC ()\n",
    "                latex . SetTextSize (0.02)\n",
    "                latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "\n",
    "\n",
    "                legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+Bx^{}-Cx\",\"l\");\n",
    "                legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "                legend.AddEntry(fb,\"Bx^{3}-Cx\",\"l\");\n",
    "                legend . SetLineWidth (0)\n",
    "                legend.Draw()\n",
    "                \n",
    "                canvas . cd ()\n",
    "                pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                pad2 . Draw ()\n",
    "                pad2 . cd ()\n",
    "                pad2.Clear()\n",
    "\n",
    "\n",
    "                h3.SetLineColor(TColor.GetColor(5))\n",
    "                h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                h3.Draw()\n",
    "                line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                line . SetLineColor ( ROOT . kRed )\n",
    "                line . SetLineWidth (2)\n",
    "                line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                pad1 . SetBottomMargin (0)\n",
    "                pad2 . SetTopMargin (0)\n",
    "                pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                h1 . GetXaxis (). SetLabelSize (0)\n",
    "                h1 . GetXaxis (). SetTitleSize (0)\n",
    "                h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                h3 . SetTitle (\"\")\n",
    "                h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "            #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "            #207,512 divisions\n",
    "                h3 . GetYaxis (). SetNdivisions (207)\n",
    "                h1 . GetYaxis (). SetRangeUser (0.5 ,2500)\n",
    "                h1 .GetYaxis().SetNdivisions(107)\n",
    "                h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "                canvas.Update()\n",
    "                canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "            third_order_pol.append(tot_sig_2_point_5_sigma)\n",
    "            third_order_pol.append(tot_sig_3_sigma)\n",
    "            third_order_pol.append(tot_sig_3_point_5_sigma)\n",
    "\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd order normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_order_pol = []\n",
    "mass_range_min = [1.0853341]\n",
    "fit_limit_low=[0,0.05*0.059818,0.1*0.059818,1.2707699000000001,1.2707699000000001+(0.05*0.059818),1.2707699000000001 +(0.1*0.059818)]\n",
    "for mm in mass_range_min:\n",
    "    canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "    canvas.Draw()\n",
    "    canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "    \n",
    "\n",
    "    binning = [70,100,130]\n",
    "    for b in binning:\n",
    "\n",
    "        bins=b\n",
    "        for mmm in range(0,3,1):\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            for entry in list1:\n",
    "                distribution = entry\n",
    "            #Step 1\n",
    "                data0 = background_selector(entry)\n",
    "                h0 = ROOT.TH1F(\"Background\",\"Background without peak\",bins,mm,1.23)\n",
    "                for i in range(0,data0.shape[0]):\n",
    "                    h0.Fill(data0.iloc[i])\n",
    "                fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fb.SetParameters(0,0,0);\n",
    "                h0.Fit(fb,\"EM\");\n",
    "                par = fb.GetParameters()\n",
    "\n",
    "            #Step 1\n",
    "                data = distribution['mass']\n",
    "        #the minimum x (lower edge of the first bin)=mm        \n",
    "                h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(distribution['rapidity'].min(),distribution['rapidity'].max(),distribution['pT'].min(),distribution['pT'].max(), mm, bins),bins,mm,1.23)\n",
    "                for i in range(0,data.shape[0]):\n",
    "                    h1.Fill(data.iloc[i])\n",
    "                f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                f1.SetParameters(1,par[0],par[1],par[2]);\n",
    "                h1.Fit(f1,\"EM\");\n",
    "                par1 = f1.GetParameters()\n",
    "\n",
    "\n",
    "            #Step2\n",
    "                canvas .Clear ()\n",
    "                pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                pad1 . Draw ()\n",
    "                pad1 . cd ()\n",
    "                pad1. Clear()\n",
    "\n",
    "\n",
    "                h1.SetTitleOffset(-1)\n",
    "                h1.SetFillStyle(3003);\n",
    "                h1.SetLineWidth(2)\n",
    "                h1.SetStats (0)\n",
    "                h1.SetYTitle(\"Entries\")\n",
    "                h1.SetLineColor(ROOT.kBlack)\n",
    "                h2 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3.SetLineWidth(2)\n",
    "                h3.SetStats (0)\n",
    "                h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3])\n",
    "                f2.SetNpx(100000);\n",
    "                f2.SetParameters(par1[0],0.0001,1.115,par1[1],par1[2],par1[3]);\n",
    "                f2.SetLineColor(ROOT.kRed)\n",
    "                h1.Fit(f2,\"EM\");\n",
    "                par2 = f2.GetParameters()\n",
    "\n",
    "\n",
    "                h1.Draw(\"pe\")\n",
    "                fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fs.SetNpx(100000);\n",
    "                fs.SetLineColor(ROOT.kGreen)\n",
    "                fb.SetLineStyle(4)\n",
    "                fb.SetLineColor(ROOT.kBlue)\n",
    "                fb.SetNpx(100000);\n",
    "                fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                fb.SetParameters(par2[3],par2[4],par2[5]);\n",
    "                fs.Draw(\"SAME\")\n",
    "                fb.Draw(\"SAME\")\n",
    "                f2.Draw(\"SAME\")\n",
    "\n",
    "                bin1 = h1.FindBin(mm+fit_limit_low[mmm]);\n",
    "                bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                for i in range(bin1,bin2):\n",
    "                    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                    t_value = h1.GetBinContent(i)\n",
    "                    h2.SetBinContent(i,f_value)\n",
    "                    if (h1.GetBinError(i) > 0):\n",
    "                        h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                h2.Sumw2()\n",
    "\n",
    "            #To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "            #(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "                integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "            #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "            #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                if sigma_signal_under_peak!=0:\n",
    "                    print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "            #Background\n",
    "                backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                if backgnd_under_peak<0:\n",
    "                    print('Negative background')\n",
    "                sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "            #Significance = signal/(signal+background)^0.5\n",
    "                Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                #3.5 sigma\n",
    "                signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                std = par2 [1]\n",
    "                estd = f2.GetParError(1)\n",
    "\n",
    "                latex = ROOT . TLatex ()\n",
    "                latex . SetNDC ()\n",
    "                latex . SetTextSize (0.02)\n",
    "                latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "\n",
    "\n",
    "                legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx+Dx^{2}\",\"l\");\n",
    "                legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "                legend.AddEntry(fb,\"B+Cx+Dx^{2}\",\"l\");\n",
    "                legend . SetLineWidth (0)\n",
    "                legend.Draw()\n",
    "\n",
    "                canvas . cd ()\n",
    "                pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                pad2 . Draw ()\n",
    "                pad2 . cd ()\n",
    "                pad2.Clear()\n",
    "\n",
    "\n",
    "                h3.SetLineColor(TColor.GetColor(5))\n",
    "                h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                h3.Draw()\n",
    "                line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                line . SetLineColor ( ROOT . kRed )\n",
    "                line . SetLineWidth (2)\n",
    "                line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                pad1 . SetBottomMargin (0)\n",
    "                pad2 . SetTopMargin (0)\n",
    "                pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                h1 . GetXaxis (). SetLabelSize (0)\n",
    "                h1 . GetXaxis (). SetTitleSize (0)\n",
    "                h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                h3 . SetTitle (\"\")\n",
    "                h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "            #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "            #207,512 divisions\n",
    "                h3 . GetYaxis (). SetNdivisions (207)\n",
    "                h1 . GetYaxis (). SetRangeUser (0.5 ,7000)\n",
    "                h1 .GetYaxis().SetNdivisions(107)\n",
    "                h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "                canvas.Update()\n",
    "                canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "            second_order_pol.append(tot_sig_2_point_5_sigma)\n",
    "            second_order_pol.append(tot_sig_3_sigma)\n",
    "            second_order_pol.append(tot_sig_3_point_5_sigma)\n",
    "\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del h0, canvas, h1, h2, h3, pad1, pad2, f1,f2, fs, fb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pol = []\n",
    "mass_range_min = [1.0853341]\n",
    "fit_limit_low=[0,0.05*0.059818,0.1*0.059818,1.2707699000000001,1.2707699000000001+(0.05*0.059818),1.2707699000000001 +(0.1*0.059818)]\n",
    "for mm in mass_range_min:\n",
    "    canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "    canvas.Draw()\n",
    "    canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "    \n",
    "\n",
    "    binning = [70,100,130]\n",
    "    for b in binning:\n",
    "\n",
    "        bins=b\n",
    "        for mmm in range(0,3,1):\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            for entry in list1:\n",
    "                distribution = entry\n",
    "            #Step 1\n",
    "                data0 = background_selector(entry)\n",
    "                h0 = ROOT.TH1F(\"Background\",\"Background without peak\",bins,mm,1.23)\n",
    "                for i in range(0,data0.shape[0]):\n",
    "                    h0.Fill(data0.iloc[i])\n",
    "                fb = TF1(\"fb\",\"[0]+[1]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fb.SetParameters(0,0);\n",
    "                h0.Fit(fb,\"RNIFCWW\");\n",
    "                par = fb.GetParameters()\n",
    "\n",
    "            #Step 1\n",
    "                data = distribution['mass']\n",
    "        #the minimum x (lower edge of the first bin)=mm        \n",
    "                h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(distribution['rapidity'].min(),distribution['rapidity'].max(),distribution['pT'].min(),distribution['pT'].max(), mm, bins),bins,mm,1.23)\n",
    "                for i in range(0,data.shape[0]):\n",
    "                    h1.Fill(data.iloc[i])\n",
    "                f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                f1.SetParameters(1,par[0],par[1]);\n",
    "                h1.Fit(f1,\"RNI\");\n",
    "                par1 = f1.GetParameters()\n",
    "\n",
    "\n",
    "            #Step2\n",
    "                canvas .Clear ()\n",
    "                pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                pad1 . Draw ()\n",
    "                pad1 . cd ()\n",
    "                pad1. Clear()\n",
    "\n",
    "\n",
    "                h1.SetTitleOffset(-1)\n",
    "                h1.SetFillStyle(3003);\n",
    "                h1.SetLineWidth(2)\n",
    "                h1.SetStats (0)\n",
    "                h1.SetYTitle(\"Entries\")\n",
    "                h1.SetLineColor(ROOT.kBlack)\n",
    "                h2 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3.SetLineWidth(2)\n",
    "                h3.SetStats (0)\n",
    "                h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3])\n",
    "                f2.SetNpx(100000);\n",
    "                f2.SetParameters(par1[0],0.0001,1.115,par1[1],par1[2]);\n",
    "                f2.SetLineColor(ROOT.kRed)\n",
    "                h1.Fit(f2,\"MNIR\");\n",
    "                par2 = f2.GetParameters()\n",
    "\n",
    "\n",
    "                h1.Draw(\"pe\")\n",
    "                fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fs.SetNpx(100000);\n",
    "                fs.SetLineColor(ROOT.kGreen)\n",
    "                fb.SetLineStyle(4)\n",
    "                fb.SetLineColor(ROOT.kBlue)\n",
    "                fb.SetNpx(100000);\n",
    "                fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                fb.SetParameters(par2[3],par2[4]);\n",
    "                fs.Draw(\"SAME\")\n",
    "                fb.Draw(\"SAME\")\n",
    "                f2.Draw(\"SAME\")\n",
    "\n",
    "                bin1 = h1.FindBin(mm+fit_limit_low[mmm]);\n",
    "                bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                for i in range(bin1,bin2):\n",
    "                    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                    t_value = h1.GetBinContent(i)\n",
    "                    h2.SetBinContent(i,f_value)\n",
    "                    if (h1.GetBinError(i) > 0):\n",
    "                        h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                h2.Sumw2()\n",
    "\n",
    "            #To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "            #(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "                integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "            #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "            #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                if sigma_signal_under_peak!=0:\n",
    "                    print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "            #Background\n",
    "                backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                if backgnd_under_peak<0:\n",
    "                    print('fail')\n",
    "                sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "            #Significance = signal/(signal+background)^0.5\n",
    "                Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                #3.5 sigma\n",
    "                signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                std = par2 [1]\n",
    "                estd = f2.GetParError(1)\n",
    "\n",
    "                latex = ROOT . TLatex ()\n",
    "                latex . SetNDC ()\n",
    "                latex . SetTextSize (0.02)\n",
    "                latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "\n",
    "\n",
    "                legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx\",\"l\");\n",
    "                legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "                legend.AddEntry(fb,\"B+Cx\",\"l\");\n",
    "                legend . SetLineWidth (0)\n",
    "                legend.Draw()\n",
    "\n",
    "                canvas . cd ()\n",
    "                pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                pad2 . Draw ()\n",
    "                pad2 . cd ()\n",
    "                pad2.Clear()\n",
    "\n",
    "\n",
    "                h3.SetLineColor(TColor.GetColor(5))\n",
    "                h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                h3.Draw()\n",
    "                line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                line . SetLineColor ( ROOT . kRed )\n",
    "                line . SetLineWidth (2)\n",
    "                line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                pad1 . SetBottomMargin (0)\n",
    "                pad2 . SetTopMargin (0)\n",
    "                pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                h1 . GetXaxis (). SetLabelSize (0)\n",
    "                h1 . GetXaxis (). SetTitleSize (0)\n",
    "                h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                h3 . SetTitle (\"\")\n",
    "                h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "            #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "            #207,512 divisions\n",
    "                h3 . GetYaxis (). SetNdivisions (207)\n",
    "                h1 . GetYaxis (). SetRangeUser (0.5 ,2500)\n",
    "                h1 .GetYaxis().SetNdivisions(107)\n",
    "                h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "                canvas.Update()\n",
    "                canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "            linear_pol.append(tot_sig_2_point_5_sigma)\n",
    "            linear_pol.append(tot_sig_3_sigma)\n",
    "            linear_pol.append(tot_sig_3_point_5_sigma)\n",
    "\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_2nd_order_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[df_clean['issignal']==1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian with second order pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_2nd_order_pol = []\n",
    "mass_range_min = [1.0853341]\n",
    "fit_limit_low=[0,0.05*0.059818,0.1*0.059818,1.2707699000000001,1.2707699000000001+(0.05*0.059818),1.2707699000000001 +(0.1*0.059818)]\n",
    "for mm in mass_range_min:\n",
    "    canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "    canvas.Draw()\n",
    "    canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "    \n",
    "\n",
    "    binning = [70,100,130]\n",
    "    for b in binning:\n",
    "\n",
    "        bins=b\n",
    "        for mmm in range(0,3,1):\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            for entry in list1:\n",
    "                distribution = entry\n",
    "            #Step 1\n",
    "                data0 = background_selector(entry)\n",
    "                h0 = ROOT.TH1F(\"Background\",\"Background without peak\",bins,mm,1.23)\n",
    "                for i in range(0,data0.shape[0]):\n",
    "                    h0.Fill(data0.iloc[i])\n",
    "                fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fb.SetParameters(0,0,0);\n",
    "                h0.Fit(fb,\"LRNIFCWW\");\n",
    "                par = fb.GetParameters()\n",
    "\n",
    "            #Step 1\n",
    "                data = distribution['mass']\n",
    "        #the minimum x (lower edge of the first bin)=mm        \n",
    "                h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(distribution['rapidity'].min(),distribution['rapidity'].max(),distribution['pT'].min(),distribution['pT'].max(), mm, bins),bins,mm,1.23)\n",
    "                for i in range(0,data.shape[0]):\n",
    "                    h1.Fill(data.iloc[i])\n",
    "                f1 = TF1(\"step1\",\"[0]*exp(-0.5*((x-1.115683)/0.0014)^2)+[1]+[2]*x+[3]*x*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                f1.SetParameters(1,par[0],par[1], par[2]);\n",
    "                h1.Fit(f1,\"LRNI\");\n",
    "                par1 = f1.GetParameters()\n",
    "\n",
    "\n",
    "            #Step2\n",
    "                canvas .Clear ()\n",
    "                pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                pad1 . Draw ()\n",
    "                pad1 . cd ()\n",
    "                pad1. Clear()\n",
    "\n",
    "\n",
    "                h1.SetTitleOffset(-1)\n",
    "                h1.SetFillStyle(3003);\n",
    "                h1.SetLineWidth(2)\n",
    "                h1.SetStats (0)\n",
    "                h1.SetYTitle(\"Entries\")\n",
    "                h1.SetLineColor(ROOT.kBlack)\n",
    "                h2 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3.SetLineWidth(2)\n",
    "                h3.SetStats (0)\n",
    "                h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                f2 = TF1(\"full\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]+[4]*x+[5]*x*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3])\n",
    "                f2.SetNpx(100000);\n",
    "                f2.SetParameters(par1[0],0.001,1.115,par1[1],par1[2], par1[3]);\n",
    "                f2.SetLineColor(ROOT.kRed)\n",
    "                h1.Fit(f2,\"LMNIR\");\n",
    "                par2 = f2.GetParameters()\n",
    "\n",
    "\n",
    "                h1.Draw(\"pe\")\n",
    "                fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fs.SetNpx(100000);\n",
    "                fs.SetLineColor(ROOT.kGreen)\n",
    "                fb.SetLineStyle(4)\n",
    "                fb.SetLineColor(ROOT.kBlue)\n",
    "                fb.SetNpx(100000);\n",
    "                fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                fb.SetParameters(par2[3],par2[4], par2[5]);\n",
    "                fs.Draw(\"SAME\")\n",
    "                fb.Draw(\"SAME\")\n",
    "                f2.Draw(\"SAME\")\n",
    "\n",
    "                bin1 = h1.FindBin(mm+fit_limit_low[mmm]);\n",
    "                bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                for i in range(bin1,bin2):\n",
    "                    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                    t_value = h1.GetBinContent(i)\n",
    "                    h2.SetBinContent(i,f_value)\n",
    "                    if (h1.GetBinError(i) > 0):\n",
    "                        h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                h2.Sumw2()\n",
    "\n",
    "            #To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "            #(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "                integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "            #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "            #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                if sigma_signal_under_peak!=0:\n",
    "                    print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "            #Background\n",
    "                backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                if backgnd_under_peak<0:\n",
    "                    print('fail')\n",
    "                sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "            #Significance = signal/(signal+background)^0.5\n",
    "                Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                #3.5 sigma\n",
    "                signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                std = par2 [1]\n",
    "                estd = f2.GetParError(1)\n",
    "\n",
    "                latex = ROOT . TLatex ()\n",
    "                latex . SetNDC ()\n",
    "                latex . SetTextSize (0.02)\n",
    "                latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "\n",
    "\n",
    "                legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                legend.AddEntry(f2,\"Ae^{#frac{-1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}+B+Cx+Dx^{2}\",\"l\");\n",
    "                legend.AddEntry(fs,\"Ae^{#frac{-1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}\",\"l\");\n",
    "                legend.AddEntry(fb,\"B+Cx+Dx^{2}\",\"l\");\n",
    "                legend . SetLineWidth (0)\n",
    "                legend.Draw()\n",
    "\n",
    "                canvas . cd ()\n",
    "                pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                pad2 . Draw ()\n",
    "                pad2 . cd ()\n",
    "                pad2.Clear()\n",
    "\n",
    "\n",
    "                h3.SetLineColor(TColor.GetColor(5))\n",
    "                h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                h3.Draw()\n",
    "                line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                line . SetLineColor ( ROOT . kRed )\n",
    "                line . SetLineWidth (2)\n",
    "                line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                pad1 . SetBottomMargin (0)\n",
    "                pad2 . SetTopMargin (0)\n",
    "                pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                h1 . GetXaxis (). SetLabelSize (0)\n",
    "                h1 . GetXaxis (). SetTitleSize (0)\n",
    "                h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                h3 . SetTitle (\"\")\n",
    "                h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "            #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "            #207,512 divisions\n",
    "                h3 . GetYaxis (). SetNdivisions (207)\n",
    "                h1 . GetYaxis (). SetRangeUser (0.5 ,2950)\n",
    "                h1 .GetYaxis().SetNdivisions(107)\n",
    "                h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "                canvas.Update()\n",
    "                canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "            gaussian_2nd_order_pol.append(tot_sig_2_point_5_sigma)\n",
    "            gaussian_2nd_order_pol.append(tot_sig_3_sigma)\n",
    "            gaussian_2nd_order_pol.append(tot_sig_3_point_5_sigma)\n",
    "\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian with linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_linear = []\n",
    "mass_range_min = [1.08,1.085, 1.09, 1.092, 1.094, 1.096]\n",
    "fit_limit_low=[0,0.001,0.005,1.21,1.22,1.23]\n",
    "for mm in mass_range_min:\n",
    "    canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "    canvas.Draw()\n",
    "    canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "    \n",
    "\n",
    "    binning = [70,100,130]\n",
    "    for b in binning:\n",
    "\n",
    "        bins=b\n",
    "        for mmm in range(0,3,1):\n",
    "            tot_sig_3_sigma = 0\n",
    "            tot_bac_3_sigma = 0\n",
    "            tot_sig_3_point_5_sigma = 0\n",
    "            tot_bac_3_point_5_sigma = 0\n",
    "            tot_sig_2_point_5_sigma = 0\n",
    "            tot_bac_2_point_5_sigma = 0\n",
    "            for entry in list1:\n",
    "                distribution = entry\n",
    "            #Step 1\n",
    "                data0 = background_selector(entry)\n",
    "                h0 = ROOT.TH1F(\"Background\",\"Background without peak\",bins,mm,1.23)\n",
    "                for i in range(0,data0.shape[0]):\n",
    "                    h0.Fill(data0.iloc[i])\n",
    "                fb = TF1(\"fb\",\"[0]+[1]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fb.SetParameters(0,0);\n",
    "                h0.Fit(fb,\"LRNIFCWW\");\n",
    "                par = fb.GetParameters()\n",
    "\n",
    "            #Step 1\n",
    "                data = distribution['mass']\n",
    "        #the minimum x (lower edge of the first bin)=mm        \n",
    "                h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(distribution['rapidity'].min(),distribution['rapidity'].max(),distribution['pT'].min(),distribution['pT'].max(), mm, bins),bins,mm,1.23)\n",
    "                for i in range(0,data.shape[0]):\n",
    "                    h1.Fill(data.iloc[i])\n",
    "                f1 = TF1(\"step1\",\"[0]*exp(-0.5*((x-1.115683)/0.0014)^2)+[1]+[2]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                f1.SetParameters(1,par[0],par[1]);\n",
    "                h1.Fit(f1,\"LRNI\");\n",
    "                par1 = f1.GetParameters()\n",
    "\n",
    "\n",
    "            #Step2\n",
    "                canvas .Clear ()\n",
    "                pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                pad1 . Draw ()\n",
    "                pad1 . cd ()\n",
    "                pad1. Clear()\n",
    "\n",
    "\n",
    "                h1.SetTitleOffset(-1)\n",
    "                h1.SetFillStyle(3003);\n",
    "                h1.SetLineWidth(2)\n",
    "                h1.SetStats (0)\n",
    "                h1.SetYTitle(\"Entries\")\n",
    "                h1.SetLineColor(ROOT.kBlack)\n",
    "                h2 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.23);\n",
    "                h3.SetLineWidth(2)\n",
    "                h3.SetStats (0)\n",
    "                h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "                f2 = TF1(\"full\",\"[0]*exp(-0.5*((x-[2])/[1])^2)+[3]+[4]*x\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3])\n",
    "                f2.SetNpx(100000);\n",
    "                f2.SetParameters(par1[0],0.001,1.115,par1[1],par1[2]);\n",
    "                f2.SetLineColor(ROOT.kRed)\n",
    "                h1.Fit(f2,\"LMNIR\");\n",
    "                par2 = f2.GetParameters()\n",
    "\n",
    "\n",
    "                h1.Draw(\"pe\")\n",
    "                fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",mm+fit_limit_low[mmm],fit_limit_low[mmm+3]);\n",
    "                fs.SetNpx(100000);\n",
    "                fs.SetLineColor(ROOT.kGreen)\n",
    "                fb.SetLineStyle(4)\n",
    "                fb.SetLineColor(ROOT.kBlue)\n",
    "                fb.SetNpx(100000);\n",
    "                fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                fb.SetParameters(par2[3],par2[4]);\n",
    "                fs.Draw(\"SAME\")\n",
    "                fb.Draw(\"SAME\")\n",
    "                f2.Draw(\"SAME\")\n",
    "\n",
    "                bin1 = h1.FindBin(mm+fit_limit_low[mmm]);\n",
    "                bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                for i in range(bin1,bin2):\n",
    "                    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                    t_value = h1.GetBinContent(i)\n",
    "                    h2.SetBinContent(i,f_value)\n",
    "                    if (h1.GetBinError(i) > 0):\n",
    "                        h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                h2.Sumw2()\n",
    "\n",
    "            #To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "            #(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "                integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "            #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "            #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "                sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                if sigma_signal_under_peak!=0:\n",
    "                    print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "            #Background\n",
    "                backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                if backgnd_under_peak<0:\n",
    "                    print('fail')\n",
    "                sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "            #Significance = signal/(signal+background)^0.5\n",
    "                Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                #3.5 sigma\n",
    "                signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                std = par2 [1]\n",
    "                estd = f2.GetParError(1)\n",
    "\n",
    "                latex = ROOT . TLatex ()\n",
    "                latex . SetNDC ()\n",
    "                latex . SetTextSize (0.02)\n",
    "                latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "                latex . DrawLatex (0.4 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "\n",
    "\n",
    "                legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                legend.AddEntry(f2,\"Ae^{#frac{-1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}+B+Cx\",\"l\");\n",
    "                legend.AddEntry(fs,\"Ae^{#frac{-1}{2} #frac{(x-#mu)^{2}}{#sigma^{2}}}\",\"l\");\n",
    "                legend.AddEntry(fb,\"B+Cx\",\"l\");\n",
    "                legend . SetLineWidth (0)\n",
    "                legend.Draw()\n",
    "\n",
    "                canvas . cd ()\n",
    "                pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                pad2 . Draw ()\n",
    "                pad2 . cd ()\n",
    "                pad2.Clear()\n",
    "\n",
    "\n",
    "                h3.SetLineColor(TColor.GetColor(5))\n",
    "                h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                h3.Draw()\n",
    "                line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "                line . SetLineColor ( ROOT . kRed )\n",
    "                line . SetLineWidth (2)\n",
    "                line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                pad1 . SetBottomMargin (0)\n",
    "                pad2 . SetTopMargin (0)\n",
    "                pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                h1 . GetXaxis (). SetLabelSize (0)\n",
    "                h1 . GetXaxis (). SetTitleSize (0)\n",
    "                h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                h3 . SetTitle (\"\")\n",
    "                h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "            #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "            #207,512 divisions\n",
    "                h3 . GetYaxis (). SetNdivisions (207)\n",
    "                h1 . GetYaxis (). SetRangeUser (0.5 ,2650)\n",
    "                h1 .GetYaxis().SetNdivisions(107)\n",
    "                h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "                canvas.Update()\n",
    "                canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "\n",
    "            gaussian_linear.append(tot_sig_2_point_5_sigma)\n",
    "            gaussian_linear.append(tot_sig_3_sigma)\n",
    "            gaussian_linear.append(tot_sig_3_point_5_sigma)\n",
    "\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigma_signal_under_peak\n",
    "sigma_integral\n",
    "#sigma_backgnd_under_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(h[0].min(), h[0].max(), 4, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pT_vs_rapidity(df, var_xaxis , var_yaxis , range_var_xaxis, range_var_yaxis):\n",
    "    import matplotlib as mpl\n",
    "    fig, axs = plt.subplots(figsize=(8, 6),dpi = 300)\n",
    "    h=plt.hist2d(df[var_xaxis],df[var_yaxis],range=[range_var_xaxis,range_var_yaxis], bins=np.arange(0,17)*0.2+0, norm=mpl.colors.LogNorm())\n",
    "    v1 = np.linspace(0, h[0].max(), 4, endpoint=True)\n",
    "    cbar = fig.colorbar(h[3], ticks = v1 )\n",
    "    #cbar.set_ticks([h[0].min(),(h[0].max()-h[0].min())/2,h[0].max()])\n",
    "    #cbar.set_ticklabels([h[0].min(),(h[0].max()-h[0].min())/2,h[0].max()])\n",
    "    \n",
    "    #v1 = np.linspace(Z.min(), Z.max(), 8, endpoint=True)\n",
    "    #cbar=plt.colorbar(ticks=v1)              # the mystery step ???????????\n",
    "    cbar.ax.set_yticklabels([ '0', '1784', '3568', '5353']) # add the labels\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.vlines(x=1.59,ymin=-1,ymax=2.4, color='r', linestyle='-')\n",
    "    #plt.hlines(y=bins4[1], xmin=bins0[3], xmax=3.162, colors='b', linestyles='solid', label='')\n",
    "    #plt.hlines(y=bins4[2], xmin=bins0[3], xmax=3.162, colors='b', linestyles='solid', label='')\n",
    "\n",
    "    #plt.hlines(y=0.4, xmin=-0.1, xmax=df[var_xaxis].max(), colors='b', linestyles='solid', label='')\n",
    "    #plt.hlines(y=0.2, xmin=-0.1, xmax=1.5996, colors='b', linestyles='solid', label='')\n",
    "    #plt.hlines(y=0.9, xmin=-0.1, xmax=3.5, colors='b', linestyles='solid', label='')\n",
    "    plt.xlabel('$y_{Lab}$', fontsize=20)\n",
    "    plt.ylabel('$p_{T}$ (GeV/$c$)', fontsize=18)\n",
    "    axs.text(0.02, 3, r'CBM Performance', fontsize=15)\n",
    "    axs.text(0.02, 2.8, r'DCM-QGSM-SMM, Au+Au @ 12 $A$GeV/$c$', fontsize=15, color ='r')\n",
    "    axs.text(1.2, 0.6, r'$y_{CM}$', fontsize=20, color ='r')\n",
    "    axs.tick_params(axis='both', which='major', labelsize=18)\n",
    "    axs.grid(b=True, animated=True )\n",
    "    axs.set_xticks(np.arange(0,17)*0.2+0)\n",
    "    axs.set_xticklabels(['0' ,'' ,'' ,'0.6','','', '1.2','','', '1.8','' ,'' ,'2.4','','' ,'3' , ''])\n",
    "    axs.set_yticks(np.arange(0,16)*0.2+0)\n",
    "    axs.set_yticklabels(['0' ,'' ,'' ,'0.6','','', '1.2','','', '1.8','' ,'' ,'2.4','','' ,'3' , ''])\n",
    "    #plt.title(\"  y-$p_{T}$ plot for signal candidates (MC=1) with a cut = %.2f\"%0.95,  fontsize=18)\n",
    "    #plt.grid(which='both', ydata =yy)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/pT_vs_rapidity.png\")\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1=[-0., 3.2]\n",
    "range2=[-0.01, 3.]\n",
    "\n",
    "h =pT_vs_rapidity(df4[df4['issignal']==1],'rapidity','pT', range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_rapidity_cut = df3_base[(df3_base['rapidity']<2) & (df3_base['rapidity']>0.8) &(df3_base['pT']>0.15)\n",
    "                           &(df3_base['pT']<0.9)]\n",
    "pT_vs_rapidity(pt_rapidity_cut,'rapidity','pT', range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pt_below_mid_rapidity_cut = df3_base[(df3_base['rapidity']<1.5996) & (df3_base['pT']>0.4)]\n",
    "pT_vs_rapidity(df3_base,'rapidity','pT', range1, range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del  h1, h2 ,h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyf_tf1_params(x, p):\n",
    "    return p[0] * x[0] + p[1]\n",
    "\n",
    "npars = 2\n",
    "f = ROOT.TF1(\"tf1_params\", pyf_tf1_params, 0.0, 1.0, npars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenztian( x ,p):\n",
    "    return 0.5*p[0]*p[1] /( ((x[0]-p[2])**2) + ((0.5 * p[1])**2)) \n",
    "\n",
    "def gaus_fit( x ,p):\n",
    "    return p[0]*np.exp(-0.5*((x[0]-p[2])/p[1])**2)\n",
    "\n",
    "\n",
    "f2 = ROOT.TF1 (\" gaussfit\", \"[0]*exp(-0.5*((x-[2])/[1])^2)\"  ,1.1 ,1.13)\n",
    "\n",
    "#def lorenztian( x ,p):\n",
    "#    return p[0]*2*np.sqrt(2)*p[1]*p[2]*np.sqrt(p[2]*(p[2]**2 + p[1]**2)) /(np.pi*np.sqrt(p[2]+np.sqrt(p[2]*(p[2]**2 + p[1]**2)))) /( ((x[0]**2) - (p[2]**2))**2 +(p[1]*p[2])**2 )\n",
    "mm= 1.105\n",
    "bins =100\n",
    "canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "canvas.Draw()\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "distribution = mid_pT_high_rapidity\n",
    "data = distribution['mass']\n",
    "#the minimum x (lower edge of the first bin)=mm        \n",
    "h1 = ROOT.TH1F(\"B_&_S\",\"\", bins,mm,1.13)\n",
    "for i in range(0,data.shape[0]):\n",
    "    h1.Fill(data.iloc[i])\n",
    "f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014)\",mm,1.13);\n",
    "#f1.SetParameters(1);\n",
    "h1.Fit(f1,\"RNI\");\n",
    "par1 = f1.GetParameters()\n",
    "\n",
    "\n",
    "#Step2\n",
    "canvas .Clear ()\n",
    "pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "pad1 . Draw ()\n",
    "pad1 . cd ()\n",
    "pad1. Clear()\n",
    "\n",
    "\n",
    "h1.SetTitleOffset(-1)\n",
    "h1.SetFillStyle(3003);\n",
    "h1.SetLineWidth(2)\n",
    "h1.SetStats (0)\n",
    "h1.SetYTitle(\"Entries\")\n",
    "h1.SetLineColor(ROOT.kBlack)\n",
    "h2 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.13);\n",
    "h3 = ROOT.TH1F(\"h2\", \"\", bins, mm, 1.13);\n",
    "h3.SetLineWidth(2)\n",
    "h3.SetStats (0)\n",
    "h3.GetXaxis().SetTitle(\"Mass (GeV/c^2)\")\n",
    "\n",
    "f2 = TF1(\"full\",lorenztian,mm,1.13,3);\n",
    "f2.SetNpx(100000);\n",
    "f2.SetParameters(par1[0],0.0001,1.115);\n",
    "f2.SetLineColor(ROOT.kRed)\n",
    "h1.Fit(f2,\"E\");\n",
    "par2 = f2.GetParameters()\n",
    "\n",
    "\n",
    "h1.Draw(\"pe\")\n",
    "\n",
    "f2.Draw(\"SAME\")\n",
    "\n",
    "bin1 = h1.FindBin(mm);\n",
    "bin2 = h1.FindBin(1.13);\n",
    "for i in range(bin1,bin2):\n",
    "    f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "    t_value = h1.GetBinContent(i)\n",
    "    h2.SetBinContent(i,f_value)\n",
    "    if (h1.GetBinError(i) > 0):\n",
    "        h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "h2.Sumw2()\n",
    "\n",
    "#To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "#(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "#To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "#To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "signal_under_peak = (fs.Integral(integral_min,integral_max)/binwidth);\n",
    "sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "if sigma_signal_under_peak!=0:\n",
    "    print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "#Background\n",
    "backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "#Significance = signal/(signal+background)^0.5\n",
    "#Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "#3.5 sigma\n",
    "signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "std =  f2.GetParameter(1)\n",
    "estd = f2.GetParError(1)\n",
    "\n",
    "latex = ROOT . TLatex ()\n",
    "latex . SetNDC ()\n",
    "latex . SetTextSize (0.02)\n",
    "#latex . DrawLatex (0.4 ,0.85, \"Significance in 2.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "#latex . DrawLatex (0.4 ,0.80, \"Significance in 3#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "#latex . DrawLatex (0.4 ,0.75, \"Significance in 3.5#sigma region around peak = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "latex . DrawLatex (0.2 ,0.75, \" #Gamma = %.4f #pm %.5f GeV\"%(std,estd ))\n",
    "latex . DrawLatex (0.2 ,0.70, \" m_{0} = %.4f #pm %.5f GeV\"%(par2 [2],f2.GetParError(2) ))\n",
    "#latex . DrawLatex (0.2 ,0.65,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "\n",
    "\n",
    "legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "legend . SetLineWidth (0)\n",
    "legend.Draw()\n",
    "\n",
    "canvas . cd ()\n",
    "pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "pad2 . Draw ()\n",
    "pad2 . cd ()\n",
    "pad2.Clear()\n",
    "\n",
    "\n",
    "h3.SetLineColor(TColor.GetColor(5))\n",
    "h3.SetYTitle(\"d-f/#Deltad\")\n",
    "h3.Draw()\n",
    "line = ROOT . TLine (mm,0 ,1.125 ,0)\n",
    "line . SetLineColor ( ROOT . kRed )\n",
    "line . SetLineWidth (2)\n",
    "line . Draw (\" same \")\n",
    "\n",
    "\n",
    "pad1 . SetBottomMargin (0)\n",
    "pad2 . SetTopMargin (0)\n",
    "pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "h1 . GetXaxis (). SetLabelSize (0)\n",
    "h1 . GetXaxis (). SetTitleSize (0)\n",
    "h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "h3 . SetTitle (\"\")\n",
    "h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "h1 . GetXaxis (). SetRangeUser (1. ,1.126)\n",
    "h3 . GetXaxis (). SetRangeUser (1.11 ,1.122)\n",
    "#ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "#207,512 divisions\n",
    "h3 . GetYaxis (). SetNdivisions (207)\n",
    "h1 . GetYaxis (). SetRangeUser (0.5 ,1000)\n",
    "h1 .GetYaxis().SetNdivisions(107)\n",
    "h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "canvas.Update()\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.png\")\n",
    "\n",
    "\n",
    "\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sgnal[sgnal['issignal']==1]\n",
    "lowest_rapidity = df[df['rapidity']<0.5]\n",
    "low_rapidity = df[(df['rapidity']>0.5)   & (df['rapidity']<1)]\n",
    "mid_rapidity = df[(df['rapidity']>1.5)   & (df['rapidity']<2)]\n",
    "high_rapidity = df[(df['rapidity']>2)    & (df['rapidity']<2.5)]\n",
    "higher_rapidity = df[(df['rapidity']>2.5)]\n",
    "\n",
    "    \n",
    "\n",
    "low_pT_lowest_rapidity = lowest_rapidity[lowest_rapidity['pT']<1]\n",
    "mid_pT_lowest_rapidity = lowest_rapidity[(lowest_rapidity['pT']>1) & (lowest_rapidity['pT']<2)]\n",
    "high_pT_lowest_rapidity =lowest_rapidity[(lowest_rapidity['pT']>2)]\n",
    "\n",
    "\n",
    "low_pT_low_rapidity = low_rapidity[low_rapidity['pT']<1]\n",
    "mid_pT_low_rapidity = low_rapidity[(low_rapidity['pT']>1) & (low_rapidity['pT']<2)]\n",
    "high_pT_low_rapidity= low_rapidity[(low_rapidity['pT']>2)]\n",
    "    \n",
    "\n",
    "low_pT_mid_rapidity = mid_rapidity[mid_rapidity['pT']<1]\n",
    "mid_pT_mid_rapidity = mid_rapidity[(mid_rapidity['pT']>1) & (mid_rapidity['pT']<2)]\n",
    "high_pT_mid_rapidity=mid_rapidity[(mid_rapidity['pT']>2)]\n",
    "    \n",
    "\n",
    "low_pT_high_rapidity = high_rapidity[high_rapidity['pT']<1]\n",
    "mid_pT_high_rapidity = high_rapidity[(high_rapidity['pT']>1) & (high_rapidity['pT']<2)]\n",
    "high_pT_high_rapidity=high_rapidity[(high_rapidity['pT']>2)]\n",
    "\n",
    "low_pT_higher_rapidity = higher_rapidity[higher_rapidity['pT']<1]\n",
    "mid_pT_higher_rapidity = higher_rapidity[(higher_rapidity['pT']>1) & (higher_rapidity['pT']<2)]\n",
    "high_pT_higher_rapidity=higher_rapidity[(higher_rapidity['pT']>2)]\n",
    "\n",
    "\n",
    "del  lowest_rapidity, mid_rapidity, high_rapidity, higher_rapidity, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [low_pT_lowest_rapidity, mid_pT_lowest_rapidity, high_pT_lowest_rapidity, low_pT_low_rapidity,\n",
    "         mid_pT_low_rapidity, high_pT_low_rapidity, low_pT_mid_rapidity, mid_pT_mid_rapidity,\n",
    "        high_pT_mid_rapidity, low_pT_high_rapidity, mid_pT_high_rapidity, high_pT_high_rapidity, \n",
    "         low_pT_higher_rapidity, mid_pT_higher_rapidity, high_pT_higher_rapidity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal[signal['issignal']==1]['rapidity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['mass'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import TFile, TTree\n",
    "from array import array\n",
    "from ROOT import std\n",
    "\n",
    "f = TFile('pt_y_yield_bdt_cut_0.95.root','recreate')\n",
    "t = TTree('t1','tree with df')\n",
    "\n",
    "\n",
    "rapidity = array('f',[0])\n",
    "mass = array('f',[0])\n",
    "pT = array('f',[0])\n",
    "issignal = array('f',[0])\n",
    "\n",
    "t.Branch('rapidity', rapidity,'y/F')\n",
    "t.Branch('mass', mass,'mass/F')\n",
    "t.Branch('pT', pT,'pT/F')\n",
    "t.Branch('issignal', issignal,'pT/F')\n",
    "\n",
    "for i in range(len(df4['mass'])):\n",
    "    rapidity[0] = df4['rapidity'].iloc[i]\n",
    "    mass[0] = df4['mass'].iloc[i]\n",
    "    pT[0] = df4['pT'].iloc[i]\n",
    "    issignal[0] = df4['issignal'].iloc[i]\n",
    "    t.Fill()\n",
    "f.Write()\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[(df4['rapidity']>1.4)& (df4['pT']>1.4)]['pT'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency \n",
    "Efficieny correction on just one configuration i.e lorenztian + 2nd order pol, 100 mass binings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hist(h1, f2, fs, fb, h3):\n",
    "    c = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "    c . Draw() \n",
    "    c.Clear ()\n",
    "    \n",
    "    pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "    pad1 . Draw ()\n",
    "    pad1 . cd ()\n",
    "    pad1 . Clear()\n",
    "    pad1 . SetBottomMargin (0)\n",
    "    \n",
    "    h1 . SetTitleOffset(-1)\n",
    "    h1 . SetFillStyle(3003);\n",
    "    h1 . SetLineWidth(2)\n",
    "    h1 . SetStats (0)\n",
    "    h1 . SetYTitle(\"Entries\")\n",
    "    h1 . SetLineColor(ROOT.kBlack)\n",
    "    h1 . GetXaxis (). SetLabelSize (0)\n",
    "    h1 . GetXaxis (). SetTitleSize (0)\n",
    "    h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "    h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "    h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "    h1 . GetYaxis().SetNdivisions(107)\n",
    "    \n",
    "    \n",
    "    fs.SetNpx(100000);\n",
    "    fs.SetLineColor(ROOT.kGreen)\n",
    "    \n",
    "    fb.SetLineStyle(4)\n",
    "    fb.SetLineColor(ROOT.kBlue)\n",
    "    fb.SetNpx(100000);\n",
    "    \n",
    "    f2.SetNpx(100000);\n",
    "    f2.SetLineColor(ROOT.kRed)\n",
    "    \n",
    "    \n",
    "    h1.Draw(\"pe\")\n",
    "    fs.Draw(\"SAME\")\n",
    "    fb.Draw(\"SAME\")\n",
    "    f2.Draw(\"SAME\")\n",
    "    \n",
    "    latex = ROOT . TLatex ()\n",
    "    latex . SetNDC ()\n",
    "    latex . SetTextSize (0.02)\n",
    "    latex . DrawLatex (0.4 ,0.85, \"Significance in m_{0} #pm 2.5#Gamma  = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "    latex . DrawLatex (0.4 ,0.80, \"Significance in m_{0} #pm 3#Gamma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "    latex . DrawLatex (0.4 ,0.75, \"Significance in m_{0} #pm 3.5#Gamma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "    latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(par2 [1],f2.GetParError(1) ))\n",
    "    latex . DrawLatex (0.4 ,0.65, \" m_{0} = %.4f #pm %.5f GeV\"%(par2 [2],f2.GetParError(2) ))\n",
    "    latex . DrawLatex (0.4 ,0.6,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "    latex . DrawLatex (0.4 ,0.55,\" True signal (MC=1) = %.f\"%(mc_counts))\n",
    "\n",
    "\n",
    "    legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "    legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "    legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx+Dx^{2}\",\"l\");\n",
    "    legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "    legend.AddEntry(fb,\"B+Cx+Dx^{2}\",\"l\");\n",
    "    legend . SetLineWidth (0)\n",
    "    legend.Draw()\n",
    "    \n",
    "    c . cd ()\n",
    "    pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "    pad2 . Draw ()\n",
    "    pad2 . cd ()\n",
    "    pad2.Clear()\n",
    "    pad2.SetGrid()\n",
    "    pad2 . SetTopMargin (0)\n",
    "    pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "    \n",
    "    h3.SetLineWidth(2)\n",
    "    h3.SetStats (0)\n",
    "    h3.GetXaxis().SetTitle(\"Mass [GeV/c{^2}]\")\n",
    "    h3 . SetTitle (\"\")\n",
    "    h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "    h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "    h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "    h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "    #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "    h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "    #207,512 divisions\n",
    "    h3 . GetYaxis (). SetNdivisions (207)\n",
    "    h3 . GetXaxis (). SetNdivisions (207)\n",
    "    h3.SetLineColor(TColor.GetColor(5))\n",
    "    h3.SetYTitle(\"d-f/#Deltad\")\n",
    "    \n",
    "    h3.Draw()\n",
    "    \n",
    "    \n",
    "    line = ROOT . TLine (mm,0 ,1.23 ,0)\n",
    "    line . SetLineColor ( ROOT . kRed )\n",
    "    line . SetLineWidth (2)\n",
    "    line . Draw (\" same \")\n",
    "    c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf [\")\n",
    "    \n",
    "    #c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lorentzian + second order pol\n",
    "#lorentzian + second order pol\n",
    "#lorentzian + second order pol\n",
    "a = []\n",
    "pt_y_bin_for_yield_min=[]\n",
    "pt_y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_min=[]\n",
    "true_mc_in_recons =[]\n",
    "\n",
    "\n",
    "df = df3_base\n",
    "mass_range_min = [1.08]\n",
    "fit_limit_low=[0,0.1* (df['mass'].describe()[2]),   0.2* (df['mass'].describe()[2]),\n",
    "               1.23,\n",
    "               df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.1* (df['mass'].describe()[2]),\n",
    "                df['mass'].describe()[1]+1.2*(df['mass'].describe()[2])+0.2* (df['mass'].describe()[2])]\n",
    "\n",
    "\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,1,1):\n",
    "\n",
    "        binning = [100]\n",
    "        for b in binning:\n",
    "\n",
    "            y_bin_low=-0.2\n",
    "            y_bin_up =0\n",
    "            for i in range(0,15,1):\n",
    "                tot_sig_3_sigma = 0\n",
    "                tot_bac_3_sigma = 0\n",
    "                tot_sig_3_point_5_sigma = 0\n",
    "                tot_bac_3_point_5_sigma = 0\n",
    "                tot_sig_2_point_5_sigma = 0\n",
    "                tot_bac_2_point_5_sigma = 0\n",
    "                tot_sig_2_sigma = 0\n",
    "                \n",
    "                y_bin_low = truncate(y_bin_low+0.2)\n",
    "                y_bin_up = truncate(y_bin_up+0.2)\n",
    "                df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "                pt_bin_low =-0.2\n",
    "                pt_bin_up =0\n",
    "                \n",
    "                for i in range(0,15,1):\n",
    "                    pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                    #print(pt_bin_low)\n",
    "                    pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                    df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                    mc_counts = df_pt[df_pt['issignal']>0].shape[0]\n",
    "                    #print(y_bin_low, y_bin_up, \" pT \", pt_bin_low,pt_bin_up)\n",
    "                    if df_pt.shape[0]>500:\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fb =TF1(\"fb\",\"[0]+[1]*x+[2]*x*x+[3]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #fb.SetParameters(0,0,0);\n",
    "                        #fb.SetParameters(0,0,0,0);\n",
    "                        h0.Fit(fb,\"RIEM\");\n",
    "                        par = fb.GetParameters()\n",
    "                        #Step 1\n",
    "                        data = df_pt['mass']\n",
    "                        \n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #f1=TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x+[4]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        f1.SetParameters(1,par[0], par[1], par[2]);\n",
    "                        #f1.SetParameters(1,par[0], par[1], par[2],par[3]);\n",
    "                        h1.Fit(f1,\"RNI\");\n",
    "                        par1 = f1.GetParameters()\n",
    "\n",
    "\n",
    "\n",
    "                #step 2\n",
    "                        f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x+[6]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3], par1[4]);\n",
    "                        f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3]);\n",
    "\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNIR\"))\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                        fb.SetParameters(par2[3],par2[4],par2[5], par2[6]);\n",
    "\n",
    "\n",
    "\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "\n",
    "\n",
    "                        bin1 = h1.FindBin(fit_limit_low[mmm]+mm);\n",
    "                        bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "\n",
    "                        h2.Sumw2()\n",
    "\n",
    "                                #To integrate over the gaussian peak we take the integral limits 3 sigmas (i.e. parameter 3) below the mean value\n",
    "                    #(i.e. par 1) of the gaussian as a minimum limit and 3 sigmas above the mean as a max limit of the integral*/\n",
    "                        integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                        integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "                    #To integrate area under the signal plus background curve we take 3 sigma and integrate\n",
    "                        binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                        tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                        sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "                    #To find the signal, we integrate just the gaussian peak with 3 sigma \n",
    "                        #params.integral = fit->GetParameter(0) * sqrt(2*3.1415) * fit->GetParameter(2) / h->GetBinWidth(1);\n",
    "                        #signal_under_peak = par2[1] * np.sqrt(2*3.1415) *3 *par2[2]/ binwidth\n",
    "                        signal_under_peak = fs.Integral(integral_min,integral_max)/binwidth\n",
    "                        if signal_under_peak<0:\n",
    "                            signal_under_peak = 0\n",
    "                            print('Negative signal')                \n",
    "                        sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                        man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                        if sigma_signal_under_peak!=0:\n",
    "                            print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                        tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "                    #Background\n",
    "                        backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                        if backgnd_under_peak<0:\n",
    "                            print('Negative background')\n",
    "                        sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                        tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "                    #Significance = signal/(signal+background)^0.5\n",
    "                        Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "\n",
    "                        #3.5 sigma\n",
    "                        signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                        tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                        tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_sigma = (fs.Integral(par2[2] - (TMath.Abs(2*par2[1])),par2[2] + (TMath.Abs(2*par2[1])))/binwidth);\n",
    "                        \n",
    "                        draw_hist(h1, f2, fs, fb, h3)\n",
    "                        \n",
    "\n",
    "                        \n",
    "            #a.append(tot_sig_2_point_5_sigma)\n",
    "                        a.append(signal_under_peak_2_point_5_sigma)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "                    else:\n",
    "                        a.append(0)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "            #a.append(tot_sig_3_point_5_sigma)\n",
    "#c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_clean_mc = true_mc_in_recons\n",
    "#len(dcm_clean_mc)\n",
    "#sum(true_mc_in_recons)\n",
    "len(dcm_clean_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot off\n",
    "#lorentzian + second order pol\n",
    "a = []\n",
    "pt_y_bin_for_yield_min=[]\n",
    "pt_y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_max=[]\n",
    "y_bin_for_yield_min=[]\n",
    "true_mc_in_recons =[]\n",
    "\n",
    "\n",
    "\n",
    "df = df4\n",
    "\n",
    "for mm in mass_range_min:\n",
    "    for mmm in range(0,1,1):\n",
    "        canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "        canvas.Draw()\n",
    "\n",
    "        binning = [100]\n",
    "        for b in binning:\n",
    "\n",
    "            y_bin_low=1\n",
    "            y_bin_up =1.2\n",
    "            for i in range(0,1,1):\n",
    "                \n",
    "                y_bin_low = truncate(y_bin_low+0.2)\n",
    "                y_bin_up = truncate(y_bin_up+0.2)\n",
    "                df_y = df[(df['rapidity']>y_bin_low) & (df['rapidity']<y_bin_up)]\n",
    "                pt_bin_low =-0.2\n",
    "                pt_bin_up =0.\n",
    "                for i in range(0,1,1):\n",
    "                    pt_bin_low = truncate(pt_bin_low+0.2)\n",
    "                    #print(pt_bin_low)\n",
    "                    pt_bin_up = truncate(pt_bin_up+0.2)\n",
    "                    df_pt = df_y[(df_y['pT']>pt_bin_low) & (df_y['pT']<pt_bin_up)]\n",
    "                    mc_counts = df_pt[df_pt['issignal']==1].shape[0]\n",
    "                    #step 0\n",
    "                    if df_pt.shape[0]>400:\n",
    "                        data0 = background_selector(df_pt)\n",
    "                        h0 = ROOT.TH1F(\"Background\",\"Background without peak\",b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data0.shape[0]):\n",
    "                            h0.Fill(data0.iloc[i])\n",
    "                        fb = TF1(\"fb\",\"[0]+[1]*x+[2]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fb =TF1(\"fb\",\"[0]+[1]*x+[2]*x*x+[3]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #fb.SetParameters(0,0,0);\n",
    "                        #fb.SetParameters(0,0,0,0);\n",
    "                        h0.Fit(fb,\"RIEM\");\n",
    "                        par = fb.GetParameters()\n",
    "                        #Step 1\n",
    "                        data = df_pt['mass']\n",
    "                        \n",
    "                #the minimum x (lower edge of the first bin)=mm        \n",
    "                        h1 = ROOT.TH1F(\"B_&_S\",\"rapidity=[%.2f,%.2f] & p_{T}=[%.2f,%.2f] & Min Mass= %.3f & bins=%.0f\"%(df_pt['rapidity'].min(),df_pt['rapidity'].max(),df_pt['pT'].min(),df_pt['pT'].max(), mm, b),b,mm,fit_limit_low[5])\n",
    "                        for i in range(0,data.shape[0]):\n",
    "                            h1.Fill(data.iloc[i])\n",
    "                        f1 = TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #f1=TF1(\"step1\",\"((0.5)*[0]*0.0014) /((x-1.115683)*(x-1.115683)+ .25*0.0014*0.0014) +[1]+[2]*x+[3]*x*x+[4]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        f1.SetParameters(1,par[0], par[1], par[2]);\n",
    "                        #f1.SetParameters(1,par[0], par[1], par[2],par[3]);\n",
    "                        h1.Fit(f1,\"RNI\");\n",
    "                        par1 = f1.GetParameters()\n",
    "\n",
    "                        canvas .Clear ()\n",
    "                        pad1 = ROOT . TPad (\" pad1 \",\" pad1 \" ,0 ,0.3 ,1 ,1)\n",
    "                        pad1 . Draw ()\n",
    "                        pad1 . cd ()\n",
    "                        pad1. Clear()\n",
    "\n",
    "                #step 2\n",
    "                        f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2 = TF1(\"full\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1]) +[3]+[4]*x+[5]*x*x+[6]*x*x*x\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3])\n",
    "                        #f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3], par1[4]);\n",
    "                        f2.SetNpx(100000);\n",
    "                        f2.SetParameters(par1[0],0.001,1.115,par1[1], par1[2], par1[3]);\n",
    "                        f2.SetLineColor(ROOT.kRed)\n",
    "                        r= ROOT.TFitResultPtr(h1.Fit(f2,\"MNIR\"))\n",
    "                        par2 = f2.GetParameters()\n",
    "\n",
    "                        fs = TF1(\"fs\",\"((0.5)*[0]*[1]) /((x-[2])*(x-[2])+ .25*[1]*[1])\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        #fs = TF1(\"fs\",\"[0]*exp(-0.5*((x-[2])/[1])^2)\",fit_limit_low[mmm]+mm,fit_limit_low[mmm+3]);\n",
    "                        fs.SetNpx(100000);\n",
    "                        fs.SetLineColor(ROOT.kGreen)\n",
    "                        fb.SetLineStyle(4)\n",
    "                        fb.SetLineColor(ROOT.kBlue)\n",
    "                        fb.SetNpx(100000);\n",
    "                        fs.SetParameters(par2[0],par2[1],par2[2]);\n",
    "                        fb.SetParameters(par2[3],par2[4],par2[5], par2[6]);\n",
    "\n",
    "\n",
    "                        h1.SetTitleOffset(0)\n",
    "                        h1.SetFillStyle(3003);\n",
    "                        h1.SetLineWidth(2)\n",
    "                        h1.SetStats (0)\n",
    "                        h1.SetYTitle(\"Entries\")\n",
    "                        h1.SetLineColor(ROOT.kBlack)\n",
    "                        h1.GetYaxis().SetTitle(\"Counts\")\n",
    "                        h2 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h4 =  ROOT.TH1F(\"h2\", \"\", b, mm, 1.23)\n",
    "                        h5 = ROOT.TH1F(\"h2\", \"\", b, mm, 1.23);\n",
    "                        h3.SetLineWidth(2)\n",
    "                        h3.SetStats (0)\n",
    "                        h3.GetXaxis().SetTitle(\"Mass (GeV/#it{c}^{2}]\")\n",
    "\n",
    "                        h1.Draw(\"pe\")\n",
    "                        h_mc.SetLineColor(ROOT.kMagenta)\n",
    "                        h_mc.SetLineWidth(2)\n",
    "                        #h_mc.Draw(\"SAMEpe\")\n",
    "                        fs.Draw(\"SAME\")\n",
    "                        fb.Draw(\"SAME\")\n",
    "                        f2.Draw(\"SAME\")\n",
    "                        bin1 = h1.FindBin(fit_limit_low[mmm]+mm);\n",
    "                        bin2 = h1.FindBin(fit_limit_low[mmm+3]);\n",
    "                        for i in range(bin1,bin2):\n",
    "                            f_value= f2.Eval(h1.GetBinCenter(i));\n",
    "                            fs_values = fs.Eval(h3.GetBinCenter(i))\n",
    "                            t_value = h1.GetBinContent(i)\n",
    "                            t_value_mc = h_mc.GetBinContent(i)\n",
    "                            h2.SetBinContent(i,f_value)\n",
    "                            h4.SetBinContent(i,fs_values)\n",
    "                            if (h1.GetBinError(i) > 0):\n",
    "                                h3.SetBinContent(i,(t_value-f_value)/h1.GetBinError(i))\n",
    "                            if (h_mc.GetBinError(i) > 0):\n",
    "                                h5.SetBinContent(i,(t_value_mc-fs_values)/h_mc.GetBinError(i))\n",
    "\n",
    "\n",
    "                        h2.Sumw2()\n",
    "                        #h4.Sumw2()\n",
    "                        h5.SetLineColor(ROOT.kBlue)\n",
    "                        h5.SetLineWidth(2)\n",
    "\n",
    "                        integral_min = par2[2] - (TMath.Abs(3*par2[1]));\n",
    "                        integral_max = par2[2] + (TMath.Abs(3*par2[1]));\n",
    "\n",
    "                        binwidth = h1.GetXaxis().GetBinWidth(1);\n",
    "                        tot = f2.Integral(integral_min,integral_max)/binwidth;\n",
    "                        sigma_integral = f2.IntegralError(integral_min,integral_max);\n",
    "                        #signal_under_peak = par2[0] * np.sqrt(2*3.1415*par2[1]*par2[1])/binwidth\n",
    "                        signal_under_peak = fs.Integral(integral_min,integral_max)/binwidth\n",
    "                        if signal_under_peak<0:\n",
    "                            signal_under_peak = 0\n",
    "                            print('Negative signal')                \n",
    "                        sigma_signal_under_peak = fs.IntegralError(integral_min,integral_max);\n",
    "                        man_sigma_signal_under_peak = TMath.Sqrt(signal_under_peak)\n",
    "                        if sigma_signal_under_peak!=0:\n",
    "                            print(\"Integral errors \",sigma_signal_under_peak)\n",
    "\n",
    "                        tot_sig_3_sigma= tot_sig_3_sigma+signal_under_peak\n",
    "                    #Background\n",
    "                        backgnd_under_peak = (fb.Integral(integral_min,integral_max)/binwidth)\n",
    "                        if backgnd_under_peak<0:\n",
    "                            print('Negative background')\n",
    "                        sigma_backgnd_under_peak = fb.IntegralError(integral_min,integral_max);\n",
    "                        tot_bac_3_sigma = tot_bac_3_sigma+backgnd_under_peak\n",
    "                    #Significance = signal/(signal+background)^0.5\n",
    "                        Significance = signal_under_peak/TMath.Sqrt(tot);\n",
    "                        #print(\"total - background = \",tot-backgnd_under_peak)\n",
    "                        #3.5 sigma\n",
    "                        signal_under_peak_3_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_3_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])))/binwidth);\n",
    "                        tot_sig_3_point_5_sigma = tot_sig_3_point_5_sigma+signal_under_peak_3_point_5_sigma\n",
    "                        tot_bac_3_point_5_sigma = tot_bac_3_point_5_sigma + bac_under_peak_3_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_3_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(3.5*par2[1])),par2[2] + (TMath.Abs(3.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_3_point_5_sigma = TMath.Sqrt(signal_under_peak_3_point_5_sigma)\n",
    "\n",
    "                        signal_under_peak_2_point_5_sigma = (fs.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        bac_under_peak_2_point_5_sigma = (fb.Integral(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])))/binwidth);\n",
    "                        tot_sig_2_point_5_sigma = tot_sig_2_point_5_sigma+signal_under_peak_2_point_5_sigma\n",
    "                        tot_bac_2_point_5_sigma = tot_bac_2_point_5_sigma + bac_under_peak_2_point_5_sigma\n",
    "\n",
    "                        sigma_signal_under_peak_2_point_5_sigma = fs.IntegralError(par2[2] - (TMath.Abs(2.5*par2[1])),par2[2] + (TMath.Abs(2.5*par2[1])));\n",
    "                        man_sigma_signal_under_peak_2_point_5_sigma = TMath.Sqrt(signal_under_peak_2_point_5_sigma)\n",
    "\n",
    "\n",
    "                        std = par2 [1]\n",
    "                        estd = f2.GetParError(1)\n",
    "                        \n",
    "                        latex = ROOT . TLatex ()\n",
    "                        latex . SetNDC ()\n",
    "                        latex . SetTextSize (0.02)\n",
    "                        latex . DrawLatex (0.4 ,0.85, \"Significance in m_{0} #pm 2.5#Gamma  = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_2_point_5_sigma, man_sigma_signal_under_peak_2_point_5_sigma, signal_under_peak_2_point_5_sigma,bac_under_peak_2_point_5_sigma,signal_under_peak_2_point_5_sigma/TMath.Sqrt(bac_under_peak_2_point_5_sigma+signal_under_peak_2_point_5_sigma) ))\n",
    "                        latex . DrawLatex (0.4 ,0.80, \"Significance in m_{0} #pm 3#Gamma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak,man_sigma_signal_under_peak, signal_under_peak,backgnd_under_peak,Significance ))\n",
    "                        latex . DrawLatex (0.4 ,0.75, \"Significance in m_{0} #pm 3.5#Gamma = #frac{%.1f #pm %.1f}{#sqrt{%.1f+%.1f}} = %.1f\"%(signal_under_peak_3_point_5_sigma,man_sigma_signal_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma,bac_under_peak_3_point_5_sigma,signal_under_peak_3_point_5_sigma/TMath.Sqrt(signal_under_peak_3_point_5_sigma+bac_under_peak_3_point_5_sigma) ))\n",
    "                        latex . DrawLatex (0.4 ,0.70, \" #Gamma = %.4f #pm %.5f GeV\"%(par2 [1],f2.GetParError(1) ))\n",
    "                        latex . DrawLatex (0.4 ,0.65, \" m_{0} = %.4f #pm %.5f GeV\"%(par2 [2],f2.GetParError(2) ))\n",
    "                        latex . DrawLatex (0.4 ,0.6,\" #frac{#chi^{2}}{ndf} = %.1f/%d = %.4f\"%(f2.GetChisquare() , f2.GetNDF() , f2.GetChisquare() / f2.GetNDF() ))\n",
    "                        latex . DrawLatex (0.4 ,0.55,\" True signal (MC=1) = %.f\"%(mc_counts))\n",
    "                        \n",
    "                        latex1 = ROOT . TLatex ()\n",
    "                        latex1 . SetNDC ()\n",
    "                        latex1 . SetTextSize (0.035)\n",
    "                        latex1. DrawLatex (0.4 ,0.25, \"CBM performance\")\n",
    "                        latex1. DrawLatex (0.4 ,0.15, \"URQMD, Au+Au @ 12#it{A} GeV/#it{c}\")\n",
    "                        latex1.Draw()\n",
    "\n",
    "                        \n",
    "                        legend = ROOT.TLegend(0.87,0.3,0.6,0.6);\n",
    "                        legend.AddEntry(h1,\"Invariant mass of lambda\",\"l\");\n",
    "                        legend.AddEntry(f2,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}+B+Cx+Dx^{2}\",\"l\");\n",
    "                        legend.AddEntry(fs,\"A #frac{0.5 #Gamma}{(m-m_{0})^{2} + 0.25#Gamma^{2}}\",\"l\");\n",
    "                        legend.AddEntry(fb,\"B+Cx+Dx^{2}\",\"l\");\n",
    "                        legend . SetLineWidth (0)\n",
    "                        legend.Draw()\n",
    "\n",
    "                        canvas . cd ()\n",
    "                        pad2 = ROOT . TPad (\" pad2 \",\" pad2 \" ,0 ,0.05 ,1 ,0.3)\n",
    "                        pad2 . Draw ()\n",
    "                        pad2 . cd ()\n",
    "                        pad2.Clear()\n",
    "\n",
    "\n",
    "                        h3.SetLineColor(TColor.GetColor(5))\n",
    "                        h3.SetYTitle(\"d-f/#Deltad\")\n",
    "                        #h5.Draw()\n",
    "                        h3.Draw(\"SAME\")\n",
    "                        line = ROOT . TLine (mm,0 ,1.2 ,0)\n",
    "                        line . SetLineColor ( ROOT . kRed )\n",
    "                        line . SetLineWidth (2)\n",
    "                        line . Draw (\" same \")\n",
    "\n",
    "\n",
    "                        pad1 . SetBottomMargin (0)\n",
    "                        pad2 . SetTopMargin (0)\n",
    "                        pad2 . SetBottomMargin (0.25)\n",
    "\n",
    "                        h1 . GetXaxis (). SetLabelSize (0)\n",
    "                        #h1.SetTitle(\"\")\n",
    "                        h1 . GetXaxis (). SetTitleSize (0)\n",
    "                        h1 . GetYaxis (). SetTitleSize (0.05)\n",
    "                        h1 . GetYaxis (). SetLabelSize (0.03)\n",
    "                        h1 . GetYaxis (). SetTitleOffset (0.6)\n",
    "\n",
    "                        h3 . SetTitle (\"\")\n",
    "                        h3 . GetXaxis (). SetLabelSize (0.12)\n",
    "                        h3 . GetXaxis (). SetTitleSize (0.12)\n",
    "                        h3 . GetYaxis (). SetLabelSize (0.1)\n",
    "                        h3 . GetYaxis (). SetTitleSize (0.15)\n",
    "                    #ratio . GetYaxis (). SetTitle (\" Data /MC\")\n",
    "                        h3 . GetYaxis (). SetTitleOffset (0.17)\n",
    "                    #207,512 divisions\n",
    "                        h3 . GetYaxis (). SetNdivisions (207)\n",
    "                        #h_mc.GetYaxis (). SetRangeUser (0.5 ,700)\n",
    "                        h1 . GetYaxis (). SetRangeUser (0.5 ,400)\n",
    "                        h3 . GetXaxis (). SetRangeUser (1.08 ,1.2)\n",
    "                        h1 . GetXaxis (). SetRangeUser (1.08 ,1.2)\n",
    "                        h1 .GetYaxis().SetNdivisions(107)\n",
    "                        h3 . GetXaxis (). SetNdivisions (207)\n",
    "\n",
    "                        canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/c.png\")\n",
    "\n",
    "            #a.append(tot_sig_2_point_5_sigma)\n",
    "                        a.append(signal_under_peak)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low+0.2))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up+0.2))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "                    else:\n",
    "                        a.append(0)\n",
    "                        y_bin_for_yield_min.append(truncate(y_bin_low+0.2))\n",
    "                        y_bin_for_yield_max.append(truncate(y_bin_up+0.2))\n",
    "                        pt_y_bin_for_yield_min.append(pt_bin_low)\n",
    "                        pt_y_bin_for_yield_max.append(pt_bin_up)\n",
    "                        true_mc_in_recons.append(mc_counts)\n",
    "            #a.append(tot_sig_3_point_5_sigma)\n",
    "#canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.pdf ]\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n",
    "#mc_counts\n",
    "#sum(a)\n",
    "#sum(true_mc_in_recons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt[df_pt['issignal']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "file =uproot.open(\"lambda_qa_dcm.root\")\n",
    "array1 = file[\"SimParticles_McLambda/SimParticles_rapidity_SimParticles_pT_McLambda\"].to_numpy()\n",
    "#for i in range(0,14,1):\n",
    "array1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 15*15\n",
    "pt_y_yields = pd.DataFrame(data=np.arange(0,size,1),columns = ['numbering'])\n",
    "pt_y_yields['rapidity_min_MC'] = np.zeros(size)\n",
    "pt_y_yields['pT_min_MC'] = np.zeros(size)\n",
    "\n",
    "pt_y_yields['ratio_recons_sim']=np.zeros(size)\n",
    "pt_y_yields['ratio_recons_mc']=np.zeros(size)\n",
    "pt_y_yields['pT_min'] = np.zeros(size)\n",
    "pt_y_yields ['pt_y_yields_MC']=np.zeros(size)\n",
    "pt_y_yields['pt_y_yields_recons']=a\n",
    "pt_y_yields['true_mc_in_recons'] = true_mc_in_recons\n",
    "pt_y_yields['total_mc_in_recons'] = dcm_clean_mc\n",
    "\n",
    "for i in range(0,15):\n",
    "    for j in range(0,15):\n",
    "        pt_y_yields['rapidity_min_MC'].iloc[i+j*15]=0+j*0.2\n",
    "    \n",
    "\n",
    "for i in range(0,15):    \n",
    "    pt_y_yields['pT_min_MC'].iloc[i]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+1*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+2*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+3*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+4*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+5*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+6*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+7*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+8*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+9*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+10*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+11*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+12*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+13*15]=i/5\n",
    "    pt_y_yields['pT_min_MC'].iloc[i+14*15]=i/5\n",
    "    \n",
    "\n",
    "\n",
    "for i in range(0,15,1):\n",
    "    pt_y_yields ['pt_y_yields_MC'].iloc[i]=array1[0][0][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+1*15]=array1[0][1][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+2*15]=array1[0][2][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+3*15]=array1[0][3][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+4*15]=array1[0][4][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+5*15]=array1[0][5][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+6*15]=array1[0][6][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+7*15]=array1[0][7][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+8*15]=array1[0][8][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+9*15]=array1[0][9][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+10*15]=array1[0][10][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+11*15]=array1[0][11][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+12*15]=array1[0][12][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+13*15]=array1[0][13][i]\n",
    "    pt_y_yields['pt_y_yields_MC'].iloc[i+14*15]=array1[0][14][i]\n",
    "\n",
    "for i in range(0,15*15,1):\n",
    "    pt_y_yields['ratio_recons_mc'].iloc[i]=a[i]/pt_y_yields['true_mc_in_recons'].iloc[i]\n",
    "    pt_y_yields['ratio_recons_sim'].iloc[i]=a[i]/pt_y_yields['pt_y_yields_MC'].iloc[i]\n",
    "    pt_y_yields['pT_min'].iloc[i] = pt_y_bin_for_yield_min[i]\n",
    "    #print(\"%.2f\"%pt_y_yields['rapidity_min_MC'].iloc[i],\"       \",pt_y_yields['pT_min_MC'].iloc[i],\"    \", pt_y_yields['ratio'].iloc[i] )\n",
    "#plt.plot(pt_y_yields['numbering'], pt_y_yields['ratio_recons_sim'], label='Reconstructed/Sim')\n",
    "plt.plot(pt_y_yields['numbering'], pt_y_yields['ratio_recons_mc'], label='Rencostructed/MC')\n",
    "plt.legend()\n",
    "plt.ylim([0.9,1.1])\n",
    "plt.savefig(\"hists\")\n",
    "#pt_y_yields[(pt_y_yields['rapidity_min_MC']>1) & (pt_y_yields['rapidity_min_MC']<1.4) &(pt_y_yields['pT_min_MC']<1)&(pt_y_yields['pT_min_MC']>0)]\n",
    "pt_y_yields[(pt_y_yields['numbering']>100) & (pt_y_yields['numbering']<120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h4 = ROOT.TH2F(\"recons\", \"recons\", 15,0,3,15,0,3);\n",
    "h5 = ROOT.TH2F(\"Mc\", \"Mc\", 15,0,3,15,0,3);\n",
    "h6 = ROOT.TH2F(\"Mc in reconstructed\", \"Mc in reconstructed\", 15,0,3,15,0,3);\n",
    "h7 = ROOT.TH2F(\"DCM Efficiency\", \"DCM Efficiency\", 15,0,3,15,0,3);\n",
    "h8 = ROOT.TH2F(\"total mc in reconstructed\", \"total mc in reconstructed\", 15,0,3,15,0,3);\n",
    "\n",
    "\n",
    "h4.SetStats(0)\n",
    "h5.SetStats(0)\n",
    "h6.SetStats(0)\n",
    "\n",
    "c = ROOT . TCanvas (\" canvas \",\"\", 950,800)\n",
    "c.Draw()\n",
    "bin1 = h4.FindBin(0);\n",
    "bin2 = h4.FindBin(3);\n",
    "for i in range(1,225):\n",
    "    #recons.SetBinContent( (pt_y_yields1['rapidity_min'].iloc[i]), (pt_y_yields1['pT_min'].iloc[i]) ,pt_y_yields1['pt_y_yields'].iloc[i])\n",
    "    y= (pt_y_yields['rapidity_min_MC'].iloc[i])\n",
    "    pT=(pt_y_yields['pT_min_MC'].iloc[i])\n",
    "    y_bin = int((y+0.1)/0.2 + 1);\n",
    "    pT_bin = int((pT+0.1)/0.2 + 1);\n",
    "    h4.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_recons'].iloc[i]);\n",
    "    h5.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_MC'].iloc[i]);\n",
    "    h6.SetBinContent(y_bin, pT_bin, pt_y_yields['true_mc_in_recons'].iloc[i]);\n",
    "    h7.SetBinContent(y_bin, pT_bin, a[i]);\n",
    "    h8.SetBinContent(y_bin, pT_bin, pt_y_yields['total_mc_in_recons'].iloc[i]);\n",
    "\n",
    "c.SetGrid()\n",
    "#h4.Draw('colz')\n",
    "\n",
    "#h5.Draw('colz')\n",
    "#hist_2d.Draw('colz')\n",
    "ratio_recons_to_recons_mc=h4.Divide(h8)\n",
    "\n",
    "#h6.Draw('colz')\n",
    "#ratio_recons_to_mc=h4.Divide(h5)\n",
    "h4.Draw('colz')\n",
    "\n",
    "h4.GetZaxis().SetRangeUser (0 ,0.8)\n",
    "h4.SetTitleOffset(-1)\n",
    "latex = ROOT . TLatex ()\n",
    "latex . SetNDC ()\n",
    "latex . SetTextSize (0.039)\n",
    "#latex . DrawLatex (0.4 ,0.7, \"#Lambda_{Reconstructed} / #Lambda_{MC} =  %.f / %.f = %.3f\"%(sum(a),df4[df4['issignal']>0].shape[0], sum(a) / (df4[df4['issignal']>0].shape[0])))\n",
    "latex . DrawLatex (0.12 ,0.68, \"ML algorithm Efficiency = #Lambda_{Reconstructed} / #Lambda_{Reconstructable} \" )\n",
    "\n",
    "latex.Draw()\n",
    "\n",
    "latex1 = ROOT . TLatex ()\n",
    "latex1 . SetNDC ()\n",
    "latex1 . SetTextSize (0.035)\n",
    "latex1. DrawLatex (0.12 ,0.84, \"CBM performance\")\n",
    "latex1. DrawLatex (0.12 ,0.76, \"DCM-QGSM-SMM, Au+Au @ 12#it{A} GeV/#it{c}\")\n",
    "latex1 . DrawLatex (0.45 ,.61, \"= %.f / %.f = %.3f\"%(sum(a),sum(pt_y_yields ['total_mc_in_recons']), sum(a) / (sum(pt_y_yields ['total_mc_in_recons']))))\n",
    "latex1.Draw()\n",
    "\n",
    "\n",
    "h4 . SetTitle (\"\")\n",
    "h4 .GetXaxis().SetTitle(\"#it{y}_{Lab}\")\n",
    "h4. GetXaxis().SetTitleSize(0.06)\n",
    "h4 .GetXaxis().SetTitleOffset(0.7)\n",
    "h4 .GetXaxis().SetLabelSize(0.05)\n",
    "h4 .GetYaxis().SetTitle(\"p_{T} (GeV/#it{c})\")\n",
    "h4. GetYaxis().SetTitleSize(0.06)\n",
    "h4 .GetYaxis().SetTitleOffset(0.7)\n",
    "h4 .GetYaxis().SetLabelSize(0.05)\n",
    "h4 .GetZaxis().SetLabelSize(0.05)\n",
    "\n",
    "c.SetRightMargin(0.13);\n",
    "c. Update()\n",
    "c . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h8 = ROOT.TH2F(\"recons_urqmd\", \"recons_urqmd\", 15,0,3,15,0,3);\n",
    "h9 = ROOT.TH2F(\"Mc_urqmd\", \"Mc_urqmd\", 15,0,3,15,0,3);\n",
    "h10 = ROOT.TH2F(\"Mc in reconstructed_urqmd\", \"Mc in reconstructed_urqmd\", 15,0,3,15,0,3);\n",
    "h11 = ROOT.TH2F(\"urqmd_Efficiency\", \"Efficiency\", 15,0,3,15,0,3);\n",
    "h11.SetStats(0)\n",
    "h9.SetStats(0)\n",
    "h10.SetStats(0)\n",
    "\n",
    "canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "canvas.Draw()\n",
    "bin1 = h8.FindBin(0);\n",
    "bin2 = h8.FindBin(3);\n",
    "for i in range(1,225):\n",
    "    #recons.SetBinContent( (pt_y_yields1['rapidity_min'].iloc[i]), (pt_y_yields1['pT_min'].iloc[i]) ,pt_y_yields1['pt_y_yields'].iloc[i])\n",
    "    y= (pt_y_yields['rapidity_min_MC'].iloc[i])\n",
    "    pT=(pt_y_yields['pT_min_MC'].iloc[i])\n",
    "    y_bin = int((y+0.1)/0.2 + 1);\n",
    "    pT_bin = int((pT+0.1)/0.2 + 1);\n",
    "    h8.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_recons'].iloc[i]);\n",
    "    h9.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_MC'].iloc[i]);\n",
    "    h10.SetBinContent(y_bin, pT_bin, pt_y_yields['true_mc_in_recons'].iloc[i]);\n",
    "    h11.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_recons'].iloc[i]);\n",
    "\n",
    "canvas.SetGrid()\n",
    "#h4.Draw('colz')\n",
    "\n",
    "#h5.Draw('colz')\n",
    "#hist_2d.Draw('colz')\n",
    "ratio_recons_to_recons_mc=h11.Divide(h9)\n",
    "\n",
    "#h6.Draw('colz')\n",
    "#ratio_recons_to_mc=h4.Divide(h5)\n",
    "h11.Draw('colz')\n",
    "\n",
    "h11.GetZaxis().SetLabelSize (0.02)\n",
    "\n",
    "h11.SetTitleOffset(-1)\n",
    "latex = ROOT . TLatex ()\n",
    "latex . SetNDC ()\n",
    "latex . SetTextSize (0.03)\n",
    "#latex . DrawLatex (0.4 ,0.7, \"#Lambda_{Reconstructed} / #Lambda_{MC} =  %.f / %.f = %.3f\"%(sum(a),df4[df4['issignal']>0].shape[0], sum(a) / (df4[df4['issignal']>0].shape[0])))\n",
    "latex . DrawLatex (0.3 ,0.7, \"#Lambda_{Reconstructed} / #Lambda_{Simulated} =  %.f / %.f = %.3f\"%(sum(a),sum(pt_y_yields ['pt_y_yields_MC']), sum(a) / (sum(pt_y_yields ['pt_y_yields_MC']))))\n",
    "latex . DrawLatex (0.3 ,0.6, \"URQMD\")\n",
    "\n",
    "latex.Draw()\n",
    "\n",
    "\n",
    "h11 . SetTitle (\"\")\n",
    "h11 .GetXaxis().SetTitle(\"y_{Lab}\")\n",
    "h11 .GetXaxis().SetTitleOffset(0)\n",
    "h11 .GetYaxis().SetTitle(\"p_{T} GeV/c\")\n",
    "h11 .GetXaxis().SetTitleOffset(0)\n",
    "canvas . Print (\"/home/shahid/cbmsoft/Cut_optimization/uncut_data/Project/pT_rapidity_distribution_XGB_extracted_signal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import TFile, TTree\n",
    "from array import array\n",
    "from ROOT import std\n",
    "\n",
    "f = TFile('new_urqmd_efficiency_pt_y_yield_bdt_cut_0.9.root','recreate')\n",
    "t = TTree('t1','tree')\n",
    "\n",
    "\n",
    "h8 = ROOT.TH2F(\"recons_urqmd\", \"recons_urqmd\", 15,0,3,15,0,3);\n",
    "h9 = ROOT.TH2F(\"Mc_urqmd\", \"Mc_urqmd\", 15,0,3,15,0,3);\n",
    "h10 = ROOT.TH2F(\"Mc in reconstructed_urqmd\", \"Mc in reconstructed_urqmd\", 15,0,3,15,0,3);\n",
    "h11 = ROOT.TH2F(\"urqmd_Efficiency\", \"Efficiency\", 15,0,3,15,0,3);\n",
    "h8.SetStats(0)\n",
    "h9.SetStats(0)\n",
    "h10.SetStats(0)\n",
    "\n",
    "\n",
    "bin1 = h8.FindBin(0);\n",
    "bin2 = h8.FindBin(3);\n",
    "for i in range(1,225):\n",
    "    #recons.SetBinContent( (pt_y_yields1['rapidity_min'].iloc[i]), (pt_y_yields1['pT_min'].iloc[i]) ,pt_y_yields1['pt_y_yields'].iloc[i])\n",
    "    y= (pt_y_yields['rapidity_min_MC'].iloc[i])\n",
    "    pT=(pt_y_yields['pT_min_MC'].iloc[i])\n",
    "    y_bin = int((y+0.1)/0.2 + 1);\n",
    "    pT_bin = int((pT+0.1)/0.2 + 1);\n",
    "    h8.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_recons'].iloc[i]);\n",
    "    h9.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_MC'].iloc[i]);\n",
    "    h10.SetBinContent(y_bin, pT_bin, pt_y_yields['true_mc_in_recons'].iloc[i]);\n",
    "    h11.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_recons'].iloc[i]);\n",
    "    \n",
    "\n",
    "\n",
    "#h4.Draw('colz')\n",
    "\n",
    "#h5.Draw('colz')\n",
    "#hist_2d.Draw('colz')\n",
    "#ratio_recons_to_recons_mc=h8.Divide(h9)\n",
    "\n",
    "#h6.Draw('colz')\n",
    "ratio_recons_to_mc=h11.Divide(h9)\n",
    "#h8.Draw('colz')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h8 . SetTitle (\"\")\n",
    "h8 .GetXaxis().SetTitle(\"y_{Lab}\")\n",
    "h8 .GetXaxis().SetTitleOffset(0)\n",
    "h8 .GetYaxis().SetTitle(\"p_{T} GeV/c\")\n",
    "h8 .GetXaxis().SetTitleOffset(0)\n",
    "\n",
    "f.Write()\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import TFile, TTree\n",
    "from array import array\n",
    "from ROOT import std\n",
    "\n",
    "f = TFile('new_dcm_100_efficiency_pt_y_yield_bdt_cut_0.9.root','recreate')\n",
    "t = TTree('t1','tree')\n",
    "\n",
    "\n",
    "h4 = ROOT.TH2F(\"recons\", \"recons\", 15,0,3,15,0,3);\n",
    "h5 = ROOT.TH2F(\"Mc\", \"Mc\", 15,0,3,15,0,3);\n",
    "h6 = ROOT.TH2F(\"Mc in reconstructed\", \"Mc in reconstructed\", 15,0,3,15,0,3);\n",
    "h7 = ROOT.TH2F(\"Efficiency\", \"Efficiency\", 15,0,3,15,0,3);\n",
    "h8 = ROOT.TH2F(\"reconstructable_mc\", \"reconstructable_mc\", 15,0,3,15,0,3);\n",
    "\n",
    "bin1 = h4.FindBin(0);\n",
    "bin2 = h4.FindBin(3);\n",
    "for i in range(1,225):\n",
    "    #recons.SetBinContent( (pt_y_yields1['rapidity_min'].iloc[i]), (pt_y_yields1['pT_min'].iloc[i]) ,pt_y_yields1['pt_y_yields'].iloc[i])\n",
    "    y= (pt_y_yields['rapidity_min_MC'].iloc[i])\n",
    "    pT=(pt_y_yields['pT_min_MC'].iloc[i])\n",
    "    y_bin = int((y+0.1)/0.2 + 1);\n",
    "    pT_bin = int((pT+0.1)/0.2 + 1);\n",
    "    h4.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_recons'].iloc[i]);\n",
    "    h5.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_MC'].iloc[i]);\n",
    "    h6.SetBinContent(y_bin, pT_bin, pt_y_yields['true_mc_in_recons'].iloc[i]);\n",
    "    h7.SetBinContent(y_bin, pT_bin, pt_y_yields['pt_y_yields_recons'].iloc[i]);\n",
    "    h8.SetBinContent(y_bin, pT_bin, dcm_clean_mc[i]);\n",
    "    \n",
    "\n",
    "\n",
    "#h4.Draw('colz')\n",
    "\n",
    "#h5.Draw('colz')\n",
    "#hist_2d.Draw('colz')\n",
    "#ratio_recons_to_recons_mc=h4.Divide(h5)\n",
    "\n",
    "#h6.Draw('colz')\n",
    "ratio_recons_to_mc=h7.Divide(h5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f.Write()\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inFile = ROOT . TFile . Open ( \"lambda_qa_urqmd.root\" ,\" READ \")\n",
    "inFile.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist_2d = inFile.Get(\"SimParticles_McLambda/SimParticles_rapidity_SimParticles_pT_McLambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h4 = ROOT.TH2F(\"recons\", \"recons\", 15,0,3,15,0,3);\n",
    "h4.SetStats(0)\n",
    "canvas = ROOT . TCanvas (\" canvas \",\"\", 1200,1000)\n",
    "canvas.Draw()\n",
    "\n",
    "for i in range(1,225):\n",
    "    #recons.SetBinContent( (pt_y_yields1['rapidity_min'].iloc[i]), (pt_y_yields1['pT_min'].iloc[i]) ,pt_y_yields1['pt_y_yields'].iloc[i])\n",
    "    y= (df4['rapidity'].iloc[i])\n",
    "    pT=(df4['pT'].iloc[i])\n",
    "    y_bin = int((y+0.1)/0.2 + 1);\n",
    "    pT_bin = int((pT+0.1)/0.2 + 1);\n",
    "    h4.SetBinContent(y_bin, pT_bin, df4['issignal'].iloc[i]);\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h4.Draw('colz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "fig, axs =plt.subplots(figsize=(12,10))\n",
    "h =axs.hist2d(df4[df4['issignal']==1]['rapidity'], df4[df4['issignal']==1]['pT'], bins=(bins1, bins1),norm=mpl.colors.LogNorm())\n",
    "cbar=fig.colorbar(h[3], ax=axs)\n",
    "plt.show()\n",
    "fig.savefig('hists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins1 = np.linspace(0,3,16)\n",
    "bins1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binned_statistic as b_s\n",
    "bin_means, bin_edges, binnumber = b_s(df[variable_xaxis],df[variable_yaxis], statistic='mean', bins=non_uniform_binning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
